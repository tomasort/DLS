saving to results/2022-03-31_05-37-35_resnet44_m-1
creating model resnet
created model with configuration: {'dataset': 'cifar10'}
number of parameters: 661338
/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x150089a84940>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x150089a849d0>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]
data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 512, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 1, 'autoaugment': False, 'cutout': None}
 Regime:None

Starting Epoch: 1

Files already downloaded and verified
Files already downloaded and verified
TRAINING - Epoch: [0][0/97]	Time 2.264 (2.264)	Data 1.867 (1.867)	Loss 2.3050 (2.3050)	Prec@1 9.766 (9.766)	Prec@5 48.633 (48.633)	Acc 0.098 (0.098)	
TRAINING - Epoch: [0][10/97]	Time 0.073 (0.273)	Data 0.000 (0.170)	Loss 2.2193 (2.2733)	Prec@1 19.727 (15.874)	Prec@5 70.703 (60.263)	Acc 0.159 (0.141)	
TRAINING - Epoch: [0][20/97]	Time 0.074 (0.178)	Data 0.000 (0.089)	Loss 2.0908 (2.2110)	Prec@1 24.219 (18.220)	Prec@5 73.047 (65.811)	Acc 0.182 (0.156)	
TRAINING - Epoch: [0][30/97]	Time 0.073 (0.144)	Data 0.000 (0.060)	Loss 1.9570 (2.1475)	Prec@1 25.000 (20.331)	Prec@5 81.250 (69.777)	Acc 0.203 (0.169)	
TRAINING - Epoch: [0][40/97]	Time 0.073 (0.127)	Data 0.000 (0.046)	Loss 1.9752 (2.1054)	Prec@1 24.805 (21.761)	Prec@5 80.273 (72.247)	Acc 0.218 (0.179)	
TRAINING - Epoch: [0][50/97]	Time 0.073 (0.116)	Data 0.000 (0.037)	Loss 1.8694 (2.0668)	Prec@1 27.539 (22.955)	Prec@5 84.180 (74.272)	Acc 0.230 (0.188)	
TRAINING - Epoch: [0][60/97]	Time 0.073 (0.109)	Data 0.000 (0.031)	Loss 1.8508 (2.0317)	Prec@1 28.320 (24.081)	Prec@5 83.984 (75.909)	Acc 0.241 (0.196)	
TRAINING - Epoch: [0][70/97]	Time 0.073 (0.104)	Data 0.000 (0.027)	Loss 1.7983 (2.0023)	Prec@1 31.836 (24.923)	Prec@5 87.500 (77.272)	Acc 0.249 (0.203)	
TRAINING - Epoch: [0][80/97]	Time 0.073 (0.100)	Data 0.000 (0.023)	Loss 1.7203 (1.9732)	Prec@1 34.961 (25.755)	Prec@5 88.867 (78.499)	Acc 0.258 (0.209)	
TRAINING - Epoch: [0][90/97]	Time 0.072 (0.097)	Data 0.000 (0.021)	Loss 1.7628 (1.9475)	Prec@1 28.516 (26.479)	Prec@5 87.500 (79.475)	Acc 0.265 (0.215)	
TRAINING - Epoch: [0][96/97]	Time 0.072 (0.095)	Data 0.000 (0.019)	Loss 1.7317 (1.9340)	Prec@1 34.570 (26.848)	Prec@5 86.523 (80.032)	Acc 0.268 (0.218)	
EVALUATING - Epoch: [0][0/20]	Time 0.673 (0.673)	Data 0.656 (0.656)	Loss 1.6946 (1.6946)	Prec@1 34.375 (34.375)	Prec@5 90.820 (90.820)	Acc 0.344 (0.344)	
EVALUATING - Epoch: [0][10/20]	Time 0.016 (0.086)	Data 0.000 (0.066)	Loss 1.8037 (1.7113)	Prec@1 33.594 (34.570)	Prec@5 87.305 (89.169)	Acc 0.346 (0.341)	
EVALUATING - Epoch: [0][19/20]	Time 0.032 (0.055)	Data 0.000 (0.037)	Loss 1.7016 (1.7124)	Prec@1 31.618 (34.380)	Prec@5 89.338 (88.680)	Acc 0.344 (0.343)	

Results - Epoch: 1
Training Loss 1.9340 	Training Prec@1 26.848 	Training Prec@5 80.032 	Validation Loss 1.7124 	Validation Prec@1 34.380 	Validation Prec@5 88.680 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)
Plot file saved at: /scratch/tor213/DLS/results/2022-03-31_05-37-35_resnet44_m-1/results.html

Starting Epoch: 2

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [1][0/97]	Time 0.672 (0.672)	Data 0.598 (0.598)	Loss 1.6974 (1.6974)	Prec@1 37.695 (37.695)	Prec@5 86.914 (86.914)	Acc 0.377 (0.377)	
TRAINING - Epoch: [1][10/97]	Time 0.073 (0.149)	Data 0.000 (0.075)	Loss 1.6849 (1.6846)	Prec@1 32.617 (35.156)	Prec@5 88.867 (88.441)	Acc 0.352 (0.364)	
TRAINING - Epoch: [1][20/97]	Time 0.073 (0.114)	Data 0.000 (0.041)	Loss 1.6135 (1.6691)	Prec@1 37.305 (35.528)	Prec@5 90.625 (89.090)	Acc 0.355 (0.358)	
TRAINING - Epoch: [1][30/97]	Time 0.073 (0.101)	Data 0.000 (0.028)	Loss 1.6429 (1.6556)	Prec@1 34.961 (36.051)	Prec@5 91.602 (89.390)	Acc 0.361 (0.358)	
TRAINING - Epoch: [1][40/97]	Time 0.073 (0.094)	Data 0.000 (0.021)	Loss 1.6054 (1.6405)	Prec@1 37.500 (36.747)	Prec@5 90.430 (89.491)	Acc 0.367 (0.360)	
TRAINING - Epoch: [1][50/97]	Time 0.073 (0.090)	Data 0.000 (0.017)	Loss 1.5207 (1.6252)	Prec@1 41.992 (37.305)	Prec@5 91.992 (89.794)	Acc 0.373 (0.362)	
TRAINING - Epoch: [1][60/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 1.5674 (1.6116)	Prec@1 38.672 (38.163)	Prec@5 90.234 (90.068)	Acc 0.382 (0.364)	
TRAINING - Epoch: [1][70/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 1.5403 (1.5993)	Prec@1 45.898 (38.936)	Prec@5 89.844 (90.251)	Acc 0.389 (0.367)	
TRAINING - Epoch: [1][80/97]	Time 0.073 (0.083)	Data 0.000 (0.011)	Loss 1.5234 (1.5840)	Prec@1 40.820 (39.627)	Prec@5 91.406 (90.531)	Acc 0.396 (0.371)	
TRAINING - Epoch: [1][90/97]	Time 0.072 (0.082)	Data 0.000 (0.010)	Loss 1.3773 (1.5682)	Prec@1 50.195 (40.374)	Prec@5 94.727 (90.780)	Acc 0.404 (0.374)	
TRAINING - Epoch: [1][96/97]	Time 0.072 (0.082)	Data 0.000 (0.009)	Loss 1.5162 (1.5619)	Prec@1 40.625 (40.623)	Prec@5 91.992 (90.885)	Acc 0.406 (0.376)	
EVALUATING - Epoch: [1][0/20]	Time 0.555 (0.555)	Data 0.539 (0.539)	Loss 1.4572 (1.4572)	Prec@1 44.922 (44.922)	Prec@5 93.359 (93.359)	Acc 0.449 (0.449)	
EVALUATING - Epoch: [1][10/20]	Time 0.016 (0.084)	Data 0.000 (0.068)	Loss 1.5305 (1.4685)	Prec@1 45.703 (46.165)	Prec@5 91.797 (93.537)	Acc 0.462 (0.462)	
EVALUATING - Epoch: [1][19/20]	Time 0.009 (0.053)	Data 0.000 (0.037)	Loss 1.5140 (1.4603)	Prec@1 41.176 (46.170)	Prec@5 95.221 (93.920)	Acc 0.462 (0.462)	

Results - Epoch: 2
Training Loss 1.5619 	Training Prec@1 40.623 	Training Prec@5 90.885 	Validation Loss 1.4603 	Validation Prec@1 46.170 	Validation Prec@5 93.920 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 3

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [2][0/97]	Time 0.652 (0.652)	Data 0.579 (0.579)	Loss 1.3811 (1.3811)	Prec@1 51.562 (51.562)	Prec@5 93.555 (93.555)	Acc 0.516 (0.516)	
TRAINING - Epoch: [2][10/97]	Time 0.073 (0.139)	Data 0.000 (0.064)	Loss 1.3265 (1.3737)	Prec@1 52.734 (49.396)	Prec@5 93.750 (93.768)	Acc 0.494 (0.491)	
TRAINING - Epoch: [2][20/97]	Time 0.073 (0.107)	Data 0.000 (0.034)	Loss 1.3602 (1.3591)	Prec@1 49.805 (49.944)	Prec@5 94.531 (93.629)	Acc 0.499 (0.495)	
TRAINING - Epoch: [2][30/97]	Time 0.073 (0.096)	Data 0.000 (0.023)	Loss 1.3473 (1.3501)	Prec@1 49.414 (50.139)	Prec@5 92.969 (93.756)	Acc 0.501 (0.497)	
TRAINING - Epoch: [2][40/97]	Time 0.073 (0.090)	Data 0.000 (0.017)	Loss 1.2878 (1.3364)	Prec@1 51.367 (50.667)	Prec@5 94.141 (93.826)	Acc 0.507 (0.499)	
TRAINING - Epoch: [2][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 1.1895 (1.3169)	Prec@1 56.445 (51.517)	Prec@5 94.727 (94.033)	Acc 0.515 (0.501)	
TRAINING - Epoch: [2][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 1.2396 (1.3017)	Prec@1 54.102 (52.232)	Prec@5 95.117 (94.233)	Acc 0.522 (0.504)	
TRAINING - Epoch: [2][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 1.2118 (1.2889)	Prec@1 55.469 (52.583)	Prec@5 94.922 (94.311)	Acc 0.526 (0.507)	
TRAINING - Epoch: [2][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 1.1803 (1.2820)	Prec@1 58.594 (52.927)	Prec@5 95.703 (94.401)	Acc 0.529 (0.510)	
TRAINING - Epoch: [2][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 1.1719 (1.2708)	Prec@1 55.273 (53.288)	Prec@5 96.094 (94.533)	Acc 0.533 (0.512)	
TRAINING - Epoch: [2][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 1.0772 (1.2606)	Prec@1 60.742 (53.683)	Prec@5 96.289 (94.638)	Acc 0.537 (0.513)	
EVALUATING - Epoch: [2][0/20]	Time 0.591 (0.591)	Data 0.574 (0.574)	Loss 2.5423 (2.5423)	Prec@1 36.328 (36.328)	Prec@5 81.055 (81.055)	Acc 0.363 (0.363)	
EVALUATING - Epoch: [2][10/20]	Time 0.016 (0.079)	Data 0.000 (0.063)	Loss 2.8619 (2.6686)	Prec@1 33.203 (35.405)	Prec@5 78.320 (79.457)	Acc 0.354 (0.359)	
EVALUATING - Epoch: [2][19/20]	Time 0.009 (0.050)	Data 0.000 (0.035)	Loss 2.7515 (2.6662)	Prec@1 36.397 (35.460)	Prec@5 78.309 (79.210)	Acc 0.355 (0.356)	

Results - Epoch: 3
Training Loss 1.2606 	Training Prec@1 53.683 	Training Prec@5 94.638 	Validation Loss 2.6662 	Validation Prec@1 35.460 	Validation Prec@5 79.210 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 4

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [3][0/97]	Time 0.763 (0.763)	Data 0.671 (0.671)	Loss 1.1817 (1.1817)	Prec@1 56.445 (56.445)	Prec@5 96.484 (96.484)	Acc 0.564 (0.564)	
TRAINING - Epoch: [3][10/97]	Time 0.072 (0.166)	Data 0.000 (0.088)	Loss 1.1031 (1.1005)	Prec@1 59.961 (60.174)	Prec@5 94.531 (96.325)	Acc 0.602 (0.595)	
TRAINING - Epoch: [3][20/97]	Time 0.073 (0.121)	Data 0.000 (0.046)	Loss 1.1751 (1.1029)	Prec@1 57.031 (60.063)	Prec@5 96.875 (96.187)	Acc 0.601 (0.599)	
TRAINING - Epoch: [3][30/97]	Time 0.073 (0.106)	Data 0.000 (0.031)	Loss 1.0926 (1.0943)	Prec@1 63.086 (60.522)	Prec@5 96.875 (96.264)	Acc 0.605 (0.601)	
TRAINING - Epoch: [3][40/97]	Time 0.073 (0.098)	Data 0.000 (0.024)	Loss 0.9742 (1.0833)	Prec@1 65.039 (60.985)	Prec@5 97.852 (96.346)	Acc 0.610 (0.602)	
TRAINING - Epoch: [3][50/97]	Time 0.073 (0.093)	Data 0.000 (0.019)	Loss 1.0966 (1.0802)	Prec@1 62.500 (61.117)	Prec@5 95.898 (96.381)	Acc 0.611 (0.604)	
TRAINING - Epoch: [3][60/97]	Time 0.073 (0.089)	Data 0.000 (0.016)	Loss 1.1097 (1.0724)	Prec@1 60.156 (61.440)	Prec@5 97.266 (96.430)	Acc 0.614 (0.605)	
TRAINING - Epoch: [3][70/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.9679 (1.0649)	Prec@1 61.719 (61.609)	Prec@5 97.656 (96.482)	Acc 0.616 (0.607)	
TRAINING - Epoch: [3][80/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 1.0321 (1.0600)	Prec@1 61.914 (61.709)	Prec@5 98.438 (96.593)	Acc 0.617 (0.608)	
TRAINING - Epoch: [3][90/97]	Time 0.072 (0.084)	Data 0.000 (0.011)	Loss 1.0307 (1.0558)	Prec@1 62.109 (61.912)	Prec@5 95.508 (96.598)	Acc 0.619 (0.609)	
TRAINING - Epoch: [3][96/97]	Time 0.072 (0.083)	Data 0.000 (0.010)	Loss 0.9707 (1.0517)	Prec@1 65.820 (62.073)	Prec@5 96.094 (96.615)	Acc 0.621 (0.610)	
EVALUATING - Epoch: [3][0/20]	Time 0.548 (0.548)	Data 0.530 (0.530)	Loss 1.1049 (1.1049)	Prec@1 60.352 (60.352)	Prec@5 96.875 (96.875)	Acc 0.604 (0.604)	
EVALUATING - Epoch: [3][10/20]	Time 0.016 (0.083)	Data 0.000 (0.060)	Loss 1.1990 (1.1407)	Prec@1 57.422 (60.440)	Prec@5 94.922 (95.756)	Acc 0.604 (0.608)	
EVALUATING - Epoch: [3][19/20]	Time 0.009 (0.052)	Data 0.000 (0.033)	Loss 1.2490 (1.1420)	Prec@1 52.574 (60.340)	Prec@5 95.956 (95.920)	Acc 0.603 (0.606)	

Results - Epoch: 4
Training Loss 1.0517 	Training Prec@1 62.073 	Training Prec@5 96.615 	Validation Loss 1.1420 	Validation Prec@1 60.340 	Validation Prec@5 95.920 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 5

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [4][0/97]	Time 0.786 (0.786)	Data 0.694 (0.694)	Loss 0.9001 (0.9001)	Prec@1 66.797 (66.797)	Prec@5 97.461 (97.461)	Acc 0.668 (0.668)	
TRAINING - Epoch: [4][10/97]	Time 0.073 (0.141)	Data 0.000 (0.065)	Loss 0.9046 (0.9280)	Prec@1 68.945 (67.045)	Prec@5 97.070 (97.514)	Acc 0.670 (0.670)	
TRAINING - Epoch: [4][20/97]	Time 0.073 (0.108)	Data 0.000 (0.034)	Loss 0.9261 (0.9432)	Prec@1 66.211 (66.341)	Prec@5 97.070 (97.303)	Acc 0.663 (0.667)	
TRAINING - Epoch: [4][30/97]	Time 0.073 (0.097)	Data 0.000 (0.023)	Loss 1.0089 (0.9459)	Prec@1 63.281 (66.406)	Prec@5 96.484 (97.266)	Acc 0.664 (0.666)	
TRAINING - Epoch: [4][40/97]	Time 0.073 (0.091)	Data 0.000 (0.018)	Loss 0.9514 (0.9394)	Prec@1 64.648 (66.444)	Prec@5 97.266 (97.347)	Acc 0.664 (0.666)	
TRAINING - Epoch: [4][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.8926 (0.9344)	Prec@1 66.016 (66.471)	Prec@5 97.266 (97.369)	Acc 0.665 (0.665)	
TRAINING - Epoch: [4][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.8191 (0.9290)	Prec@1 68.555 (66.589)	Prec@5 97.656 (97.387)	Acc 0.666 (0.665)	
TRAINING - Epoch: [4][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.8569 (0.9262)	Prec@1 70.117 (66.701)	Prec@5 97.852 (97.395)	Acc 0.667 (0.666)	
TRAINING - Epoch: [4][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.9375 (0.9215)	Prec@1 67.188 (66.862)	Prec@5 97.852 (97.449)	Acc 0.669 (0.666)	
TRAINING - Epoch: [4][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.9324 (0.9211)	Prec@1 66.406 (66.904)	Prec@5 97.070 (97.431)	Acc 0.669 (0.666)	
TRAINING - Epoch: [4][96/97]	Time 0.072 (0.080)	Data 0.000 (0.008)	Loss 0.8324 (0.9195)	Prec@1 67.773 (66.924)	Prec@5 98.242 (97.449)	Acc 0.669 (0.666)	
EVALUATING - Epoch: [4][0/20]	Time 0.621 (0.621)	Data 0.604 (0.604)	Loss 1.4123 (1.4123)	Prec@1 54.297 (54.297)	Prec@5 96.875 (96.875)	Acc 0.543 (0.543)	
EVALUATING - Epoch: [4][10/20]	Time 0.016 (0.083)	Data 0.000 (0.067)	Loss 1.5421 (1.4691)	Prec@1 49.609 (54.492)	Prec@5 96.289 (95.721)	Acc 0.545 (0.554)	
EVALUATING - Epoch: [4][19/20]	Time 0.009 (0.052)	Data 0.000 (0.037)	Loss 1.5450 (1.4690)	Prec@1 50.735 (54.060)	Prec@5 95.956 (95.600)	Acc 0.541 (0.548)	

Results - Epoch: 5
Training Loss 0.9195 	Training Prec@1 66.924 	Training Prec@5 97.449 	Validation Loss 1.4690 	Validation Prec@1 54.060 	Validation Prec@5 95.600 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 6

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [5][0/97]	Time 0.778 (0.778)	Data 0.704 (0.704)	Loss 0.8835 (0.8835)	Prec@1 66.602 (66.602)	Prec@5 98.828 (98.828)	Acc 0.666 (0.666)	
TRAINING - Epoch: [5][10/97]	Time 0.073 (0.141)	Data 0.000 (0.067)	Loss 0.7879 (0.8807)	Prec@1 69.727 (67.489)	Prec@5 98.242 (97.816)	Acc 0.675 (0.667)	
TRAINING - Epoch: [5][20/97]	Time 0.073 (0.108)	Data 0.000 (0.035)	Loss 0.8947 (0.8726)	Prec@1 68.359 (67.941)	Prec@5 97.852 (97.814)	Acc 0.679 (0.671)	
TRAINING - Epoch: [5][30/97]	Time 0.073 (0.097)	Data 0.000 (0.024)	Loss 0.8298 (0.8621)	Prec@1 70.703 (68.706)	Prec@5 98.828 (97.883)	Acc 0.687 (0.676)	
TRAINING - Epoch: [5][40/97]	Time 0.073 (0.091)	Data 0.000 (0.018)	Loss 0.8621 (0.8556)	Prec@1 69.336 (69.126)	Prec@5 97.852 (97.823)	Acc 0.691 (0.679)	
TRAINING - Epoch: [5][50/97]	Time 0.073 (0.087)	Data 0.000 (0.015)	Loss 0.8399 (0.8472)	Prec@1 70.117 (69.409)	Prec@5 98.047 (97.840)	Acc 0.694 (0.682)	
TRAINING - Epoch: [5][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.8101 (0.8422)	Prec@1 71.875 (69.723)	Prec@5 97.266 (97.855)	Acc 0.697 (0.684)	
TRAINING - Epoch: [5][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.7568 (0.8371)	Prec@1 71.484 (69.897)	Prec@5 98.828 (97.904)	Acc 0.699 (0.686)	
TRAINING - Epoch: [5][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.8314 (0.8350)	Prec@1 72.266 (70.064)	Prec@5 98.438 (97.924)	Acc 0.701 (0.688)	
TRAINING - Epoch: [5][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.7988 (0.8289)	Prec@1 72.461 (70.229)	Prec@5 98.438 (97.970)	Acc 0.702 (0.689)	
TRAINING - Epoch: [5][96/97]	Time 0.072 (0.080)	Data 0.000 (0.008)	Loss 0.7803 (0.8266)	Prec@1 72.266 (70.312)	Prec@5 98.438 (97.995)	Acc 0.703 (0.690)	
EVALUATING - Epoch: [5][0/20]	Time 0.530 (0.530)	Data 0.514 (0.514)	Loss 0.9196 (0.9196)	Prec@1 66.992 (66.992)	Prec@5 97.852 (97.852)	Acc 0.670 (0.670)	
EVALUATING - Epoch: [5][10/20]	Time 0.016 (0.082)	Data 0.000 (0.064)	Loss 0.9350 (0.9381)	Prec@1 66.016 (68.004)	Prec@5 97.070 (97.479)	Acc 0.680 (0.680)	
EVALUATING - Epoch: [5][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 1.0306 (0.9368)	Prec@1 64.338 (67.910)	Prec@5 97.794 (97.560)	Acc 0.679 (0.679)	

Results - Epoch: 6
Training Loss 0.8266 	Training Prec@1 70.312 	Training Prec@5 97.995 	Validation Loss 0.9368 	Validation Prec@1 67.910 	Validation Prec@5 97.560 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 7

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [6][0/97]	Time 0.712 (0.712)	Data 0.624 (0.624)	Loss 0.7796 (0.7796)	Prec@1 72.852 (72.852)	Prec@5 98.047 (98.047)	Acc 0.729 (0.729)	
TRAINING - Epoch: [6][10/97]	Time 0.073 (0.138)	Data 0.000 (0.059)	Loss 0.8636 (0.7846)	Prec@1 69.336 (71.768)	Prec@5 97.266 (98.047)	Acc 0.718 (0.728)	
TRAINING - Epoch: [6][20/97]	Time 0.073 (0.107)	Data 0.000 (0.031)	Loss 0.7790 (0.7795)	Prec@1 72.461 (72.089)	Prec@5 98.828 (98.093)	Acc 0.721 (0.724)	
TRAINING - Epoch: [6][30/97]	Time 0.073 (0.096)	Data 0.000 (0.021)	Loss 0.7440 (0.7738)	Prec@1 74.805 (72.379)	Prec@5 99.219 (98.173)	Acc 0.724 (0.723)	
TRAINING - Epoch: [6][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.7824 (0.7690)	Prec@1 72.852 (72.385)	Prec@5 98.633 (98.252)	Acc 0.724 (0.723)	
TRAINING - Epoch: [6][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.7757 (0.7660)	Prec@1 71.094 (72.449)	Prec@5 98.438 (98.280)	Acc 0.724 (0.724)	
TRAINING - Epoch: [6][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.7153 (0.7683)	Prec@1 76.367 (72.480)	Prec@5 98.438 (98.284)	Acc 0.725 (0.724)	
TRAINING - Epoch: [6][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.7887 (0.7656)	Prec@1 72.461 (72.565)	Prec@5 97.656 (98.264)	Acc 0.726 (0.724)	
TRAINING - Epoch: [6][80/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.7749 (0.7626)	Prec@1 71.289 (72.726)	Prec@5 97.656 (98.288)	Acc 0.727 (0.724)	
TRAINING - Epoch: [6][90/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.7951 (0.7627)	Prec@1 73.828 (72.718)	Prec@5 97.461 (98.292)	Acc 0.727 (0.725)	
TRAINING - Epoch: [6][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.7440 (0.7619)	Prec@1 74.609 (72.757)	Prec@5 99.023 (98.295)	Acc 0.728 (0.725)	
EVALUATING - Epoch: [6][0/20]	Time 0.511 (0.511)	Data 0.493 (0.493)	Loss 1.1561 (1.1561)	Prec@1 59.766 (59.766)	Prec@5 97.656 (97.656)	Acc 0.598 (0.598)	
EVALUATING - Epoch: [6][10/20]	Time 0.016 (0.084)	Data 0.000 (0.064)	Loss 1.2550 (1.1779)	Prec@1 59.180 (61.914)	Prec@5 96.680 (96.413)	Acc 0.619 (0.617)	
EVALUATING - Epoch: [6][19/20]	Time 0.009 (0.053)	Data 0.000 (0.035)	Loss 1.1791 (1.1810)	Prec@1 61.397 (61.620)	Prec@5 96.324 (96.660)	Acc 0.616 (0.617)	

Results - Epoch: 7
Training Loss 0.7619 	Training Prec@1 72.757 	Training Prec@5 98.295 	Validation Loss 1.1810 	Validation Prec@1 61.620 	Validation Prec@5 96.660 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 8

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [7][0/97]	Time 0.731 (0.731)	Data 0.655 (0.655)	Loss 0.6946 (0.6946)	Prec@1 74.805 (74.805)	Prec@5 99.219 (99.219)	Acc 0.748 (0.748)	
TRAINING - Epoch: [7][10/97]	Time 0.073 (0.138)	Data 0.000 (0.060)	Loss 0.6742 (0.7247)	Prec@1 75.391 (74.503)	Prec@5 98.438 (98.544)	Acc 0.745 (0.743)	
TRAINING - Epoch: [7][20/97]	Time 0.073 (0.107)	Data 0.000 (0.032)	Loss 0.6721 (0.7193)	Prec@1 75.586 (74.554)	Prec@5 99.023 (98.363)	Acc 0.746 (0.744)	
TRAINING - Epoch: [7][30/97]	Time 0.073 (0.096)	Data 0.000 (0.021)	Loss 0.7136 (0.7235)	Prec@1 74.219 (74.439)	Prec@5 98.242 (98.406)	Acc 0.744 (0.744)	
TRAINING - Epoch: [7][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.6385 (0.7125)	Prec@1 75.977 (74.695)	Prec@5 99.609 (98.485)	Acc 0.747 (0.745)	
TRAINING - Epoch: [7][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.7057 (0.7092)	Prec@1 75.586 (74.858)	Prec@5 98.828 (98.514)	Acc 0.749 (0.746)	
TRAINING - Epoch: [7][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.6645 (0.7031)	Prec@1 76.758 (75.141)	Prec@5 99.219 (98.550)	Acc 0.751 (0.746)	
TRAINING - Epoch: [7][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.6653 (0.6991)	Prec@1 76.367 (75.272)	Prec@5 98.633 (98.597)	Acc 0.753 (0.747)	
TRAINING - Epoch: [7][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.7076 (0.6971)	Prec@1 74.805 (75.345)	Prec@5 98.828 (98.585)	Acc 0.753 (0.748)	
TRAINING - Epoch: [7][90/97]	Time 0.072 (0.081)	Data 0.000 (0.007)	Loss 0.6424 (0.6960)	Prec@1 75.977 (75.408)	Prec@5 98.438 (98.560)	Acc 0.754 (0.749)	
TRAINING - Epoch: [7][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.6474 (0.6948)	Prec@1 76.172 (75.491)	Prec@5 98.438 (98.552)	Acc 0.755 (0.749)	
EVALUATING - Epoch: [7][0/20]	Time 0.605 (0.605)	Data 0.588 (0.588)	Loss 1.4624 (1.4624)	Prec@1 61.523 (61.523)	Prec@5 96.289 (96.289)	Acc 0.615 (0.615)	
EVALUATING - Epoch: [7][10/20]	Time 0.016 (0.084)	Data 0.000 (0.061)	Loss 1.6147 (1.5514)	Prec@1 57.031 (59.819)	Prec@5 94.336 (95.046)	Acc 0.598 (0.598)	
EVALUATING - Epoch: [7][19/20]	Time 0.009 (0.053)	Data 0.000 (0.034)	Loss 1.7184 (1.5446)	Prec@1 55.147 (59.570)	Prec@5 93.382 (94.840)	Acc 0.596 (0.597)	

Results - Epoch: 8
Training Loss 0.6948 	Training Prec@1 75.491 	Training Prec@5 98.552 	Validation Loss 1.5446 	Validation Prec@1 59.570 	Validation Prec@5 94.840 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 9

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [8][0/97]	Time 0.618 (0.618)	Data 0.536 (0.536)	Loss 0.6333 (0.6333)	Prec@1 75.195 (75.195)	Prec@5 99.023 (99.023)	Acc 0.752 (0.752)	
TRAINING - Epoch: [8][10/97]	Time 0.073 (0.142)	Data 0.000 (0.063)	Loss 0.5962 (0.6513)	Prec@1 79.102 (76.332)	Prec@5 99.023 (99.077)	Acc 0.763 (0.758)	
TRAINING - Epoch: [8][20/97]	Time 0.073 (0.109)	Data 0.000 (0.033)	Loss 0.6784 (0.6511)	Prec@1 76.562 (76.749)	Prec@5 98.438 (98.865)	Acc 0.767 (0.762)	
TRAINING - Epoch: [8][30/97]	Time 0.073 (0.097)	Data 0.000 (0.022)	Loss 0.6052 (0.6548)	Prec@1 79.102 (76.833)	Prec@5 99.023 (98.828)	Acc 0.768 (0.763)	
TRAINING - Epoch: [8][40/97]	Time 0.073 (0.091)	Data 0.000 (0.017)	Loss 0.7002 (0.6537)	Prec@1 76.758 (76.948)	Prec@5 98.047 (98.819)	Acc 0.769 (0.765)	
TRAINING - Epoch: [8][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.6571 (0.6552)	Prec@1 75.977 (76.888)	Prec@5 98.828 (98.797)	Acc 0.769 (0.766)	
TRAINING - Epoch: [8][60/97]	Time 0.072 (0.085)	Data 0.000 (0.011)	Loss 0.6333 (0.6498)	Prec@1 76.953 (77.072)	Prec@5 99.219 (98.806)	Acc 0.771 (0.766)	
TRAINING - Epoch: [8][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.5669 (0.6443)	Prec@1 79.883 (77.305)	Prec@5 98.438 (98.798)	Acc 0.773 (0.767)	
TRAINING - Epoch: [8][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.5461 (0.6399)	Prec@1 82.031 (77.421)	Prec@5 99.023 (98.833)	Acc 0.774 (0.768)	
TRAINING - Epoch: [8][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.5756 (0.6404)	Prec@1 81.250 (77.453)	Prec@5 99.414 (98.847)	Acc 0.775 (0.769)	
TRAINING - Epoch: [8][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.6747 (0.6395)	Prec@1 75.586 (77.495)	Prec@5 98.828 (98.854)	Acc 0.775 (0.769)	
EVALUATING - Epoch: [8][0/20]	Time 0.633 (0.633)	Data 0.614 (0.614)	Loss 2.6104 (2.6104)	Prec@1 48.633 (48.633)	Prec@5 90.039 (90.039)	Acc 0.486 (0.486)	
EVALUATING - Epoch: [8][10/20]	Time 0.016 (0.082)	Data 0.000 (0.066)	Loss 2.8396 (2.6949)	Prec@1 49.414 (49.485)	Prec@5 88.477 (90.554)	Acc 0.495 (0.493)	
EVALUATING - Epoch: [8][19/20]	Time 0.009 (0.052)	Data 0.000 (0.036)	Loss 2.9711 (2.6458)	Prec@1 45.221 (49.190)	Prec@5 90.441 (90.540)	Acc 0.492 (0.493)	

Results - Epoch: 9
Training Loss 0.6395 	Training Prec@1 77.495 	Training Prec@5 98.854 	Validation Loss 2.6458 	Validation Prec@1 49.190 	Validation Prec@5 90.540 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 10

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [9][0/97]	Time 0.732 (0.732)	Data 0.646 (0.646)	Loss 0.6987 (0.6987)	Prec@1 76.172 (76.172)	Prec@5 98.828 (98.828)	Acc 0.762 (0.762)	
TRAINING - Epoch: [9][10/97]	Time 0.073 (0.138)	Data 0.000 (0.059)	Loss 0.6341 (0.6213)	Prec@1 77.734 (78.746)	Prec@5 98.242 (98.828)	Acc 0.787 (0.783)	
TRAINING - Epoch: [9][20/97]	Time 0.073 (0.107)	Data 0.000 (0.031)	Loss 0.6261 (0.6202)	Prec@1 78.125 (78.506)	Prec@5 98.828 (98.884)	Acc 0.785 (0.784)	
TRAINING - Epoch: [9][30/97]	Time 0.073 (0.096)	Data 0.000 (0.021)	Loss 0.6120 (0.6099)	Prec@1 79.102 (78.698)	Prec@5 98.633 (98.916)	Acc 0.787 (0.785)	
TRAINING - Epoch: [9][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.6436 (0.6081)	Prec@1 78.320 (78.825)	Prec@5 98.828 (98.890)	Acc 0.788 (0.786)	
TRAINING - Epoch: [9][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.5707 (0.6099)	Prec@1 80.664 (78.680)	Prec@5 99.219 (98.897)	Acc 0.787 (0.786)	
TRAINING - Epoch: [9][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.6773 (0.6114)	Prec@1 76.758 (78.663)	Prec@5 99.023 (98.905)	Acc 0.787 (0.786)	
TRAINING - Epoch: [9][70/97]	Time 0.072 (0.083)	Data 0.000 (0.009)	Loss 0.6766 (0.6122)	Prec@1 76.172 (78.551)	Prec@5 97.852 (98.889)	Acc 0.786 (0.786)	
TRAINING - Epoch: [9][80/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.6014 (0.6074)	Prec@1 79.297 (78.757)	Prec@5 98.828 (98.905)	Acc 0.788 (0.786)	
TRAINING - Epoch: [9][90/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.5361 (0.6058)	Prec@1 82.031 (78.859)	Prec@5 99.023 (98.886)	Acc 0.789 (0.786)	
TRAINING - Epoch: [9][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.5755 (0.6048)	Prec@1 80.859 (78.892)	Prec@5 99.023 (98.903)	Acc 0.789 (0.786)	
EVALUATING - Epoch: [9][0/20]	Time 0.503 (0.503)	Data 0.478 (0.478)	Loss 1.5094 (1.5094)	Prec@1 60.742 (60.742)	Prec@5 96.289 (96.289)	Acc 0.607 (0.607)	
EVALUATING - Epoch: [9][10/20]	Time 0.016 (0.083)	Data 0.000 (0.060)	Loss 1.5326 (1.5487)	Prec@1 60.156 (61.239)	Prec@5 97.461 (95.472)	Acc 0.612 (0.609)	
EVALUATING - Epoch: [9][19/20]	Time 0.009 (0.052)	Data 0.000 (0.033)	Loss 1.6151 (1.5613)	Prec@1 58.824 (61.250)	Prec@5 94.485 (95.480)	Acc 0.613 (0.611)	

Results - Epoch: 10
Training Loss 0.6048 	Training Prec@1 78.892 	Training Prec@5 98.903 	Validation Loss 1.5613 	Validation Prec@1 61.250 	Validation Prec@5 95.480 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 11

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [10][0/97]	Time 0.743 (0.743)	Data 0.641 (0.641)	Loss 0.5324 (0.5324)	Prec@1 82.812 (82.812)	Prec@5 99.219 (99.219)	Acc 0.828 (0.828)	
TRAINING - Epoch: [10][10/97]	Time 0.073 (0.141)	Data 0.000 (0.060)	Loss 0.5269 (0.5660)	Prec@1 81.250 (80.469)	Prec@5 99.023 (99.165)	Acc 0.805 (0.812)	
TRAINING - Epoch: [10][20/97]	Time 0.073 (0.109)	Data 0.000 (0.031)	Loss 0.5390 (0.5646)	Prec@1 82.812 (80.590)	Prec@5 98.633 (99.033)	Acc 0.806 (0.809)	
TRAINING - Epoch: [10][30/97]	Time 0.073 (0.097)	Data 0.000 (0.021)	Loss 0.5343 (0.5632)	Prec@1 82.031 (80.494)	Prec@5 99.219 (98.998)	Acc 0.805 (0.807)	
TRAINING - Epoch: [10][40/97]	Time 0.073 (0.091)	Data 0.000 (0.016)	Loss 0.5553 (0.5618)	Prec@1 78.906 (80.440)	Prec@5 99.219 (99.047)	Acc 0.804 (0.807)	
TRAINING - Epoch: [10][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.4899 (0.5585)	Prec@1 81.445 (80.476)	Prec@5 99.609 (99.054)	Acc 0.805 (0.807)	
TRAINING - Epoch: [10][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.4815 (0.5564)	Prec@1 83.398 (80.507)	Prec@5 99.805 (99.091)	Acc 0.805 (0.806)	
TRAINING - Epoch: [10][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.4638 (0.5547)	Prec@1 83.789 (80.598)	Prec@5 99.414 (99.111)	Acc 0.806 (0.806)	
TRAINING - Epoch: [10][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.4916 (0.5575)	Prec@1 82.422 (80.531)	Prec@5 98.828 (99.084)	Acc 0.805 (0.806)	
TRAINING - Epoch: [10][90/97]	Time 0.072 (0.081)	Data 0.000 (0.007)	Loss 0.6173 (0.5577)	Prec@1 78.125 (80.559)	Prec@5 98.438 (99.079)	Acc 0.806 (0.806)	
TRAINING - Epoch: [10][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.4893 (0.5564)	Prec@1 83.398 (80.577)	Prec@5 99.023 (99.078)	Acc 0.806 (0.806)	
EVALUATING - Epoch: [10][0/20]	Time 0.542 (0.542)	Data 0.526 (0.526)	Loss 0.8004 (0.8004)	Prec@1 72.656 (72.656)	Prec@5 99.219 (99.219)	Acc 0.727 (0.727)	
EVALUATING - Epoch: [10][10/20]	Time 0.016 (0.085)	Data 0.000 (0.069)	Loss 0.8924 (0.8495)	Prec@1 70.898 (72.230)	Prec@5 98.438 (98.491)	Acc 0.722 (0.726)	
EVALUATING - Epoch: [10][19/20]	Time 0.009 (0.054)	Data 0.000 (0.038)	Loss 0.8257 (0.8332)	Prec@1 72.426 (72.240)	Prec@5 98.162 (98.700)	Acc 0.722 (0.724)	

Results - Epoch: 11
Training Loss 0.5564 	Training Prec@1 80.577 	Training Prec@5 99.078 	Validation Loss 0.8332 	Validation Prec@1 72.240 	Validation Prec@5 98.700 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 12

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [11][0/97]	Time 0.718 (0.718)	Data 0.632 (0.632)	Loss 0.5172 (0.5172)	Prec@1 81.836 (81.836)	Prec@5 99.219 (99.219)	Acc 0.818 (0.818)	
TRAINING - Epoch: [11][10/97]	Time 0.073 (0.145)	Data 0.000 (0.069)	Loss 0.5437 (0.5432)	Prec@1 80.078 (80.487)	Prec@5 99.219 (99.343)	Acc 0.805 (0.808)	
TRAINING - Epoch: [11][20/97]	Time 0.073 (0.111)	Data 0.000 (0.036)	Loss 0.4581 (0.5349)	Prec@1 83.008 (80.980)	Prec@5 99.414 (99.182)	Acc 0.810 (0.808)	
TRAINING - Epoch: [11][30/97]	Time 0.073 (0.098)	Data 0.000 (0.024)	Loss 0.5018 (0.5318)	Prec@1 82.617 (81.036)	Prec@5 99.219 (99.162)	Acc 0.810 (0.808)	
TRAINING - Epoch: [11][40/97]	Time 0.073 (0.092)	Data 0.000 (0.019)	Loss 0.5360 (0.5229)	Prec@1 80.859 (81.469)	Prec@5 99.414 (99.195)	Acc 0.815 (0.810)	
TRAINING - Epoch: [11][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.4668 (0.5217)	Prec@1 84.375 (81.595)	Prec@5 99.414 (99.192)	Acc 0.816 (0.811)	
TRAINING - Epoch: [11][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.6177 (0.5228)	Prec@1 78.711 (81.625)	Prec@5 98.633 (99.168)	Acc 0.816 (0.812)	
TRAINING - Epoch: [11][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.5036 (0.5229)	Prec@1 81.641 (81.649)	Prec@5 98.828 (99.164)	Acc 0.816 (0.812)	
TRAINING - Epoch: [11][80/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.5311 (0.5217)	Prec@1 82.031 (81.730)	Prec@5 99.023 (99.175)	Acc 0.817 (0.813)	
TRAINING - Epoch: [11][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.4839 (0.5218)	Prec@1 83.594 (81.705)	Prec@5 99.414 (99.169)	Acc 0.817 (0.813)	
TRAINING - Epoch: [11][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.5455 (0.5227)	Prec@1 80.664 (81.677)	Prec@5 99.023 (99.162)	Acc 0.817 (0.813)	
EVALUATING - Epoch: [11][0/20]	Time 0.627 (0.627)	Data 0.611 (0.611)	Loss 0.7234 (0.7234)	Prec@1 77.930 (77.930)	Prec@5 98.828 (98.828)	Acc 0.779 (0.779)	
EVALUATING - Epoch: [11][10/20]	Time 0.016 (0.084)	Data 0.000 (0.065)	Loss 0.7498 (0.7617)	Prec@1 75.391 (75.941)	Prec@5 98.047 (98.384)	Acc 0.759 (0.763)	
EVALUATING - Epoch: [11][19/20]	Time 0.009 (0.053)	Data 0.000 (0.036)	Loss 0.7286 (0.7477)	Prec@1 77.574 (76.060)	Prec@5 98.897 (98.580)	Acc 0.761 (0.763)	

Results - Epoch: 12
Training Loss 0.5227 	Training Prec@1 81.677 	Training Prec@5 99.162 	Validation Loss 0.7477 	Validation Prec@1 76.060 	Validation Prec@5 98.580 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 13

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [12][0/97]	Time 0.786 (0.786)	Data 0.699 (0.699)	Loss 0.5281 (0.5281)	Prec@1 80.859 (80.859)	Prec@5 99.609 (99.609)	Acc 0.809 (0.809)	
TRAINING - Epoch: [12][10/97]	Time 0.073 (0.140)	Data 0.000 (0.064)	Loss 0.5156 (0.4959)	Prec@1 82.812 (82.706)	Prec@5 99.219 (99.396)	Acc 0.827 (0.821)	
TRAINING - Epoch: [12][20/97]	Time 0.073 (0.108)	Data 0.000 (0.034)	Loss 0.4920 (0.4916)	Prec@1 84.180 (83.166)	Prec@5 99.023 (99.293)	Acc 0.832 (0.825)	
TRAINING - Epoch: [12][30/97]	Time 0.073 (0.097)	Data 0.000 (0.023)	Loss 0.4820 (0.4885)	Prec@1 83.984 (83.285)	Prec@5 99.219 (99.294)	Acc 0.833 (0.827)	
TRAINING - Epoch: [12][40/97]	Time 0.073 (0.091)	Data 0.000 (0.017)	Loss 0.4863 (0.4875)	Prec@1 83.594 (83.213)	Prec@5 99.219 (99.324)	Acc 0.832 (0.828)	
TRAINING - Epoch: [12][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.5326 (0.4931)	Prec@1 82.227 (83.008)	Prec@5 98.828 (99.303)	Acc 0.830 (0.829)	
TRAINING - Epoch: [12][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.5394 (0.4899)	Prec@1 79.102 (83.094)	Prec@5 99.219 (99.292)	Acc 0.831 (0.829)	
TRAINING - Epoch: [12][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.5019 (0.4938)	Prec@1 81.836 (82.969)	Prec@5 99.023 (99.263)	Acc 0.830 (0.829)	
TRAINING - Epoch: [12][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.5123 (0.4928)	Prec@1 83.398 (82.996)	Prec@5 99.414 (99.262)	Acc 0.830 (0.829)	
TRAINING - Epoch: [12][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.4707 (0.4944)	Prec@1 84.180 (82.941)	Prec@5 98.828 (99.253)	Acc 0.829 (0.829)	
TRAINING - Epoch: [12][96/97]	Time 0.073 (0.080)	Data 0.000 (0.007)	Loss 0.4940 (0.4966)	Prec@1 82.422 (82.839)	Prec@5 99.414 (99.249)	Acc 0.828 (0.829)	
EVALUATING - Epoch: [12][0/20]	Time 0.654 (0.654)	Data 0.637 (0.637)	Loss 0.8334 (0.8334)	Prec@1 75.781 (75.781)	Prec@5 98.438 (98.438)	Acc 0.758 (0.758)	
EVALUATING - Epoch: [12][10/20]	Time 0.016 (0.083)	Data 0.000 (0.067)	Loss 0.8803 (0.8561)	Prec@1 75.195 (74.858)	Prec@5 97.656 (97.887)	Acc 0.749 (0.750)	
EVALUATING - Epoch: [12][19/20]	Time 0.009 (0.053)	Data 0.000 (0.037)	Loss 0.8301 (0.8604)	Prec@1 72.059 (74.310)	Prec@5 98.162 (98.080)	Acc 0.743 (0.748)	

Results - Epoch: 13
Training Loss 0.4966 	Training Prec@1 82.839 	Training Prec@5 99.249 	Validation Loss 0.8604 	Validation Prec@1 74.310 	Validation Prec@5 98.080 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 14

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [13][0/97]	Time 0.672 (0.672)	Data 0.592 (0.592)	Loss 0.4425 (0.4425)	Prec@1 83.008 (83.008)	Prec@5 99.414 (99.414)	Acc 0.830 (0.830)	
TRAINING - Epoch: [13][10/97]	Time 0.073 (0.142)	Data 0.000 (0.067)	Loss 0.4757 (0.4633)	Prec@1 84.766 (84.055)	Prec@5 99.023 (99.414)	Acc 0.841 (0.836)	
TRAINING - Epoch: [13][20/97]	Time 0.073 (0.109)	Data 0.000 (0.035)	Loss 0.4838 (0.4663)	Prec@1 83.789 (83.743)	Prec@5 99.219 (99.368)	Acc 0.837 (0.837)	
TRAINING - Epoch: [13][30/97]	Time 0.073 (0.097)	Data 0.000 (0.024)	Loss 0.5084 (0.4716)	Prec@1 84.180 (83.644)	Prec@5 98.242 (99.257)	Acc 0.836 (0.837)	
TRAINING - Epoch: [13][40/97]	Time 0.073 (0.091)	Data 0.000 (0.018)	Loss 0.4613 (0.4715)	Prec@1 82.031 (83.656)	Prec@5 99.219 (99.285)	Acc 0.837 (0.837)	
TRAINING - Epoch: [13][50/97]	Time 0.072 (0.088)	Data 0.000 (0.015)	Loss 0.5160 (0.4715)	Prec@1 80.273 (83.578)	Prec@5 99.414 (99.249)	Acc 0.836 (0.837)	
TRAINING - Epoch: [13][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.4987 (0.4767)	Prec@1 83.008 (83.398)	Prec@5 99.414 (99.257)	Acc 0.834 (0.836)	
TRAINING - Epoch: [13][70/97]	Time 0.073 (0.083)	Data 0.000 (0.011)	Loss 0.5488 (0.4798)	Prec@1 81.445 (83.299)	Prec@5 98.828 (99.235)	Acc 0.833 (0.836)	
TRAINING - Epoch: [13][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.5075 (0.4770)	Prec@1 82.422 (83.360)	Prec@5 99.609 (99.257)	Acc 0.834 (0.836)	
TRAINING - Epoch: [13][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.4445 (0.4769)	Prec@1 85.156 (83.351)	Prec@5 99.414 (99.262)	Acc 0.834 (0.835)	
TRAINING - Epoch: [13][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.4861 (0.4761)	Prec@1 82.031 (83.364)	Prec@5 99.609 (99.267)	Acc 0.834 (0.835)	
EVALUATING - Epoch: [13][0/20]	Time 0.589 (0.589)	Data 0.567 (0.567)	Loss 0.7054 (0.7054)	Prec@1 75.977 (75.977)	Prec@5 99.219 (99.219)	Acc 0.760 (0.760)	
EVALUATING - Epoch: [13][10/20]	Time 0.016 (0.081)	Data 0.000 (0.064)	Loss 0.7136 (0.7345)	Prec@1 75.195 (76.403)	Prec@5 99.414 (98.899)	Acc 0.764 (0.765)	
EVALUATING - Epoch: [13][19/20]	Time 0.009 (0.052)	Data 0.000 (0.036)	Loss 0.7249 (0.7142)	Prec@1 74.632 (76.660)	Prec@5 98.897 (99.050)	Acc 0.767 (0.765)	

Results - Epoch: 14
Training Loss 0.4761 	Training Prec@1 83.364 	Training Prec@5 99.267 	Validation Loss 0.7142 	Validation Prec@1 76.660 	Validation Prec@5 99.050 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 15

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [14][0/97]	Time 0.692 (0.692)	Data 0.607 (0.607)	Loss 0.4096 (0.4096)	Prec@1 84.375 (84.375)	Prec@5 99.805 (99.805)	Acc 0.844 (0.844)	
TRAINING - Epoch: [14][10/97]	Time 0.073 (0.138)	Data 0.000 (0.062)	Loss 0.4162 (0.4433)	Prec@1 84.375 (84.570)	Prec@5 99.219 (99.183)	Acc 0.846 (0.844)	
TRAINING - Epoch: [14][20/97]	Time 0.073 (0.107)	Data 0.000 (0.033)	Loss 0.4637 (0.4411)	Prec@1 83.789 (84.608)	Prec@5 99.023 (99.228)	Acc 0.846 (0.845)	
TRAINING - Epoch: [14][30/97]	Time 0.073 (0.096)	Data 0.000 (0.022)	Loss 0.3928 (0.4398)	Prec@1 86.719 (84.753)	Prec@5 99.219 (99.238)	Acc 0.848 (0.845)	
TRAINING - Epoch: [14][40/97]	Time 0.073 (0.090)	Data 0.000 (0.017)	Loss 0.4370 (0.4459)	Prec@1 84.570 (84.608)	Prec@5 99.609 (99.243)	Acc 0.846 (0.846)	
TRAINING - Epoch: [14][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.5438 (0.4529)	Prec@1 80.469 (84.505)	Prec@5 99.414 (99.200)	Acc 0.845 (0.846)	
TRAINING - Epoch: [14][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.4479 (0.4520)	Prec@1 84.180 (84.445)	Prec@5 99.414 (99.248)	Acc 0.844 (0.846)	
TRAINING - Epoch: [14][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.4311 (0.4501)	Prec@1 82.227 (84.403)	Prec@5 99.805 (99.277)	Acc 0.844 (0.845)	
TRAINING - Epoch: [14][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.4801 (0.4511)	Prec@1 82.422 (84.300)	Prec@5 99.609 (99.272)	Acc 0.843 (0.845)	
TRAINING - Epoch: [14][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.5236 (0.4535)	Prec@1 82.812 (84.263)	Prec@5 99.219 (99.260)	Acc 0.843 (0.845)	
TRAINING - Epoch: [14][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3829 (0.4536)	Prec@1 86.328 (84.252)	Prec@5 99.609 (99.261)	Acc 0.843 (0.845)	
EVALUATING - Epoch: [14][0/20]	Time 0.563 (0.563)	Data 0.546 (0.546)	Loss 0.9663 (0.9663)	Prec@1 74.219 (74.219)	Prec@5 98.242 (98.242)	Acc 0.742 (0.742)	
EVALUATING - Epoch: [14][10/20]	Time 0.016 (0.080)	Data 0.000 (0.062)	Loss 1.0344 (0.9770)	Prec@1 71.094 (73.065)	Prec@5 97.461 (97.514)	Acc 0.731 (0.733)	
EVALUATING - Epoch: [14][19/20]	Time 0.009 (0.051)	Data 0.000 (0.034)	Loss 1.1492 (0.9743)	Prec@1 68.015 (72.860)	Prec@5 96.691 (97.470)	Acc 0.729 (0.732)	

Results - Epoch: 15
Training Loss 0.4536 	Training Prec@1 84.252 	Training Prec@5 99.261 	Validation Loss 0.9743 	Validation Prec@1 72.860 	Validation Prec@5 97.470 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 16

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [15][0/97]	Time 0.789 (0.789)	Data 0.696 (0.696)	Loss 0.4649 (0.4649)	Prec@1 83.203 (83.203)	Prec@5 99.609 (99.609)	Acc 0.832 (0.832)	
TRAINING - Epoch: [15][10/97]	Time 0.073 (0.144)	Data 0.000 (0.063)	Loss 0.4524 (0.4425)	Prec@1 84.570 (84.375)	Prec@5 99.609 (99.414)	Acc 0.844 (0.843)	
TRAINING - Epoch: [15][20/97]	Time 0.073 (0.110)	Data 0.000 (0.033)	Loss 0.4447 (0.4456)	Prec@1 82.422 (84.319)	Prec@5 99.414 (99.423)	Acc 0.843 (0.843)	
TRAINING - Epoch: [15][30/97]	Time 0.073 (0.098)	Data 0.000 (0.023)	Loss 0.5196 (0.4538)	Prec@1 82.812 (83.997)	Prec@5 98.242 (99.357)	Acc 0.840 (0.843)	
TRAINING - Epoch: [15][40/97]	Time 0.073 (0.092)	Data 0.000 (0.017)	Loss 0.3992 (0.4484)	Prec@1 86.523 (84.280)	Prec@5 99.414 (99.343)	Acc 0.843 (0.842)	
TRAINING - Epoch: [15][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.4423 (0.4418)	Prec@1 84.570 (84.586)	Prec@5 99.219 (99.353)	Acc 0.846 (0.843)	
TRAINING - Epoch: [15][60/97]	Time 0.073 (0.086)	Data 0.000 (0.012)	Loss 0.4041 (0.4397)	Prec@1 86.523 (84.705)	Prec@5 99.805 (99.376)	Acc 0.847 (0.843)	
TRAINING - Epoch: [15][70/97]	Time 0.073 (0.084)	Data 0.000 (0.010)	Loss 0.3980 (0.4374)	Prec@1 87.305 (84.829)	Prec@5 99.805 (99.370)	Acc 0.848 (0.844)	
TRAINING - Epoch: [15][80/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.4512 (0.4351)	Prec@1 84.375 (84.840)	Prec@5 99.219 (99.395)	Acc 0.848 (0.845)	
TRAINING - Epoch: [15][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.4515 (0.4356)	Prec@1 84.570 (84.879)	Prec@5 99.414 (99.408)	Acc 0.849 (0.845)	
TRAINING - Epoch: [15][96/97]	Time 0.072 (0.081)	Data 0.000 (0.007)	Loss 0.3866 (0.4347)	Prec@1 87.109 (84.919)	Prec@5 100.000 (99.402)	Acc 0.849 (0.845)	
EVALUATING - Epoch: [15][0/20]	Time 0.776 (0.776)	Data 0.758 (0.758)	Loss 0.7654 (0.7654)	Prec@1 77.344 (77.344)	Prec@5 99.219 (99.219)	Acc 0.773 (0.773)	
EVALUATING - Epoch: [15][10/20]	Time 0.016 (0.085)	Data 0.000 (0.069)	Loss 0.7948 (0.7903)	Prec@1 76.953 (77.060)	Prec@5 98.828 (98.651)	Acc 0.771 (0.771)	
EVALUATING - Epoch: [15][19/20]	Time 0.009 (0.054)	Data 0.000 (0.038)	Loss 0.8541 (0.7784)	Prec@1 73.897 (77.230)	Prec@5 98.529 (98.810)	Acc 0.772 (0.772)	

Results - Epoch: 16
Training Loss 0.4347 	Training Prec@1 84.919 	Training Prec@5 99.402 	Validation Loss 0.7784 	Validation Prec@1 77.230 	Validation Prec@5 98.810 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 17

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [16][0/97]	Time 0.704 (0.704)	Data 0.623 (0.623)	Loss 0.3949 (0.3949)	Prec@1 85.547 (85.547)	Prec@5 99.414 (99.414)	Acc 0.855 (0.855)	
TRAINING - Epoch: [16][10/97]	Time 0.073 (0.137)	Data 0.000 (0.062)	Loss 0.3668 (0.3964)	Prec@1 87.500 (85.849)	Prec@5 99.805 (99.538)	Acc 0.858 (0.858)	
TRAINING - Epoch: [16][20/97]	Time 0.073 (0.107)	Data 0.000 (0.033)	Loss 0.4317 (0.4051)	Prec@1 84.961 (85.770)	Prec@5 99.609 (99.535)	Acc 0.858 (0.859)	
TRAINING - Epoch: [16][30/97]	Time 0.073 (0.096)	Data 0.000 (0.022)	Loss 0.4389 (0.4124)	Prec@1 84.766 (85.427)	Prec@5 99.609 (99.546)	Acc 0.854 (0.858)	
TRAINING - Epoch: [16][40/97]	Time 0.073 (0.090)	Data 0.000 (0.017)	Loss 0.4265 (0.4163)	Prec@1 84.375 (85.366)	Prec@5 99.805 (99.486)	Acc 0.854 (0.857)	
TRAINING - Epoch: [16][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.4372 (0.4183)	Prec@1 84.570 (85.252)	Prec@5 98.828 (99.483)	Acc 0.853 (0.856)	
TRAINING - Epoch: [16][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.4253 (0.4209)	Prec@1 84.766 (85.259)	Prec@5 99.805 (99.462)	Acc 0.853 (0.855)	
TRAINING - Epoch: [16][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.3990 (0.4198)	Prec@1 84.961 (85.354)	Prec@5 99.023 (99.458)	Acc 0.854 (0.855)	
TRAINING - Epoch: [16][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.4687 (0.4207)	Prec@1 84.766 (85.364)	Prec@5 98.633 (99.433)	Acc 0.854 (0.855)	
TRAINING - Epoch: [16][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3685 (0.4203)	Prec@1 86.719 (85.343)	Prec@5 99.219 (99.444)	Acc 0.853 (0.855)	
TRAINING - Epoch: [16][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.4203 (0.4216)	Prec@1 84.375 (85.289)	Prec@5 100.000 (99.444)	Acc 0.853 (0.855)	
EVALUATING - Epoch: [16][0/20]	Time 0.538 (0.538)	Data 0.522 (0.522)	Loss 0.7476 (0.7476)	Prec@1 77.344 (77.344)	Prec@5 98.242 (98.242)	Acc 0.773 (0.773)	
EVALUATING - Epoch: [16][10/20]	Time 0.016 (0.081)	Data 0.000 (0.064)	Loss 0.8758 (0.8333)	Prec@1 72.852 (74.769)	Prec@5 99.414 (98.224)	Acc 0.748 (0.755)	
EVALUATING - Epoch: [16][19/20]	Time 0.009 (0.051)	Data 0.000 (0.036)	Loss 0.7715 (0.8144)	Prec@1 73.529 (74.840)	Prec@5 100.000 (98.410)	Acc 0.748 (0.752)	

Results - Epoch: 17
Training Loss 0.4216 	Training Prec@1 85.289 	Training Prec@5 99.444 	Validation Loss 0.8144 	Validation Prec@1 74.840 	Validation Prec@5 98.410 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 18

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [17][0/97]	Time 0.763 (0.763)	Data 0.686 (0.686)	Loss 0.3988 (0.3988)	Prec@1 86.914 (86.914)	Prec@5 99.023 (99.023)	Acc 0.869 (0.869)	
TRAINING - Epoch: [17][10/97]	Time 0.073 (0.141)	Data 0.000 (0.064)	Loss 0.4782 (0.4158)	Prec@1 83.984 (85.707)	Prec@5 99.023 (99.432)	Acc 0.857 (0.864)	
TRAINING - Epoch: [17][20/97]	Time 0.073 (0.108)	Data 0.000 (0.033)	Loss 0.3774 (0.4073)	Prec@1 87.109 (85.872)	Prec@5 99.023 (99.479)	Acc 0.859 (0.861)	
TRAINING - Epoch: [17][30/97]	Time 0.073 (0.097)	Data 0.000 (0.023)	Loss 0.3685 (0.4026)	Prec@1 87.500 (85.963)	Prec@5 99.805 (99.546)	Acc 0.860 (0.860)	
TRAINING - Epoch: [17][40/97]	Time 0.073 (0.091)	Data 0.000 (0.017)	Loss 0.3437 (0.4000)	Prec@1 88.477 (86.142)	Prec@5 99.805 (99.571)	Acc 0.861 (0.860)	
TRAINING - Epoch: [17][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.4100 (0.4038)	Prec@1 86.133 (86.018)	Prec@5 99.609 (99.548)	Acc 0.860 (0.860)	
TRAINING - Epoch: [17][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.3985 (0.4029)	Prec@1 85.742 (86.005)	Prec@5 99.414 (99.542)	Acc 0.860 (0.860)	
TRAINING - Epoch: [17][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.4262 (0.4029)	Prec@1 84.961 (86.006)	Prec@5 99.609 (99.543)	Acc 0.860 (0.860)	
TRAINING - Epoch: [17][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.4251 (0.4042)	Prec@1 84.570 (85.947)	Prec@5 99.219 (99.523)	Acc 0.859 (0.860)	
TRAINING - Epoch: [17][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3815 (0.4028)	Prec@1 86.523 (86.021)	Prec@5 99.805 (99.515)	Acc 0.860 (0.860)	
TRAINING - Epoch: [17][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.4649 (0.4053)	Prec@1 83.984 (85.919)	Prec@5 99.219 (99.517)	Acc 0.859 (0.860)	
EVALUATING - Epoch: [17][0/20]	Time 0.679 (0.679)	Data 0.662 (0.662)	Loss 0.8021 (0.8021)	Prec@1 76.953 (76.953)	Prec@5 99.023 (99.023)	Acc 0.770 (0.770)	
EVALUATING - Epoch: [17][10/20]	Time 0.016 (0.082)	Data 0.000 (0.060)	Loss 0.8224 (0.8141)	Prec@1 74.805 (75.568)	Prec@5 98.828 (98.793)	Acc 0.756 (0.757)	
EVALUATING - Epoch: [17][19/20]	Time 0.009 (0.052)	Data 0.000 (0.033)	Loss 0.9236 (0.8042)	Prec@1 71.691 (75.830)	Prec@5 99.632 (98.970)	Acc 0.758 (0.758)	

Results - Epoch: 18
Training Loss 0.4053 	Training Prec@1 85.919 	Training Prec@5 99.517 	Validation Loss 0.8042 	Validation Prec@1 75.830 	Validation Prec@5 98.970 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 19

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [18][0/97]	Time 0.675 (0.675)	Data 0.585 (0.585)	Loss 0.4045 (0.4045)	Prec@1 86.133 (86.133)	Prec@5 100.000 (100.000)	Acc 0.861 (0.861)	
TRAINING - Epoch: [18][10/97]	Time 0.073 (0.138)	Data 0.000 (0.058)	Loss 0.3487 (0.3860)	Prec@1 87.891 (86.861)	Prec@5 99.805 (99.609)	Acc 0.869 (0.866)	
TRAINING - Epoch: [18][20/97]	Time 0.073 (0.107)	Data 0.000 (0.030)	Loss 0.3703 (0.3940)	Prec@1 87.891 (86.598)	Prec@5 99.414 (99.498)	Acc 0.866 (0.866)	
TRAINING - Epoch: [18][30/97]	Time 0.073 (0.096)	Data 0.000 (0.021)	Loss 0.3603 (0.3888)	Prec@1 89.062 (86.801)	Prec@5 99.609 (99.540)	Acc 0.868 (0.866)	
TRAINING - Epoch: [18][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.4278 (0.3927)	Prec@1 85.547 (86.581)	Prec@5 99.219 (99.490)	Acc 0.866 (0.867)	
TRAINING - Epoch: [18][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.4220 (0.3908)	Prec@1 83.984 (86.546)	Prec@5 99.609 (99.494)	Acc 0.865 (0.866)	
TRAINING - Epoch: [18][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.3611 (0.3914)	Prec@1 86.133 (86.482)	Prec@5 99.805 (99.501)	Acc 0.865 (0.866)	
TRAINING - Epoch: [18][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.4112 (0.3952)	Prec@1 84.961 (86.394)	Prec@5 99.414 (99.477)	Acc 0.864 (0.866)	
TRAINING - Epoch: [18][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.3069 (0.3934)	Prec@1 89.844 (86.449)	Prec@5 99.609 (99.453)	Acc 0.864 (0.866)	
TRAINING - Epoch: [18][90/97]	Time 0.073 (0.081)	Data 0.000 (0.007)	Loss 0.3674 (0.3935)	Prec@1 85.547 (86.435)	Prec@5 99.805 (99.463)	Acc 0.864 (0.866)	
TRAINING - Epoch: [18][96/97]	Time 0.073 (0.080)	Data 0.000 (0.007)	Loss 0.3816 (0.3925)	Prec@1 85.938 (86.445)	Prec@5 100.000 (99.474)	Acc 0.864 (0.865)	
EVALUATING - Epoch: [18][0/20]	Time 0.591 (0.591)	Data 0.570 (0.570)	Loss 0.6549 (0.6549)	Prec@1 78.125 (78.125)	Prec@5 99.023 (99.023)	Acc 0.781 (0.781)	
EVALUATING - Epoch: [18][10/20]	Time 0.016 (0.087)	Data 0.000 (0.069)	Loss 0.7215 (0.6930)	Prec@1 76.367 (78.445)	Prec@5 98.438 (98.509)	Acc 0.784 (0.787)	
EVALUATING - Epoch: [18][19/20]	Time 0.009 (0.055)	Data 0.000 (0.038)	Loss 0.6971 (0.6793)	Prec@1 76.838 (78.780)	Prec@5 98.897 (98.630)	Acc 0.788 (0.786)	

Results - Epoch: 19
Training Loss 0.3925 	Training Prec@1 86.445 	Training Prec@5 99.474 	Validation Loss 0.6793 	Validation Prec@1 78.780 	Validation Prec@5 98.630 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 20

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [19][0/97]	Time 0.812 (0.812)	Data 0.728 (0.728)	Loss 0.3438 (0.3438)	Prec@1 87.695 (87.695)	Prec@5 99.805 (99.805)	Acc 0.877 (0.877)	
TRAINING - Epoch: [19][10/97]	Time 0.073 (0.145)	Data 0.000 (0.066)	Loss 0.3805 (0.3719)	Prec@1 87.109 (86.932)	Prec@5 99.609 (99.716)	Acc 0.869 (0.875)	
TRAINING - Epoch: [19][20/97]	Time 0.073 (0.110)	Data 0.000 (0.035)	Loss 0.3531 (0.3706)	Prec@1 87.891 (87.044)	Prec@5 99.219 (99.637)	Acc 0.870 (0.873)	
TRAINING - Epoch: [19][30/97]	Time 0.073 (0.098)	Data 0.000 (0.024)	Loss 0.3375 (0.3715)	Prec@1 87.109 (87.216)	Prec@5 99.805 (99.590)	Acc 0.872 (0.872)	
TRAINING - Epoch: [19][40/97]	Time 0.072 (0.092)	Data 0.000 (0.018)	Loss 0.3296 (0.3709)	Prec@1 89.062 (87.238)	Prec@5 99.805 (99.595)	Acc 0.872 (0.872)	
TRAINING - Epoch: [19][50/97]	Time 0.072 (0.088)	Data 0.000 (0.014)	Loss 0.3907 (0.3679)	Prec@1 86.914 (87.374)	Prec@5 99.219 (99.571)	Acc 0.874 (0.872)	
TRAINING - Epoch: [19][60/97]	Time 0.072 (0.086)	Data 0.000 (0.012)	Loss 0.3454 (0.3662)	Prec@1 87.695 (87.385)	Prec@5 100.000 (99.574)	Acc 0.874 (0.873)	
TRAINING - Epoch: [19][70/97]	Time 0.072 (0.084)	Data 0.000 (0.010)	Loss 0.3694 (0.3676)	Prec@1 85.547 (87.324)	Prec@5 99.219 (99.552)	Acc 0.873 (0.873)	
TRAINING - Epoch: [19][80/97]	Time 0.072 (0.082)	Data 0.000 (0.009)	Loss 0.3273 (0.3702)	Prec@1 89.453 (87.256)	Prec@5 99.414 (99.539)	Acc 0.873 (0.873)	
TRAINING - Epoch: [19][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3795 (0.3719)	Prec@1 86.523 (87.178)	Prec@5 99.609 (99.534)	Acc 0.872 (0.873)	
TRAINING - Epoch: [19][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3542 (0.3732)	Prec@1 87.695 (87.132)	Prec@5 99.805 (99.539)	Acc 0.871 (0.873)	
EVALUATING - Epoch: [19][0/20]	Time 0.445 (0.445)	Data 0.429 (0.429)	Loss 0.6005 (0.6005)	Prec@1 81.250 (81.250)	Prec@5 99.414 (99.414)	Acc 0.812 (0.812)	
EVALUATING - Epoch: [19][10/20]	Time 0.016 (0.082)	Data 0.000 (0.065)	Loss 0.6696 (0.6484)	Prec@1 80.664 (79.776)	Prec@5 98.242 (98.722)	Acc 0.798 (0.800)	
EVALUATING - Epoch: [19][19/20]	Time 0.009 (0.052)	Data 0.000 (0.036)	Loss 0.7149 (0.6251)	Prec@1 77.941 (80.130)	Prec@5 98.529 (98.850)	Acc 0.801 (0.800)	

Results - Epoch: 20
Training Loss 0.3732 	Training Prec@1 87.132 	Training Prec@5 99.539 	Validation Loss 0.6251 	Validation Prec@1 80.130 	Validation Prec@5 98.850 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 21

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [20][0/97]	Time 0.667 (0.667)	Data 0.564 (0.564)	Loss 0.3512 (0.3512)	Prec@1 87.891 (87.891)	Prec@5 99.219 (99.219)	Acc 0.879 (0.879)	
TRAINING - Epoch: [20][10/97]	Time 0.073 (0.139)	Data 0.000 (0.060)	Loss 0.3486 (0.3591)	Prec@1 86.133 (87.482)	Prec@5 99.609 (99.467)	Acc 0.875 (0.876)	
TRAINING - Epoch: [20][20/97]	Time 0.073 (0.107)	Data 0.000 (0.031)	Loss 0.3681 (0.3561)	Prec@1 87.695 (87.528)	Prec@5 99.609 (99.600)	Acc 0.875 (0.876)	
TRAINING - Epoch: [20][30/97]	Time 0.073 (0.096)	Data 0.000 (0.021)	Loss 0.3303 (0.3530)	Prec@1 88.086 (87.620)	Prec@5 99.805 (99.635)	Acc 0.876 (0.876)	
TRAINING - Epoch: [20][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.4451 (0.3551)	Prec@1 82.812 (87.629)	Prec@5 99.609 (99.614)	Acc 0.876 (0.876)	
TRAINING - Epoch: [20][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.4125 (0.3608)	Prec@1 86.328 (87.397)	Prec@5 99.805 (99.617)	Acc 0.874 (0.876)	
TRAINING - Epoch: [20][60/97]	Time 0.072 (0.085)	Data 0.000 (0.011)	Loss 0.3109 (0.3630)	Prec@1 89.648 (87.308)	Prec@5 99.414 (99.606)	Acc 0.873 (0.875)	
TRAINING - Epoch: [20][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.3200 (0.3605)	Prec@1 89.453 (87.412)	Prec@5 100.000 (99.609)	Acc 0.874 (0.875)	
TRAINING - Epoch: [20][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.3275 (0.3628)	Prec@1 88.477 (87.317)	Prec@5 99.609 (99.597)	Acc 0.873 (0.875)	
TRAINING - Epoch: [20][90/97]	Time 0.072 (0.081)	Data 0.000 (0.007)	Loss 0.3392 (0.3610)	Prec@1 87.695 (87.367)	Prec@5 99.414 (99.599)	Acc 0.874 (0.875)	
TRAINING - Epoch: [20][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3624 (0.3613)	Prec@1 87.500 (87.351)	Prec@5 99.414 (99.587)	Acc 0.874 (0.875)	
EVALUATING - Epoch: [20][0/20]	Time 0.720 (0.720)	Data 0.694 (0.694)	Loss 0.6709 (0.6709)	Prec@1 78.711 (78.711)	Prec@5 99.414 (99.414)	Acc 0.787 (0.787)	
EVALUATING - Epoch: [20][10/20]	Time 0.016 (0.084)	Data 0.000 (0.064)	Loss 0.6776 (0.6577)	Prec@1 78.906 (79.492)	Prec@5 99.023 (98.793)	Acc 0.795 (0.790)	
EVALUATING - Epoch: [20][19/20]	Time 0.009 (0.053)	Data 0.000 (0.035)	Loss 0.6933 (0.6431)	Prec@1 80.882 (80.010)	Prec@5 99.265 (98.840)	Acc 0.800 (0.794)	

Results - Epoch: 21
Training Loss 0.3613 	Training Prec@1 87.351 	Training Prec@5 99.587 	Validation Loss 0.6431 	Validation Prec@1 80.010 	Validation Prec@5 98.840 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 22

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [21][0/97]	Time 0.737 (0.737)	Data 0.635 (0.635)	Loss 0.3704 (0.3704)	Prec@1 86.719 (86.719)	Prec@5 99.805 (99.805)	Acc 0.867 (0.867)	
TRAINING - Epoch: [21][10/97]	Time 0.073 (0.142)	Data 0.000 (0.064)	Loss 0.3823 (0.3349)	Prec@1 86.328 (88.406)	Prec@5 99.805 (99.645)	Acc 0.884 (0.880)	
TRAINING - Epoch: [21][20/97]	Time 0.073 (0.109)	Data 0.000 (0.034)	Loss 0.3243 (0.3378)	Prec@1 88.672 (88.207)	Prec@5 99.805 (99.637)	Acc 0.882 (0.882)	
TRAINING - Epoch: [21][30/97]	Time 0.073 (0.097)	Data 0.000 (0.023)	Loss 0.3917 (0.3444)	Prec@1 85.156 (88.080)	Prec@5 99.805 (99.622)	Acc 0.881 (0.882)	
TRAINING - Epoch: [21][40/97]	Time 0.073 (0.091)	Data 0.000 (0.017)	Loss 0.3623 (0.3441)	Prec@1 87.695 (88.062)	Prec@5 99.609 (99.643)	Acc 0.881 (0.881)	
TRAINING - Epoch: [21][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.3366 (0.3467)	Prec@1 87.500 (87.925)	Prec@5 99.805 (99.655)	Acc 0.879 (0.881)	
TRAINING - Epoch: [21][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.4163 (0.3513)	Prec@1 85.938 (87.782)	Prec@5 99.219 (99.625)	Acc 0.878 (0.881)	
TRAINING - Epoch: [21][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2784 (0.3487)	Prec@1 88.867 (87.833)	Prec@5 99.805 (99.634)	Acc 0.878 (0.880)	
TRAINING - Epoch: [21][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.3089 (0.3508)	Prec@1 88.867 (87.664)	Prec@5 99.805 (99.629)	Acc 0.877 (0.880)	
TRAINING - Epoch: [21][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3954 (0.3538)	Prec@1 87.500 (87.569)	Prec@5 99.219 (99.616)	Acc 0.876 (0.879)	
TRAINING - Epoch: [21][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3286 (0.3534)	Prec@1 88.672 (87.583)	Prec@5 99.414 (99.613)	Acc 0.876 (0.879)	
EVALUATING - Epoch: [21][0/20]	Time 0.518 (0.518)	Data 0.498 (0.498)	Loss 0.6219 (0.6219)	Prec@1 80.273 (80.273)	Prec@5 99.805 (99.805)	Acc 0.803 (0.803)	
EVALUATING - Epoch: [21][10/20]	Time 0.016 (0.083)	Data 0.000 (0.063)	Loss 0.6988 (0.6797)	Prec@1 78.711 (78.161)	Prec@5 98.828 (98.917)	Acc 0.782 (0.787)	
EVALUATING - Epoch: [21][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.7142 (0.6614)	Prec@1 79.412 (78.570)	Prec@5 99.632 (99.130)	Acc 0.786 (0.787)	

Results - Epoch: 22
Training Loss 0.3534 	Training Prec@1 87.583 	Training Prec@5 99.613 	Validation Loss 0.6614 	Validation Prec@1 78.570 	Validation Prec@5 99.130 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 23

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [22][0/97]	Time 0.755 (0.755)	Data 0.658 (0.658)	Loss 0.3204 (0.3204)	Prec@1 88.477 (88.477)	Prec@5 99.609 (99.609)	Acc 0.885 (0.885)	
TRAINING - Epoch: [22][10/97]	Time 0.073 (0.144)	Data 0.000 (0.067)	Loss 0.3364 (0.3287)	Prec@1 88.672 (89.080)	Prec@5 99.414 (99.627)	Acc 0.891 (0.889)	
TRAINING - Epoch: [22][20/97]	Time 0.073 (0.110)	Data 0.000 (0.035)	Loss 0.3353 (0.3324)	Prec@1 89.453 (88.839)	Prec@5 100.000 (99.656)	Acc 0.888 (0.889)	
TRAINING - Epoch: [22][30/97]	Time 0.073 (0.098)	Data 0.000 (0.024)	Loss 0.3534 (0.3387)	Prec@1 86.719 (88.483)	Prec@5 99.609 (99.653)	Acc 0.885 (0.888)	
TRAINING - Epoch: [22][40/97]	Time 0.073 (0.092)	Data 0.000 (0.018)	Loss 0.3545 (0.3394)	Prec@1 86.523 (88.329)	Prec@5 100.000 (99.643)	Acc 0.883 (0.887)	
TRAINING - Epoch: [22][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.3467 (0.3389)	Prec@1 89.258 (88.297)	Prec@5 100.000 (99.674)	Acc 0.883 (0.886)	
TRAINING - Epoch: [22][60/97]	Time 0.073 (0.086)	Data 0.000 (0.012)	Loss 0.3269 (0.3376)	Prec@1 88.477 (88.390)	Prec@5 99.805 (99.689)	Acc 0.884 (0.886)	
TRAINING - Epoch: [22][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.3896 (0.3373)	Prec@1 86.523 (88.345)	Prec@5 99.414 (99.689)	Acc 0.883 (0.886)	
TRAINING - Epoch: [22][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.3225 (0.3391)	Prec@1 87.891 (88.245)	Prec@5 100.000 (99.665)	Acc 0.882 (0.885)	
TRAINING - Epoch: [22][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3520 (0.3402)	Prec@1 88.281 (88.178)	Prec@5 99.805 (99.661)	Acc 0.882 (0.885)	
TRAINING - Epoch: [22][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3945 (0.3416)	Prec@1 87.305 (88.160)	Prec@5 99.609 (99.662)	Acc 0.882 (0.885)	
EVALUATING - Epoch: [22][0/20]	Time 0.572 (0.572)	Data 0.553 (0.553)	Loss 0.5543 (0.5543)	Prec@1 82.031 (82.031)	Prec@5 99.414 (99.414)	Acc 0.820 (0.820)	
EVALUATING - Epoch: [22][10/20]	Time 0.016 (0.080)	Data 0.000 (0.062)	Loss 0.5837 (0.5747)	Prec@1 82.227 (82.262)	Prec@5 99.023 (98.988)	Acc 0.823 (0.822)	
EVALUATING - Epoch: [22][19/20]	Time 0.009 (0.051)	Data 0.000 (0.034)	Loss 0.5528 (0.5738)	Prec@1 80.147 (81.800)	Prec@5 99.265 (99.100)	Acc 0.818 (0.821)	

Results - Epoch: 23
Training Loss 0.3416 	Training Prec@1 88.160 	Training Prec@5 99.662 	Validation Loss 0.5738 	Validation Prec@1 81.800 	Validation Prec@5 99.100 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 24

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [23][0/97]	Time 0.650 (0.650)	Data 0.554 (0.554)	Loss 0.3905 (0.3905)	Prec@1 86.328 (86.328)	Prec@5 100.000 (100.000)	Acc 0.863 (0.863)	
TRAINING - Epoch: [23][10/97]	Time 0.073 (0.149)	Data 0.000 (0.074)	Loss 0.3604 (0.3341)	Prec@1 87.500 (88.583)	Prec@5 99.414 (99.663)	Acc 0.886 (0.882)	
TRAINING - Epoch: [23][20/97]	Time 0.073 (0.113)	Data 0.000 (0.039)	Loss 0.3915 (0.3462)	Prec@1 84.961 (87.946)	Prec@5 99.609 (99.665)	Acc 0.879 (0.882)	
TRAINING - Epoch: [23][30/97]	Time 0.073 (0.100)	Data 0.000 (0.027)	Loss 0.3764 (0.3459)	Prec@1 86.133 (87.872)	Prec@5 100.000 (99.691)	Acc 0.879 (0.881)	
TRAINING - Epoch: [23][40/97]	Time 0.073 (0.093)	Data 0.000 (0.020)	Loss 0.3239 (0.3418)	Prec@1 89.258 (88.062)	Prec@5 99.805 (99.695)	Acc 0.881 (0.881)	
TRAINING - Epoch: [23][50/97]	Time 0.073 (0.089)	Data 0.000 (0.016)	Loss 0.3924 (0.3373)	Prec@1 88.672 (88.281)	Prec@5 99.023 (99.686)	Acc 0.883 (0.881)	
TRAINING - Epoch: [23][60/97]	Time 0.072 (0.086)	Data 0.000 (0.014)	Loss 0.3365 (0.3339)	Prec@1 87.891 (88.352)	Prec@5 99.805 (99.696)	Acc 0.884 (0.881)	
TRAINING - Epoch: [23][70/97]	Time 0.073 (0.084)	Data 0.000 (0.012)	Loss 0.3039 (0.3310)	Prec@1 89.844 (88.449)	Prec@5 99.609 (99.697)	Acc 0.884 (0.882)	
TRAINING - Epoch: [23][80/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.3295 (0.3294)	Prec@1 89.258 (88.491)	Prec@5 99.805 (99.699)	Acc 0.885 (0.882)	
TRAINING - Epoch: [23][90/97]	Time 0.072 (0.082)	Data 0.000 (0.009)	Loss 0.2488 (0.3300)	Prec@1 91.406 (88.509)	Prec@5 99.805 (99.669)	Acc 0.885 (0.882)	
TRAINING - Epoch: [23][96/97]	Time 0.072 (0.081)	Data 0.000 (0.009)	Loss 0.3635 (0.3309)	Prec@1 87.305 (88.485)	Prec@5 100.000 (99.672)	Acc 0.885 (0.883)	
EVALUATING - Epoch: [23][0/20]	Time 0.570 (0.570)	Data 0.553 (0.553)	Loss 0.5940 (0.5940)	Prec@1 83.008 (83.008)	Prec@5 99.023 (99.023)	Acc 0.830 (0.830)	
EVALUATING - Epoch: [23][10/20]	Time 0.016 (0.082)	Data 0.000 (0.063)	Loss 0.5741 (0.5944)	Prec@1 80.859 (81.392)	Prec@5 99.414 (98.935)	Acc 0.814 (0.818)	
EVALUATING - Epoch: [23][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.5111 (0.5779)	Prec@1 83.088 (81.400)	Prec@5 99.632 (99.160)	Acc 0.814 (0.816)	

Results - Epoch: 24
Training Loss 0.3309 	Training Prec@1 88.485 	Training Prec@5 99.672 	Validation Loss 0.5779 	Validation Prec@1 81.400 	Validation Prec@5 99.160 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 25

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [24][0/97]	Time 0.621 (0.621)	Data 0.537 (0.537)	Loss 0.2803 (0.2803)	Prec@1 91.406 (91.406)	Prec@5 99.609 (99.609)	Acc 0.914 (0.914)	
TRAINING - Epoch: [24][10/97]	Time 0.073 (0.137)	Data 0.000 (0.059)	Loss 0.2936 (0.3124)	Prec@1 90.234 (89.045)	Prec@5 100.000 (99.751)	Acc 0.890 (0.892)	
TRAINING - Epoch: [24][20/97]	Time 0.073 (0.106)	Data 0.000 (0.031)	Loss 0.2933 (0.2994)	Prec@1 90.234 (89.472)	Prec@5 100.000 (99.795)	Acc 0.895 (0.893)	
TRAINING - Epoch: [24][30/97]	Time 0.073 (0.095)	Data 0.000 (0.021)	Loss 0.2811 (0.3043)	Prec@1 91.016 (89.384)	Prec@5 99.219 (99.723)	Acc 0.894 (0.893)	
TRAINING - Epoch: [24][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.3076 (0.3078)	Prec@1 89.062 (89.215)	Prec@5 99.805 (99.719)	Acc 0.892 (0.893)	
TRAINING - Epoch: [24][50/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.2872 (0.3067)	Prec@1 91.211 (89.281)	Prec@5 99.805 (99.705)	Acc 0.893 (0.893)	
TRAINING - Epoch: [24][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.3378 (0.3097)	Prec@1 88.086 (89.197)	Prec@5 99.805 (99.709)	Acc 0.892 (0.893)	
TRAINING - Epoch: [24][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.3401 (0.3128)	Prec@1 88.281 (89.120)	Prec@5 99.414 (99.689)	Acc 0.891 (0.893)	
TRAINING - Epoch: [24][80/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.3718 (0.3164)	Prec@1 87.695 (89.007)	Prec@5 99.805 (99.667)	Acc 0.890 (0.892)	
TRAINING - Epoch: [24][90/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3009 (0.3177)	Prec@1 89.648 (88.938)	Prec@5 99.805 (99.642)	Acc 0.889 (0.892)	
TRAINING - Epoch: [24][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3061 (0.3177)	Prec@1 90.039 (88.934)	Prec@5 99.609 (99.638)	Acc 0.889 (0.892)	
EVALUATING - Epoch: [24][0/20]	Time 0.616 (0.616)	Data 0.600 (0.600)	Loss 0.4317 (0.4317)	Prec@1 85.352 (85.352)	Prec@5 99.805 (99.805)	Acc 0.854 (0.854)	
EVALUATING - Epoch: [24][10/20]	Time 0.016 (0.082)	Data 0.000 (0.064)	Loss 0.5123 (0.4915)	Prec@1 81.836 (84.215)	Prec@5 99.414 (99.272)	Acc 0.842 (0.844)	
EVALUATING - Epoch: [24][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.5094 (0.4853)	Prec@1 82.353 (84.380)	Prec@5 100.000 (99.420)	Acc 0.844 (0.844)	

Results - Epoch: 25
Training Loss 0.3177 	Training Prec@1 88.934 	Training Prec@5 99.638 	Validation Loss 0.4853 	Validation Prec@1 84.380 	Validation Prec@5 99.420 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 26

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [25][0/97]	Time 0.683 (0.683)	Data 0.608 (0.608)	Loss 0.2873 (0.2873)	Prec@1 91.016 (91.016)	Prec@5 99.609 (99.609)	Acc 0.910 (0.910)	
TRAINING - Epoch: [25][10/97]	Time 0.073 (0.144)	Data 0.000 (0.066)	Loss 0.3174 (0.3035)	Prec@1 89.844 (89.151)	Prec@5 100.000 (99.805)	Acc 0.892 (0.893)	
TRAINING - Epoch: [25][20/97]	Time 0.073 (0.110)	Data 0.000 (0.034)	Loss 0.2829 (0.2995)	Prec@1 89.453 (89.118)	Prec@5 100.000 (99.786)	Acc 0.891 (0.892)	
TRAINING - Epoch: [25][30/97]	Time 0.073 (0.098)	Data 0.000 (0.023)	Loss 0.2795 (0.2974)	Prec@1 89.648 (89.321)	Prec@5 99.609 (99.748)	Acc 0.893 (0.892)	
TRAINING - Epoch: [25][40/97]	Time 0.073 (0.092)	Data 0.000 (0.018)	Loss 0.3318 (0.2995)	Prec@1 87.695 (89.210)	Prec@5 99.805 (99.743)	Acc 0.892 (0.892)	
TRAINING - Epoch: [25][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.3573 (0.2994)	Prec@1 86.133 (89.300)	Prec@5 99.609 (99.728)	Acc 0.893 (0.893)	
TRAINING - Epoch: [25][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.3274 (0.3013)	Prec@1 89.258 (89.303)	Prec@5 99.609 (99.721)	Acc 0.893 (0.893)	
TRAINING - Epoch: [25][70/97]	Time 0.073 (0.084)	Data 0.000 (0.010)	Loss 0.3245 (0.3035)	Prec@1 89.258 (89.261)	Prec@5 99.609 (99.697)	Acc 0.893 (0.893)	
TRAINING - Epoch: [25][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.3779 (0.3096)	Prec@1 87.305 (89.132)	Prec@5 99.609 (99.689)	Acc 0.891 (0.893)	
TRAINING - Epoch: [25][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3150 (0.3123)	Prec@1 89.648 (88.996)	Prec@5 99.609 (99.684)	Acc 0.890 (0.892)	
TRAINING - Epoch: [25][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.4006 (0.3146)	Prec@1 86.914 (88.956)	Prec@5 99.609 (99.688)	Acc 0.890 (0.892)	
EVALUATING - Epoch: [25][0/20]	Time 0.645 (0.645)	Data 0.626 (0.626)	Loss 0.4409 (0.4409)	Prec@1 84.375 (84.375)	Prec@5 99.805 (99.805)	Acc 0.844 (0.844)	
EVALUATING - Epoch: [25][10/20]	Time 0.016 (0.080)	Data 0.000 (0.061)	Loss 0.5249 (0.5221)	Prec@1 81.836 (83.079)	Prec@5 99.805 (99.130)	Acc 0.831 (0.835)	
EVALUATING - Epoch: [25][19/20]	Time 0.009 (0.051)	Data 0.000 (0.034)	Loss 0.4785 (0.5065)	Prec@1 83.824 (83.340)	Prec@5 100.000 (99.270)	Acc 0.833 (0.834)	

Results - Epoch: 26
Training Loss 0.3146 	Training Prec@1 88.956 	Training Prec@5 99.688 	Validation Loss 0.5065 	Validation Prec@1 83.340 	Validation Prec@5 99.270 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 27

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [26][0/97]	Time 0.659 (0.659)	Data 0.569 (0.569)	Loss 0.2782 (0.2782)	Prec@1 90.234 (90.234)	Prec@5 99.609 (99.609)	Acc 0.902 (0.902)	
TRAINING - Epoch: [26][10/97]	Time 0.073 (0.144)	Data 0.000 (0.065)	Loss 0.3151 (0.3075)	Prec@1 88.672 (88.832)	Prec@5 99.609 (99.769)	Acc 0.888 (0.886)	
TRAINING - Epoch: [26][20/97]	Time 0.073 (0.110)	Data 0.000 (0.034)	Loss 0.2969 (0.3038)	Prec@1 90.039 (89.193)	Prec@5 99.805 (99.777)	Acc 0.892 (0.888)	
TRAINING - Epoch: [26][30/97]	Time 0.073 (0.098)	Data 0.000 (0.023)	Loss 0.4009 (0.3046)	Prec@1 85.547 (89.252)	Prec@5 99.414 (99.779)	Acc 0.893 (0.890)	
TRAINING - Epoch: [26][40/97]	Time 0.073 (0.092)	Data 0.000 (0.017)	Loss 0.3795 (0.3026)	Prec@1 86.328 (89.353)	Prec@5 99.609 (99.762)	Acc 0.894 (0.891)	
TRAINING - Epoch: [26][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.3401 (0.3024)	Prec@1 89.258 (89.484)	Prec@5 100.000 (99.743)	Acc 0.895 (0.891)	
TRAINING - Epoch: [26][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.3394 (0.3014)	Prec@1 89.258 (89.568)	Prec@5 99.609 (99.718)	Acc 0.896 (0.892)	
TRAINING - Epoch: [26][70/97]	Time 0.073 (0.084)	Data 0.000 (0.010)	Loss 0.2756 (0.3042)	Prec@1 89.844 (89.445)	Prec@5 99.805 (99.722)	Acc 0.894 (0.892)	
TRAINING - Epoch: [26][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.2982 (0.3034)	Prec@1 89.258 (89.511)	Prec@5 99.609 (99.723)	Acc 0.895 (0.893)	
TRAINING - Epoch: [26][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3302 (0.3027)	Prec@1 88.477 (89.567)	Prec@5 99.805 (99.706)	Acc 0.896 (0.893)	
TRAINING - Epoch: [26][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3024 (0.3027)	Prec@1 89.648 (89.584)	Prec@5 99.805 (99.698)	Acc 0.896 (0.893)	
EVALUATING - Epoch: [26][0/20]	Time 0.591 (0.591)	Data 0.574 (0.574)	Loss 0.5575 (0.5575)	Prec@1 81.250 (81.250)	Prec@5 99.414 (99.414)	Acc 0.812 (0.812)	
EVALUATING - Epoch: [26][10/20]	Time 0.016 (0.081)	Data 0.000 (0.059)	Loss 0.5755 (0.6256)	Prec@1 82.617 (82.156)	Prec@5 98.828 (98.935)	Acc 0.822 (0.820)	
EVALUATING - Epoch: [26][19/20]	Time 0.009 (0.051)	Data 0.000 (0.032)	Loss 0.7414 (0.6182)	Prec@1 80.147 (82.200)	Prec@5 99.632 (99.120)	Acc 0.822 (0.821)	

Results - Epoch: 27
Training Loss 0.3027 	Training Prec@1 89.584 	Training Prec@5 99.698 	Validation Loss 0.6182 	Validation Prec@1 82.200 	Validation Prec@5 99.120 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 28

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [27][0/97]	Time 0.754 (0.754)	Data 0.653 (0.653)	Loss 0.2855 (0.2855)	Prec@1 90.039 (90.039)	Prec@5 99.609 (99.609)	Acc 0.900 (0.900)	
TRAINING - Epoch: [27][10/97]	Time 0.073 (0.142)	Data 0.000 (0.060)	Loss 0.2522 (0.2785)	Prec@1 91.016 (90.234)	Prec@5 99.414 (99.716)	Acc 0.902 (0.900)	
TRAINING - Epoch: [27][20/97]	Time 0.073 (0.109)	Data 0.000 (0.032)	Loss 0.3178 (0.2862)	Prec@1 89.844 (89.927)	Prec@5 99.414 (99.684)	Acc 0.899 (0.901)	
TRAINING - Epoch: [27][30/97]	Time 0.073 (0.097)	Data 0.000 (0.021)	Loss 0.2476 (0.2865)	Prec@1 91.797 (89.982)	Prec@5 100.000 (99.729)	Acc 0.900 (0.900)	
TRAINING - Epoch: [27][40/97]	Time 0.073 (0.091)	Data 0.000 (0.016)	Loss 0.3018 (0.2902)	Prec@1 88.281 (89.901)	Prec@5 99.805 (99.733)	Acc 0.899 (0.900)	
TRAINING - Epoch: [27][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.3292 (0.2908)	Prec@1 87.891 (89.859)	Prec@5 100.000 (99.763)	Acc 0.899 (0.900)	
TRAINING - Epoch: [27][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.3289 (0.2900)	Prec@1 87.305 (89.831)	Prec@5 99.414 (99.763)	Acc 0.898 (0.900)	
TRAINING - Epoch: [27][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.2685 (0.2924)	Prec@1 89.844 (89.720)	Prec@5 100.000 (99.750)	Acc 0.897 (0.899)	
TRAINING - Epoch: [27][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.2508 (0.2918)	Prec@1 91.016 (89.711)	Prec@5 99.805 (99.759)	Acc 0.897 (0.899)	
TRAINING - Epoch: [27][90/97]	Time 0.073 (0.081)	Data 0.000 (0.007)	Loss 0.2852 (0.2925)	Prec@1 90.625 (89.702)	Prec@5 98.828 (99.755)	Acc 0.897 (0.899)	
TRAINING - Epoch: [27][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3161 (0.2921)	Prec@1 89.258 (89.731)	Prec@5 99.414 (99.746)	Acc 0.897 (0.899)	
EVALUATING - Epoch: [27][0/20]	Time 0.545 (0.545)	Data 0.528 (0.528)	Loss 0.4898 (0.4898)	Prec@1 86.133 (86.133)	Prec@5 98.828 (98.828)	Acc 0.861 (0.861)	
EVALUATING - Epoch: [27][10/20]	Time 0.016 (0.082)	Data 0.000 (0.064)	Loss 0.4710 (0.5245)	Prec@1 84.766 (83.771)	Prec@5 99.219 (98.793)	Acc 0.838 (0.844)	
EVALUATING - Epoch: [27][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.5450 (0.5204)	Prec@1 86.029 (83.850)	Prec@5 100.000 (99.060)	Acc 0.839 (0.841)	

Results - Epoch: 28
Training Loss 0.2921 	Training Prec@1 89.731 	Training Prec@5 99.746 	Validation Loss 0.5204 	Validation Prec@1 83.850 	Validation Prec@5 99.060 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 29

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [28][0/97]	Time 0.762 (0.762)	Data 0.662 (0.662)	Loss 0.2772 (0.2772)	Prec@1 90.430 (90.430)	Prec@5 99.609 (99.609)	Acc 0.904 (0.904)	
TRAINING - Epoch: [28][10/97]	Time 0.073 (0.137)	Data 0.000 (0.060)	Loss 0.2339 (0.2601)	Prec@1 91.797 (91.300)	Prec@5 100.000 (99.769)	Acc 0.913 (0.912)	
TRAINING - Epoch: [28][20/97]	Time 0.072 (0.106)	Data 0.000 (0.032)	Loss 0.2944 (0.2706)	Prec@1 89.844 (90.848)	Prec@5 99.805 (99.805)	Acc 0.908 (0.911)	
TRAINING - Epoch: [28][30/97]	Time 0.073 (0.095)	Data 0.000 (0.022)	Loss 0.2864 (0.2750)	Prec@1 91.211 (90.638)	Prec@5 99.805 (99.817)	Acc 0.906 (0.910)	
TRAINING - Epoch: [28][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.3286 (0.2823)	Prec@1 88.672 (90.377)	Prec@5 99.805 (99.824)	Acc 0.904 (0.909)	
TRAINING - Epoch: [28][50/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.2198 (0.2814)	Prec@1 92.969 (90.349)	Prec@5 99.609 (99.793)	Acc 0.903 (0.908)	
TRAINING - Epoch: [28][60/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2844 (0.2844)	Prec@1 90.820 (90.231)	Prec@5 99.609 (99.776)	Acc 0.902 (0.907)	
TRAINING - Epoch: [28][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.3216 (0.2858)	Prec@1 87.109 (90.111)	Prec@5 99.414 (99.769)	Acc 0.901 (0.906)	
TRAINING - Epoch: [28][80/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.2809 (0.2847)	Prec@1 88.086 (90.131)	Prec@5 100.000 (99.776)	Acc 0.901 (0.905)	
TRAINING - Epoch: [28][90/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.2815 (0.2839)	Prec@1 89.844 (90.112)	Prec@5 100.000 (99.785)	Acc 0.901 (0.905)	
TRAINING - Epoch: [28][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.2925 (0.2857)	Prec@1 89.062 (90.059)	Prec@5 99.805 (99.772)	Acc 0.901 (0.905)	
EVALUATING - Epoch: [28][0/20]	Time 0.682 (0.682)	Data 0.665 (0.665)	Loss 0.6026 (0.6026)	Prec@1 81.445 (81.445)	Prec@5 99.023 (99.023)	Acc 0.814 (0.814)	
EVALUATING - Epoch: [28][10/20]	Time 0.016 (0.083)	Data 0.000 (0.063)	Loss 0.6933 (0.6604)	Prec@1 78.516 (81.001)	Prec@5 99.414 (98.722)	Acc 0.810 (0.816)	
EVALUATING - Epoch: [28][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.6879 (0.6535)	Prec@1 79.779 (80.930)	Prec@5 99.265 (98.780)	Acc 0.809 (0.813)	

Results - Epoch: 29
Training Loss 0.2857 	Training Prec@1 90.059 	Training Prec@5 99.772 	Validation Loss 0.6535 	Validation Prec@1 80.930 	Validation Prec@5 98.780 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 30

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [29][0/97]	Time 0.734 (0.734)	Data 0.647 (0.647)	Loss 0.3252 (0.3252)	Prec@1 88.281 (88.281)	Prec@5 100.000 (100.000)	Acc 0.883 (0.883)	
TRAINING - Epoch: [29][10/97]	Time 0.073 (0.145)	Data 0.000 (0.070)	Loss 0.3090 (0.2749)	Prec@1 89.062 (90.572)	Prec@5 99.805 (99.734)	Acc 0.906 (0.902)	
TRAINING - Epoch: [29][20/97]	Time 0.073 (0.110)	Data 0.000 (0.037)	Loss 0.2729 (0.2779)	Prec@1 90.625 (90.495)	Prec@5 99.805 (99.749)	Acc 0.905 (0.904)	
TRAINING - Epoch: [29][30/97]	Time 0.073 (0.098)	Data 0.000 (0.025)	Loss 0.2684 (0.2789)	Prec@1 90.820 (90.379)	Prec@5 99.609 (99.735)	Acc 0.904 (0.904)	
TRAINING - Epoch: [29][40/97]	Time 0.072 (0.092)	Data 0.000 (0.019)	Loss 0.2812 (0.2800)	Prec@1 90.625 (90.382)	Prec@5 99.609 (99.762)	Acc 0.904 (0.904)	
TRAINING - Epoch: [29][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.2984 (0.2816)	Prec@1 89.648 (90.257)	Prec@5 100.000 (99.774)	Acc 0.903 (0.903)	
TRAINING - Epoch: [29][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.2797 (0.2819)	Prec@1 90.820 (90.263)	Prec@5 99.609 (99.776)	Acc 0.903 (0.903)	
TRAINING - Epoch: [29][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2869 (0.2815)	Prec@1 90.625 (90.325)	Prec@5 100.000 (99.772)	Acc 0.903 (0.903)	
TRAINING - Epoch: [29][80/97]	Time 0.073 (0.082)	Data 0.000 (0.010)	Loss 0.2726 (0.2832)	Prec@1 90.625 (90.237)	Prec@5 99.609 (99.756)	Acc 0.902 (0.903)	
TRAINING - Epoch: [29][90/97]	Time 0.072 (0.081)	Data 0.000 (0.009)	Loss 0.2637 (0.2839)	Prec@1 90.625 (90.219)	Prec@5 99.023 (99.747)	Acc 0.902 (0.903)	
TRAINING - Epoch: [29][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.2741 (0.2839)	Prec@1 89.844 (90.208)	Prec@5 99.805 (99.744)	Acc 0.902 (0.903)	
EVALUATING - Epoch: [29][0/20]	Time 0.610 (0.610)	Data 0.583 (0.583)	Loss 0.7536 (0.7536)	Prec@1 81.055 (81.055)	Prec@5 99.219 (99.219)	Acc 0.811 (0.811)	
EVALUATING - Epoch: [29][10/20]	Time 0.016 (0.080)	Data 0.000 (0.061)	Loss 0.7868 (0.8236)	Prec@1 78.125 (76.900)	Prec@5 98.828 (98.651)	Acc 0.769 (0.778)	
EVALUATING - Epoch: [29][19/20]	Time 0.009 (0.051)	Data 0.000 (0.033)	Loss 0.9454 (0.8054)	Prec@1 76.103 (77.120)	Prec@5 99.265 (98.780)	Acc 0.771 (0.775)	

Results - Epoch: 30
Training Loss 0.2839 	Training Prec@1 90.208 	Training Prec@5 99.744 	Validation Loss 0.8054 	Validation Prec@1 77.120 	Validation Prec@5 98.780 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 31

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [30][0/97]	Time 0.630 (0.630)	Data 0.546 (0.546)	Loss 0.2518 (0.2518)	Prec@1 90.430 (90.430)	Prec@5 100.000 (100.000)	Acc 0.904 (0.904)	
TRAINING - Epoch: [30][10/97]	Time 0.073 (0.145)	Data 0.000 (0.071)	Loss 0.2584 (0.2496)	Prec@1 91.211 (90.945)	Prec@5 99.805 (99.787)	Acc 0.909 (0.907)	
TRAINING - Epoch: [30][20/97]	Time 0.073 (0.110)	Data 0.000 (0.037)	Loss 0.2778 (0.2520)	Prec@1 90.234 (91.081)	Prec@5 99.609 (99.740)	Acc 0.911 (0.909)	
TRAINING - Epoch: [30][30/97]	Time 0.073 (0.098)	Data 0.000 (0.025)	Loss 0.2816 (0.2569)	Prec@1 90.039 (91.016)	Prec@5 100.000 (99.779)	Acc 0.910 (0.910)	
TRAINING - Epoch: [30][40/97]	Time 0.073 (0.092)	Data 0.000 (0.019)	Loss 0.3037 (0.2624)	Prec@1 88.867 (90.825)	Prec@5 100.000 (99.781)	Acc 0.908 (0.909)	
TRAINING - Epoch: [30][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.2235 (0.2626)	Prec@1 91.992 (90.771)	Prec@5 100.000 (99.797)	Acc 0.908 (0.909)	
TRAINING - Epoch: [30][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.2893 (0.2663)	Prec@1 91.797 (90.692)	Prec@5 99.609 (99.795)	Acc 0.907 (0.909)	
TRAINING - Epoch: [30][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2540 (0.2674)	Prec@1 90.625 (90.608)	Prec@5 100.000 (99.791)	Acc 0.906 (0.908)	
TRAINING - Epoch: [30][80/97]	Time 0.073 (0.082)	Data 0.000 (0.010)	Loss 0.2490 (0.2713)	Prec@1 91.797 (90.454)	Prec@5 99.805 (99.785)	Acc 0.905 (0.908)	
TRAINING - Epoch: [30][90/97]	Time 0.072 (0.081)	Data 0.000 (0.009)	Loss 0.2763 (0.2732)	Prec@1 89.062 (90.348)	Prec@5 99.414 (99.775)	Acc 0.903 (0.908)	
TRAINING - Epoch: [30][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3645 (0.2761)	Prec@1 86.914 (90.228)	Prec@5 99.219 (99.762)	Acc 0.902 (0.907)	
EVALUATING - Epoch: [30][0/20]	Time 0.570 (0.570)	Data 0.553 (0.553)	Loss 0.8411 (0.8411)	Prec@1 74.609 (74.609)	Prec@5 99.023 (99.023)	Acc 0.746 (0.746)	
EVALUATING - Epoch: [30][10/20]	Time 0.016 (0.096)	Data 0.000 (0.075)	Loss 0.8952 (0.8901)	Prec@1 75.977 (75.462)	Prec@5 99.414 (98.881)	Acc 0.755 (0.753)	
EVALUATING - Epoch: [30][19/20]	Time 0.009 (0.060)	Data 0.000 (0.041)	Loss 0.9320 (0.8944)	Prec@1 76.103 (75.910)	Prec@5 99.632 (98.920)	Acc 0.759 (0.755)	

Results - Epoch: 31
Training Loss 0.2761 	Training Prec@1 90.228 	Training Prec@5 99.762 	Validation Loss 0.8944 	Validation Prec@1 75.910 	Validation Prec@5 98.920 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 32

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [31][0/97]	Time 0.659 (0.659)	Data 0.564 (0.564)	Loss 0.3156 (0.3156)	Prec@1 89.453 (89.453)	Prec@5 99.414 (99.414)	Acc 0.895 (0.895)	
TRAINING - Epoch: [31][10/97]	Time 0.073 (0.144)	Data 0.000 (0.068)	Loss 0.2336 (0.2595)	Prec@1 92.578 (90.803)	Prec@5 100.000 (99.787)	Acc 0.908 (0.903)	
TRAINING - Epoch: [31][20/97]	Time 0.073 (0.110)	Data 0.000 (0.036)	Loss 0.2358 (0.2547)	Prec@1 93.164 (91.118)	Prec@5 100.000 (99.777)	Acc 0.911 (0.906)	
TRAINING - Epoch: [31][30/97]	Time 0.073 (0.098)	Data 0.000 (0.024)	Loss 0.2301 (0.2504)	Prec@1 91.211 (91.129)	Prec@5 100.000 (99.786)	Acc 0.911 (0.907)	
TRAINING - Epoch: [31][40/97]	Time 0.073 (0.092)	Data 0.000 (0.019)	Loss 0.2347 (0.2520)	Prec@1 92.383 (91.120)	Prec@5 100.000 (99.795)	Acc 0.911 (0.908)	
TRAINING - Epoch: [31][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.2870 (0.2550)	Prec@1 89.648 (91.000)	Prec@5 99.805 (99.786)	Acc 0.910 (0.909)	
TRAINING - Epoch: [31][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.3021 (0.2571)	Prec@1 89.258 (90.987)	Prec@5 100.000 (99.792)	Acc 0.910 (0.909)	
TRAINING - Epoch: [31][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2253 (0.2604)	Prec@1 92.188 (90.903)	Prec@5 99.805 (99.780)	Acc 0.909 (0.909)	
TRAINING - Epoch: [31][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.2736 (0.2616)	Prec@1 90.234 (90.832)	Prec@5 99.219 (99.771)	Acc 0.908 (0.909)	
TRAINING - Epoch: [31][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.2427 (0.2628)	Prec@1 90.625 (90.829)	Prec@5 100.000 (99.775)	Acc 0.908 (0.909)	
TRAINING - Epoch: [31][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3320 (0.2637)	Prec@1 86.914 (90.794)	Prec@5 99.805 (99.785)	Acc 0.908 (0.909)	
EVALUATING - Epoch: [31][0/20]	Time 0.631 (0.631)	Data 0.615 (0.615)	Loss 0.5120 (0.5120)	Prec@1 83.203 (83.203)	Prec@5 99.805 (99.805)	Acc 0.832 (0.832)	
EVALUATING - Epoch: [31][10/20]	Time 0.016 (0.080)	Data 0.000 (0.064)	Loss 0.4837 (0.5074)	Prec@1 85.547 (84.268)	Prec@5 99.219 (99.148)	Acc 0.843 (0.838)	
EVALUATING - Epoch: [31][19/20]	Time 0.009 (0.051)	Data 0.000 (0.035)	Loss 0.4714 (0.4940)	Prec@1 85.294 (84.570)	Prec@5 100.000 (99.240)	Acc 0.846 (0.841)	

Results - Epoch: 32
Training Loss 0.2637 	Training Prec@1 90.794 	Training Prec@5 99.785 	Validation Loss 0.4940 	Validation Prec@1 84.570 	Validation Prec@5 99.240 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 33

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [32][0/97]	Time 0.699 (0.699)	Data 0.593 (0.593)	Loss 0.2255 (0.2255)	Prec@1 91.211 (91.211)	Prec@5 99.805 (99.805)	Acc 0.912 (0.912)	
TRAINING - Epoch: [32][10/97]	Time 0.073 (0.140)	Data 0.000 (0.064)	Loss 0.2623 (0.2565)	Prec@1 90.430 (90.838)	Prec@5 100.000 (99.858)	Acc 0.908 (0.910)	
TRAINING - Epoch: [32][20/97]	Time 0.073 (0.108)	Data 0.000 (0.034)	Loss 0.2567 (0.2479)	Prec@1 91.406 (91.257)	Prec@5 99.414 (99.814)	Acc 0.913 (0.910)	
TRAINING - Epoch: [32][30/97]	Time 0.073 (0.097)	Data 0.000 (0.023)	Loss 0.2478 (0.2516)	Prec@1 90.625 (91.022)	Prec@5 100.000 (99.842)	Acc 0.910 (0.911)	
TRAINING - Epoch: [32][40/97]	Time 0.073 (0.091)	Data 0.000 (0.017)	Loss 0.1945 (0.2512)	Prec@1 92.773 (91.135)	Prec@5 100.000 (99.848)	Acc 0.911 (0.911)	
TRAINING - Epoch: [32][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.2579 (0.2521)	Prec@1 90.430 (91.153)	Prec@5 100.000 (99.828)	Acc 0.912 (0.911)	
TRAINING - Epoch: [32][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.2848 (0.2529)	Prec@1 89.258 (91.108)	Prec@5 99.805 (99.817)	Acc 0.911 (0.911)	
TRAINING - Epoch: [32][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.1870 (0.2538)	Prec@1 94.141 (91.109)	Prec@5 100.000 (99.816)	Acc 0.911 (0.911)	
TRAINING - Epoch: [32][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.2930 (0.2557)	Prec@1 90.039 (91.114)	Prec@5 100.000 (99.822)	Acc 0.911 (0.911)	
TRAINING - Epoch: [32][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.3358 (0.2555)	Prec@1 88.281 (91.119)	Prec@5 99.414 (99.815)	Acc 0.911 (0.911)	
TRAINING - Epoch: [32][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.2917 (0.2566)	Prec@1 89.844 (91.088)	Prec@5 99.805 (99.809)	Acc 0.911 (0.911)	
EVALUATING - Epoch: [32][0/20]	Time 0.482 (0.482)	Data 0.466 (0.466)	Loss 0.5846 (0.5846)	Prec@1 81.445 (81.445)	Prec@5 99.609 (99.609)	Acc 0.814 (0.814)	
EVALUATING - Epoch: [32][10/20]	Time 0.016 (0.082)	Data 0.000 (0.061)	Loss 0.6805 (0.6560)	Prec@1 81.055 (82.315)	Prec@5 99.219 (99.059)	Acc 0.823 (0.823)	
EVALUATING - Epoch: [32][19/20]	Time 0.009 (0.052)	Data 0.000 (0.034)	Loss 0.5678 (0.6408)	Prec@1 81.250 (82.130)	Prec@5 99.632 (99.260)	Acc 0.821 (0.822)	

Results - Epoch: 33
Training Loss 0.2566 	Training Prec@1 91.088 	Training Prec@5 99.809 	Validation Loss 0.6408 	Validation Prec@1 82.130 	Validation Prec@5 99.260 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 34

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [33][0/97]	Time 0.618 (0.618)	Data 0.539 (0.539)	Loss 0.2481 (0.2481)	Prec@1 91.602 (91.602)	Prec@5 99.805 (99.805)	Acc 0.916 (0.916)	
TRAINING - Epoch: [33][10/97]	Time 0.073 (0.141)	Data 0.000 (0.061)	Loss 0.2526 (0.2543)	Prec@1 91.602 (91.317)	Prec@5 99.805 (99.716)	Acc 0.913 (0.913)	
TRAINING - Epoch: [33][20/97]	Time 0.073 (0.108)	Data 0.000 (0.032)	Loss 0.2752 (0.2576)	Prec@1 90.234 (91.109)	Prec@5 99.805 (99.777)	Acc 0.911 (0.912)	
TRAINING - Epoch: [33][30/97]	Time 0.073 (0.097)	Data 0.000 (0.022)	Loss 0.2511 (0.2521)	Prec@1 90.039 (91.148)	Prec@5 100.000 (99.805)	Acc 0.911 (0.912)	
TRAINING - Epoch: [33][40/97]	Time 0.073 (0.091)	Data 0.000 (0.016)	Loss 0.2959 (0.2510)	Prec@1 89.062 (91.240)	Prec@5 99.609 (99.805)	Acc 0.912 (0.912)	
TRAINING - Epoch: [33][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.3090 (0.2508)	Prec@1 89.648 (91.215)	Prec@5 99.414 (99.797)	Acc 0.912 (0.912)	
TRAINING - Epoch: [33][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.2679 (0.2500)	Prec@1 89.844 (91.214)	Prec@5 99.805 (99.795)	Acc 0.912 (0.912)	
TRAINING - Epoch: [33][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2847 (0.2497)	Prec@1 89.648 (91.208)	Prec@5 99.609 (99.794)	Acc 0.912 (0.912)	
TRAINING - Epoch: [33][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.2674 (0.2509)	Prec@1 89.844 (91.194)	Prec@5 100.000 (99.797)	Acc 0.912 (0.912)	
TRAINING - Epoch: [33][90/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.2415 (0.2534)	Prec@1 91.602 (91.138)	Prec@5 100.000 (99.788)	Acc 0.911 (0.912)	
TRAINING - Epoch: [33][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3037 (0.2544)	Prec@1 89.258 (91.090)	Prec@5 99.609 (99.785)	Acc 0.911 (0.912)	
EVALUATING - Epoch: [33][0/20]	Time 0.569 (0.569)	Data 0.550 (0.550)	Loss 0.7862 (0.7862)	Prec@1 78.711 (78.711)	Prec@5 99.219 (99.219)	Acc 0.787 (0.787)	
EVALUATING - Epoch: [33][10/20]	Time 0.016 (0.082)	Data 0.000 (0.063)	Loss 0.7486 (0.8094)	Prec@1 77.148 (78.018)	Prec@5 98.828 (98.952)	Acc 0.780 (0.784)	
EVALUATING - Epoch: [33][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.7440 (0.8031)	Prec@1 77.574 (78.040)	Prec@5 100.000 (99.020)	Acc 0.780 (0.782)	

Results - Epoch: 34
Training Loss 0.2544 	Training Prec@1 91.090 	Training Prec@5 99.785 	Validation Loss 0.8031 	Validation Prec@1 78.040 	Validation Prec@5 99.020 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 35

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [34][0/97]	Time 0.644 (0.644)	Data 0.556 (0.556)	Loss 0.2827 (0.2827)	Prec@1 91.406 (91.406)	Prec@5 100.000 (100.000)	Acc 0.914 (0.914)	
TRAINING - Epoch: [34][10/97]	Time 0.073 (0.150)	Data 0.000 (0.075)	Loss 0.3052 (0.2556)	Prec@1 89.258 (91.531)	Prec@5 99.805 (99.876)	Acc 0.915 (0.921)	
TRAINING - Epoch: [34][20/97]	Time 0.073 (0.113)	Data 0.000 (0.039)	Loss 0.2452 (0.2459)	Prec@1 91.016 (91.490)	Prec@5 99.609 (99.851)	Acc 0.915 (0.918)	
TRAINING - Epoch: [34][30/97]	Time 0.073 (0.100)	Data 0.000 (0.027)	Loss 0.2432 (0.2451)	Prec@1 91.797 (91.394)	Prec@5 100.000 (99.817)	Acc 0.914 (0.917)	
TRAINING - Epoch: [34][40/97]	Time 0.073 (0.093)	Data 0.000 (0.020)	Loss 0.2571 (0.2469)	Prec@1 92.383 (91.244)	Prec@5 99.414 (99.814)	Acc 0.912 (0.916)	
TRAINING - Epoch: [34][50/97]	Time 0.073 (0.089)	Data 0.000 (0.016)	Loss 0.3085 (0.2468)	Prec@1 88.672 (91.318)	Prec@5 99.219 (99.812)	Acc 0.913 (0.916)	
TRAINING - Epoch: [34][60/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.2171 (0.2450)	Prec@1 92.578 (91.352)	Prec@5 99.805 (99.808)	Acc 0.914 (0.915)	
TRAINING - Epoch: [34][70/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.2260 (0.2445)	Prec@1 92.969 (91.362)	Prec@5 99.609 (99.796)	Acc 0.914 (0.915)	
TRAINING - Epoch: [34][80/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.1995 (0.2432)	Prec@1 93.164 (91.406)	Prec@5 100.000 (99.814)	Acc 0.914 (0.915)	
TRAINING - Epoch: [34][90/97]	Time 0.072 (0.082)	Data 0.000 (0.009)	Loss 0.2604 (0.2436)	Prec@1 90.625 (91.419)	Prec@5 100.000 (99.820)	Acc 0.914 (0.915)	
TRAINING - Epoch: [34][96/97]	Time 0.072 (0.081)	Data 0.000 (0.009)	Loss 0.1755 (0.2432)	Prec@1 93.945 (91.445)	Prec@5 100.000 (99.823)	Acc 0.914 (0.915)	
EVALUATING - Epoch: [34][0/20]	Time 0.555 (0.555)	Data 0.538 (0.538)	Loss 0.4668 (0.4668)	Prec@1 86.133 (86.133)	Prec@5 99.805 (99.805)	Acc 0.861 (0.861)	
EVALUATING - Epoch: [34][10/20]	Time 0.016 (0.086)	Data 0.000 (0.069)	Loss 0.5044 (0.5172)	Prec@1 84.180 (84.730)	Prec@5 99.414 (99.165)	Acc 0.847 (0.849)	
EVALUATING - Epoch: [34][19/20]	Time 0.009 (0.054)	Data 0.000 (0.038)	Loss 0.5327 (0.4983)	Prec@1 83.088 (84.810)	Prec@5 100.000 (99.350)	Acc 0.848 (0.849)	

Results - Epoch: 35
Training Loss 0.2432 	Training Prec@1 91.445 	Training Prec@5 99.823 	Validation Loss 0.4983 	Validation Prec@1 84.810 	Validation Prec@5 99.350 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 36

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [35][0/97]	Time 0.658 (0.658)	Data 0.576 (0.576)	Loss 0.1676 (0.1676)	Prec@1 94.531 (94.531)	Prec@5 100.000 (100.000)	Acc 0.945 (0.945)	
TRAINING - Epoch: [35][10/97]	Time 0.073 (0.136)	Data 0.000 (0.054)	Loss 0.2283 (0.2248)	Prec@1 91.797 (92.383)	Prec@5 99.805 (99.876)	Acc 0.924 (0.929)	
TRAINING - Epoch: [35][20/97]	Time 0.073 (0.106)	Data 0.000 (0.029)	Loss 0.2319 (0.2178)	Prec@1 92.188 (92.504)	Prec@5 100.000 (99.888)	Acc 0.925 (0.927)	
TRAINING - Epoch: [35][30/97]	Time 0.073 (0.095)	Data 0.000 (0.019)	Loss 0.2258 (0.2212)	Prec@1 91.797 (92.307)	Prec@5 99.805 (99.842)	Acc 0.923 (0.926)	
TRAINING - Epoch: [35][40/97]	Time 0.073 (0.090)	Data 0.000 (0.015)	Loss 0.2668 (0.2262)	Prec@1 91.406 (92.068)	Prec@5 99.609 (99.829)	Acc 0.921 (0.925)	
TRAINING - Epoch: [35][50/97]	Time 0.073 (0.086)	Data 0.000 (0.012)	Loss 0.2385 (0.2302)	Prec@1 91.992 (91.965)	Prec@5 100.000 (99.831)	Acc 0.920 (0.924)	
TRAINING - Epoch: [35][60/97]	Time 0.073 (0.084)	Data 0.000 (0.010)	Loss 0.2641 (0.2329)	Prec@1 90.039 (91.842)	Prec@5 99.805 (99.840)	Acc 0.918 (0.923)	
TRAINING - Epoch: [35][70/97]	Time 0.073 (0.083)	Data 0.000 (0.009)	Loss 0.2230 (0.2327)	Prec@1 92.969 (91.857)	Prec@5 100.000 (99.843)	Acc 0.919 (0.923)	
TRAINING - Epoch: [35][80/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.2609 (0.2354)	Prec@1 89.844 (91.821)	Prec@5 100.000 (99.834)	Acc 0.918 (0.922)	
TRAINING - Epoch: [35][90/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.3223 (0.2370)	Prec@1 88.672 (91.741)	Prec@5 99.805 (99.828)	Acc 0.917 (0.922)	
TRAINING - Epoch: [35][96/97]	Time 0.072 (0.080)	Data 0.000 (0.006)	Loss 0.2402 (0.2379)	Prec@1 91.406 (91.698)	Prec@5 99.805 (99.825)	Acc 0.917 (0.921)	
EVALUATING - Epoch: [35][0/20]	Time 0.579 (0.579)	Data 0.550 (0.550)	Loss 0.5739 (0.5739)	Prec@1 83.203 (83.203)	Prec@5 99.414 (99.414)	Acc 0.832 (0.832)	
EVALUATING - Epoch: [35][10/20]	Time 0.016 (0.084)	Data 0.000 (0.066)	Loss 0.6413 (0.6548)	Prec@1 82.031 (80.593)	Prec@5 99.023 (99.148)	Acc 0.806 (0.809)	
EVALUATING - Epoch: [35][19/20]	Time 0.009 (0.053)	Data 0.000 (0.036)	Loss 0.6381 (0.6416)	Prec@1 80.882 (81.100)	Prec@5 99.265 (99.250)	Acc 0.811 (0.810)	

Results - Epoch: 36
Training Loss 0.2379 	Training Prec@1 91.698 	Training Prec@5 99.825 	Validation Loss 0.6416 	Validation Prec@1 81.100 	Validation Prec@5 99.250 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 37

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [36][0/97]	Time 0.694 (0.694)	Data 0.611 (0.611)	Loss 0.2224 (0.2224)	Prec@1 92.578 (92.578)	Prec@5 99.805 (99.805)	Acc 0.926 (0.926)	
TRAINING - Epoch: [36][10/97]	Time 0.072 (0.138)	Data 0.000 (0.058)	Loss 0.1871 (0.2183)	Prec@1 93.359 (92.418)	Prec@5 99.805 (99.876)	Acc 0.924 (0.923)	
TRAINING - Epoch: [36][20/97]	Time 0.073 (0.107)	Data 0.000 (0.030)	Loss 0.2470 (0.2196)	Prec@1 91.406 (92.355)	Prec@5 99.805 (99.888)	Acc 0.924 (0.923)	
TRAINING - Epoch: [36][30/97]	Time 0.072 (0.096)	Data 0.000 (0.021)	Loss 0.2511 (0.2232)	Prec@1 90.234 (92.175)	Prec@5 100.000 (99.880)	Acc 0.922 (0.923)	
TRAINING - Epoch: [36][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.2104 (0.2238)	Prec@1 93.359 (92.197)	Prec@5 100.000 (99.886)	Acc 0.922 (0.923)	
TRAINING - Epoch: [36][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.1958 (0.2240)	Prec@1 93.555 (92.172)	Prec@5 100.000 (99.885)	Acc 0.922 (0.923)	
TRAINING - Epoch: [36][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.2257 (0.2268)	Prec@1 93.359 (92.091)	Prec@5 100.000 (99.862)	Acc 0.921 (0.922)	
TRAINING - Epoch: [36][70/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.2060 (0.2300)	Prec@1 92.773 (92.022)	Prec@5 100.000 (99.854)	Acc 0.920 (0.922)	
TRAINING - Epoch: [36][80/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.2385 (0.2288)	Prec@1 91.211 (92.050)	Prec@5 99.805 (99.858)	Acc 0.921 (0.922)	
TRAINING - Epoch: [36][90/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2224 (0.2315)	Prec@1 92.383 (91.947)	Prec@5 99.609 (99.845)	Acc 0.919 (0.922)	
TRAINING - Epoch: [36][96/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2216 (0.2316)	Prec@1 91.992 (91.938)	Prec@5 100.000 (99.841)	Acc 0.919 (0.922)	
EVALUATING - Epoch: [36][0/20]	Time 0.566 (0.566)	Data 0.550 (0.550)	Loss 0.5891 (0.5891)	Prec@1 82.422 (82.422)	Prec@5 98.828 (98.828)	Acc 0.824 (0.824)	
EVALUATING - Epoch: [36][10/20]	Time 0.016 (0.085)	Data 0.000 (0.069)	Loss 0.6878 (0.6761)	Prec@1 80.078 (81.889)	Prec@5 99.219 (98.739)	Acc 0.819 (0.825)	
EVALUATING - Epoch: [36][19/20]	Time 0.009 (0.053)	Data 0.000 (0.038)	Loss 0.6042 (0.6724)	Prec@1 81.250 (81.940)	Prec@5 99.265 (98.850)	Acc 0.819 (0.823)	

Results - Epoch: 37
Training Loss 0.2316 	Training Prec@1 91.938 	Training Prec@5 99.841 	Validation Loss 0.6724 	Validation Prec@1 81.940 	Validation Prec@5 98.850 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 38

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [37][0/97]	Time 0.797 (0.797)	Data 0.677 (0.677)	Loss 0.2616 (0.2616)	Prec@1 91.211 (91.211)	Prec@5 100.000 (100.000)	Acc 0.912 (0.912)	
TRAINING - Epoch: [37][10/97]	Time 0.073 (0.143)	Data 0.000 (0.065)	Loss 0.2263 (0.2150)	Prec@1 92.969 (92.507)	Prec@5 99.609 (99.840)	Acc 0.925 (0.921)	
TRAINING - Epoch: [37][20/97]	Time 0.073 (0.110)	Data 0.000 (0.034)	Loss 0.2205 (0.2169)	Prec@1 91.406 (92.336)	Prec@5 100.000 (99.814)	Acc 0.923 (0.923)	
TRAINING - Epoch: [37][30/97]	Time 0.073 (0.098)	Data 0.000 (0.023)	Loss 0.2100 (0.2168)	Prec@1 92.383 (92.351)	Prec@5 99.805 (99.849)	Acc 0.924 (0.923)	
TRAINING - Epoch: [37][40/97]	Time 0.073 (0.092)	Data 0.000 (0.018)	Loss 0.2900 (0.2219)	Prec@1 90.430 (92.159)	Prec@5 99.805 (99.852)	Acc 0.922 (0.923)	
TRAINING - Epoch: [37][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.2337 (0.2258)	Prec@1 92.383 (92.065)	Prec@5 99.609 (99.854)	Acc 0.921 (0.923)	
TRAINING - Epoch: [37][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.2549 (0.2290)	Prec@1 92.188 (91.960)	Prec@5 100.000 (99.846)	Acc 0.920 (0.922)	
TRAINING - Epoch: [37][70/97]	Time 0.073 (0.084)	Data 0.000 (0.010)	Loss 0.2212 (0.2324)	Prec@1 93.164 (91.835)	Prec@5 99.609 (99.835)	Acc 0.918 (0.922)	
TRAINING - Epoch: [37][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.2776 (0.2323)	Prec@1 90.625 (91.804)	Prec@5 99.805 (99.843)	Acc 0.918 (0.921)	
TRAINING - Epoch: [37][90/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.2120 (0.2311)	Prec@1 90.820 (91.805)	Prec@5 100.000 (99.854)	Acc 0.918 (0.921)	
TRAINING - Epoch: [37][96/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.2077 (0.2322)	Prec@1 91.406 (91.751)	Prec@5 100.000 (99.853)	Acc 0.918 (0.921)	
EVALUATING - Epoch: [37][0/20]	Time 0.564 (0.564)	Data 0.547 (0.547)	Loss 0.5590 (0.5590)	Prec@1 84.570 (84.570)	Prec@5 99.609 (99.609)	Acc 0.846 (0.846)	
EVALUATING - Epoch: [37][10/20]	Time 0.016 (0.086)	Data 0.000 (0.069)	Loss 0.6244 (0.6272)	Prec@1 83.008 (82.511)	Prec@5 99.414 (98.881)	Acc 0.825 (0.827)	
EVALUATING - Epoch: [37][19/20]	Time 0.009 (0.054)	Data 0.000 (0.038)	Loss 0.5414 (0.6074)	Prec@1 83.088 (82.840)	Prec@5 98.897 (98.950)	Acc 0.828 (0.828)	

Results - Epoch: 38
Training Loss 0.2322 	Training Prec@1 91.751 	Training Prec@5 99.853 	Validation Loss 0.6074 	Validation Prec@1 82.840 	Validation Prec@5 98.950 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 39

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [38][0/97]	Time 0.708 (0.708)	Data 0.632 (0.632)	Loss 0.2144 (0.2144)	Prec@1 91.602 (91.602)	Prec@5 99.805 (99.805)	Acc 0.916 (0.916)	
TRAINING - Epoch: [38][10/97]	Time 0.073 (0.145)	Data 0.000 (0.069)	Loss 0.2393 (0.2179)	Prec@1 91.406 (92.116)	Prec@5 99.805 (99.929)	Acc 0.921 (0.921)	
TRAINING - Epoch: [38][20/97]	Time 0.072 (0.110)	Data 0.000 (0.036)	Loss 0.1792 (0.2161)	Prec@1 93.945 (92.215)	Prec@5 100.000 (99.916)	Acc 0.922 (0.921)	
TRAINING - Epoch: [38][30/97]	Time 0.073 (0.098)	Data 0.000 (0.025)	Loss 0.1904 (0.2147)	Prec@1 92.969 (92.263)	Prec@5 99.609 (99.899)	Acc 0.923 (0.921)	
TRAINING - Epoch: [38][40/97]	Time 0.073 (0.092)	Data 0.000 (0.019)	Loss 0.2532 (0.2175)	Prec@1 91.602 (92.202)	Prec@5 99.414 (99.867)	Acc 0.922 (0.922)	
TRAINING - Epoch: [38][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.2888 (0.2188)	Prec@1 89.453 (92.249)	Prec@5 99.805 (99.866)	Acc 0.922 (0.922)	
TRAINING - Epoch: [38][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.3092 (0.2224)	Prec@1 89.062 (92.175)	Prec@5 99.609 (99.856)	Acc 0.922 (0.922)	
TRAINING - Epoch: [38][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2067 (0.2267)	Prec@1 93.359 (92.039)	Prec@5 99.609 (99.838)	Acc 0.920 (0.922)	
TRAINING - Epoch: [38][80/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2553 (0.2288)	Prec@1 90.625 (91.970)	Prec@5 99.805 (99.843)	Acc 0.920 (0.921)	
TRAINING - Epoch: [38][90/97]	Time 0.073 (0.081)	Data 0.000 (0.009)	Loss 0.2545 (0.2286)	Prec@1 90.820 (91.939)	Prec@5 100.000 (99.852)	Acc 0.919 (0.921)	
TRAINING - Epoch: [38][96/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.1905 (0.2281)	Prec@1 93.359 (91.962)	Prec@5 100.000 (99.845)	Acc 0.920 (0.921)	
EVALUATING - Epoch: [38][0/20]	Time 0.586 (0.586)	Data 0.556 (0.556)	Loss 0.4194 (0.4194)	Prec@1 87.500 (87.500)	Prec@5 99.805 (99.805)	Acc 0.875 (0.875)	
EVALUATING - Epoch: [38][10/20]	Time 0.021 (0.081)	Data 0.005 (0.063)	Loss 0.4436 (0.4778)	Prec@1 88.672 (86.080)	Prec@5 99.414 (99.254)	Acc 0.861 (0.862)	
EVALUATING - Epoch: [38][19/20]	Time 0.009 (0.051)	Data 0.000 (0.035)	Loss 0.4550 (0.4599)	Prec@1 85.294 (86.130)	Prec@5 100.000 (99.450)	Acc 0.861 (0.862)	

Results - Epoch: 39
Training Loss 0.2281 	Training Prec@1 91.962 	Training Prec@5 99.845 	Validation Loss 0.4599 	Validation Prec@1 86.130 	Validation Prec@5 99.450 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 40

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [39][0/97]	Time 0.690 (0.690)	Data 0.594 (0.594)	Loss 0.1859 (0.1859)	Prec@1 93.555 (93.555)	Prec@5 99.805 (99.805)	Acc 0.936 (0.936)	
TRAINING - Epoch: [39][10/97]	Time 0.072 (0.138)	Data 0.000 (0.060)	Loss 0.1846 (0.2058)	Prec@1 92.773 (92.987)	Prec@5 100.000 (99.840)	Acc 0.930 (0.933)	
TRAINING - Epoch: [39][20/97]	Time 0.073 (0.107)	Data 0.000 (0.032)	Loss 0.1809 (0.2043)	Prec@1 92.969 (92.839)	Prec@5 100.000 (99.888)	Acc 0.928 (0.931)	
TRAINING - Epoch: [39][30/97]	Time 0.073 (0.096)	Data 0.000 (0.022)	Loss 0.2550 (0.2070)	Prec@1 91.016 (92.635)	Prec@5 99.805 (99.887)	Acc 0.926 (0.930)	
TRAINING - Epoch: [39][40/97]	Time 0.073 (0.090)	Data 0.000 (0.016)	Loss 0.1976 (0.2079)	Prec@1 93.555 (92.597)	Prec@5 100.000 (99.895)	Acc 0.926 (0.929)	
TRAINING - Epoch: [39][50/97]	Time 0.073 (0.087)	Data 0.000 (0.013)	Loss 0.2895 (0.2141)	Prec@1 89.258 (92.375)	Prec@5 99.414 (99.870)	Acc 0.924 (0.928)	
TRAINING - Epoch: [39][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.2529 (0.2138)	Prec@1 90.820 (92.354)	Prec@5 99.805 (99.866)	Acc 0.924 (0.927)	
TRAINING - Epoch: [39][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2249 (0.2153)	Prec@1 91.406 (92.289)	Prec@5 100.000 (99.851)	Acc 0.923 (0.927)	
TRAINING - Epoch: [39][80/97]	Time 0.073 (0.082)	Data 0.000 (0.008)	Loss 0.2105 (0.2158)	Prec@1 92.969 (92.265)	Prec@5 99.805 (99.851)	Acc 0.923 (0.926)	
TRAINING - Epoch: [39][90/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.1821 (0.2166)	Prec@1 92.773 (92.224)	Prec@5 100.000 (99.848)	Acc 0.922 (0.926)	
TRAINING - Epoch: [39][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.2840 (0.2180)	Prec@1 90.625 (92.196)	Prec@5 100.000 (99.845)	Acc 0.922 (0.926)	
EVALUATING - Epoch: [39][0/20]	Time 0.531 (0.531)	Data 0.514 (0.514)	Loss 0.4977 (0.4977)	Prec@1 85.352 (85.352)	Prec@5 100.000 (100.000)	Acc 0.854 (0.854)	
EVALUATING - Epoch: [39][10/20]	Time 0.016 (0.085)	Data 0.000 (0.066)	Loss 0.5700 (0.5686)	Prec@1 82.031 (83.505)	Prec@5 99.023 (99.165)	Acc 0.835 (0.839)	
EVALUATING - Epoch: [39][19/20]	Time 0.009 (0.054)	Data 0.000 (0.036)	Loss 0.5403 (0.5495)	Prec@1 85.662 (83.950)	Prec@5 99.265 (99.280)	Acc 0.840 (0.838)	

Results - Epoch: 40
Training Loss 0.2180 	Training Prec@1 92.196 	Training Prec@5 99.845 	Validation Loss 0.5495 	Validation Prec@1 83.950 	Validation Prec@5 99.280 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 41

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [40][0/97]	Time 0.703 (0.703)	Data 0.592 (0.592)	Loss 0.2170 (0.2170)	Prec@1 93.164 (93.164)	Prec@5 100.000 (100.000)	Acc 0.932 (0.932)	
TRAINING - Epoch: [40][10/97]	Time 0.073 (0.142)	Data 0.000 (0.063)	Loss 0.2095 (0.2173)	Prec@1 92.578 (92.365)	Prec@5 100.000 (99.929)	Acc 0.924 (0.924)	
TRAINING - Epoch: [40][20/97]	Time 0.073 (0.109)	Data 0.000 (0.033)	Loss 0.2331 (0.2092)	Prec@1 92.578 (92.699)	Prec@5 99.609 (99.888)	Acc 0.927 (0.925)	
TRAINING - Epoch: [40][30/97]	Time 0.073 (0.098)	Data 0.000 (0.022)	Loss 0.1859 (0.2018)	Prec@1 92.773 (92.849)	Prec@5 100.000 (99.912)	Acc 0.928 (0.926)	
TRAINING - Epoch: [40][40/97]	Time 0.073 (0.092)	Data 0.000 (0.017)	Loss 0.2502 (0.2052)	Prec@1 90.820 (92.769)	Prec@5 99.805 (99.905)	Acc 0.928 (0.926)	
TRAINING - Epoch: [40][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.2259 (0.2049)	Prec@1 90.625 (92.770)	Prec@5 100.000 (99.885)	Acc 0.928 (0.927)	
TRAINING - Epoch: [40][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.1921 (0.2090)	Prec@1 92.383 (92.623)	Prec@5 100.000 (99.872)	Acc 0.926 (0.927)	
TRAINING - Epoch: [40][70/97]	Time 0.073 (0.084)	Data 0.000 (0.010)	Loss 0.2121 (0.2109)	Prec@1 92.969 (92.556)	Prec@5 100.000 (99.865)	Acc 0.926 (0.927)	
TRAINING - Epoch: [40][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.1892 (0.2116)	Prec@1 93.750 (92.472)	Prec@5 99.805 (99.877)	Acc 0.925 (0.926)	
TRAINING - Epoch: [40][90/97]	Time 0.073 (0.081)	Data 0.000 (0.008)	Loss 0.2201 (0.2135)	Prec@1 92.188 (92.400)	Prec@5 99.805 (99.876)	Acc 0.924 (0.926)	
TRAINING - Epoch: [40][96/97]	Time 0.073 (0.081)	Data 0.000 (0.007)	Loss 0.2476 (0.2139)	Prec@1 90.625 (92.361)	Prec@5 99.805 (99.879)	Acc 0.924 (0.926)	
EVALUATING - Epoch: [40][0/20]	Time 0.577 (0.577)	Data 0.561 (0.561)	Loss 0.8173 (0.8173)	Prec@1 79.492 (79.492)	Prec@5 99.609 (99.609)	Acc 0.795 (0.795)	
EVALUATING - Epoch: [40][10/20]	Time 0.016 (0.084)	Data 0.000 (0.067)	Loss 0.9739 (1.0090)	Prec@1 76.172 (77.060)	Prec@5 98.828 (98.739)	Acc 0.771 (0.776)	
EVALUATING - Epoch: [40][19/20]	Time 0.009 (0.053)	Data 0.000 (0.037)	Loss 1.1285 (0.9894)	Prec@1 74.265 (77.000)	Prec@5 98.897 (98.780)	Acc 0.770 (0.773)	

Results - Epoch: 41
Training Loss 0.2139 	Training Prec@1 92.361 	Training Prec@5 99.879 	Validation Loss 0.9894 	Validation Prec@1 77.000 	Validation Prec@5 98.780 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 42

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [41][0/97]	Time 0.704 (0.704)	Data 0.613 (0.613)	Loss 0.1776 (0.1776)	Prec@1 94.336 (94.336)	Prec@5 100.000 (100.000)	Acc 0.943 (0.943)	
TRAINING - Epoch: [41][10/97]	Time 0.073 (0.143)	Data 0.000 (0.067)	Loss 0.2073 (0.1988)	Prec@1 92.773 (92.827)	Prec@5 100.000 (99.964)	Acc 0.928 (0.931)	
TRAINING - Epoch: [41][20/97]	Time 0.073 (0.110)	Data 0.000 (0.035)	Loss 0.1501 (0.1968)	Prec@1 94.727 (93.043)	Prec@5 100.000 (99.935)	Acc 0.930 (0.930)	
TRAINING - Epoch: [41][30/97]	Time 0.072 (0.098)	Data 0.000 (0.024)	Loss 0.1677 (0.1988)	Prec@1 94.141 (92.937)	Prec@5 99.609 (99.905)	Acc 0.929 (0.929)	
TRAINING - Epoch: [41][40/97]	Time 0.072 (0.092)	Data 0.000 (0.018)	Loss 0.2072 (0.1993)	Prec@1 92.773 (92.921)	Prec@5 100.000 (99.909)	Acc 0.929 (0.929)	
TRAINING - Epoch: [41][50/97]	Time 0.072 (0.088)	Data 0.000 (0.015)	Loss 0.2091 (0.2033)	Prec@1 92.188 (92.796)	Prec@5 100.000 (99.908)	Acc 0.928 (0.929)	
TRAINING - Epoch: [41][60/97]	Time 0.072 (0.085)	Data 0.000 (0.012)	Loss 0.2201 (0.2061)	Prec@1 91.016 (92.671)	Prec@5 99.609 (99.901)	Acc 0.927 (0.929)	
TRAINING - Epoch: [41][70/97]	Time 0.072 (0.083)	Data 0.000 (0.010)	Loss 0.2141 (0.2080)	Prec@1 93.359 (92.677)	Prec@5 99.609 (99.893)	Acc 0.927 (0.929)	
TRAINING - Epoch: [41][80/97]	Time 0.072 (0.082)	Data 0.000 (0.009)	Loss 0.2194 (0.2092)	Prec@1 91.992 (92.609)	Prec@5 99.805 (99.882)	Acc 0.926 (0.928)	
TRAINING - Epoch: [41][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.2070 (0.2089)	Prec@1 91.992 (92.643)	Prec@5 100.000 (99.873)	Acc 0.926 (0.928)	
TRAINING - Epoch: [41][96/97]	Time 0.072 (0.080)	Data 0.000 (0.008)	Loss 0.2436 (0.2102)	Prec@1 93.164 (92.604)	Prec@5 99.805 (99.875)	Acc 0.926 (0.928)	
EVALUATING - Epoch: [41][0/20]	Time 0.459 (0.459)	Data 0.431 (0.431)	Loss 0.5869 (0.5869)	Prec@1 82.812 (82.812)	Prec@5 99.609 (99.609)	Acc 0.828 (0.828)	
EVALUATING - Epoch: [41][10/20]	Time 0.016 (0.082)	Data 0.000 (0.064)	Loss 0.7046 (0.6549)	Prec@1 81.836 (81.889)	Prec@5 99.609 (99.237)	Acc 0.819 (0.819)	
EVALUATING - Epoch: [41][19/20]	Time 0.009 (0.052)	Data 0.000 (0.035)	Loss 0.6421 (0.6460)	Prec@1 81.985 (82.380)	Prec@5 99.632 (99.330)	Acc 0.824 (0.820)	

Results - Epoch: 42
Training Loss 0.2102 	Training Prec@1 92.604 	Training Prec@5 99.875 	Validation Loss 0.6460 	Validation Prec@1 82.380 	Validation Prec@5 99.330 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 43

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [42][0/97]	Time 0.813 (0.813)	Data 0.715 (0.715)	Loss 0.1803 (0.1803)	Prec@1 92.969 (92.969)	Prec@5 100.000 (100.000)	Acc 0.930 (0.930)	
TRAINING - Epoch: [42][10/97]	Time 0.072 (0.143)	Data 0.000 (0.065)	Loss 0.1969 (0.2004)	Prec@1 91.992 (92.720)	Prec@5 100.000 (99.822)	Acc 0.927 (0.932)	
TRAINING - Epoch: [42][20/97]	Time 0.073 (0.109)	Data 0.000 (0.034)	Loss 0.2605 (0.2112)	Prec@1 91.406 (92.560)	Prec@5 99.609 (99.795)	Acc 0.926 (0.929)	
TRAINING - Epoch: [42][30/97]	Time 0.073 (0.097)	Data 0.000 (0.023)	Loss 0.2357 (0.2127)	Prec@1 91.992 (92.477)	Prec@5 99.805 (99.836)	Acc 0.925 (0.927)	
TRAINING - Epoch: [42][40/97]	Time 0.073 (0.091)	Data 0.000 (0.018)	Loss 0.1842 (0.2114)	Prec@1 94.336 (92.550)	Prec@5 100.000 (99.838)	Acc 0.925 (0.927)	
TRAINING - Epoch: [42][50/97]	Time 0.073 (0.088)	Data 0.000 (0.014)	Loss 0.2448 (0.2104)	Prec@1 91.992 (92.590)	Prec@5 99.805 (99.847)	Acc 0.926 (0.927)	
TRAINING - Epoch: [42][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.1753 (0.2085)	Prec@1 93.750 (92.649)	Prec@5 100.000 (99.856)	Acc 0.926 (0.927)	
TRAINING - Epoch: [42][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2275 (0.2074)	Prec@1 91.797 (92.696)	Prec@5 99.805 (99.860)	Acc 0.927 (0.927)	
TRAINING - Epoch: [42][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.2096 (0.2079)	Prec@1 92.773 (92.663)	Prec@5 100.000 (99.863)	Acc 0.927 (0.927)	
TRAINING - Epoch: [42][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.2631 (0.2086)	Prec@1 91.211 (92.660)	Prec@5 100.000 (99.871)	Acc 0.927 (0.927)	
TRAINING - Epoch: [42][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.1561 (0.2075)	Prec@1 95.703 (92.687)	Prec@5 100.000 (99.873)	Acc 0.927 (0.927)	
EVALUATING - Epoch: [42][0/20]	Time 0.568 (0.568)	Data 0.546 (0.546)	Loss 0.6209 (0.6209)	Prec@1 83.594 (83.594)	Prec@5 99.219 (99.219)	Acc 0.836 (0.836)	
EVALUATING - Epoch: [42][10/20]	Time 0.046 (0.079)	Data 0.030 (0.062)	Loss 0.7146 (0.6859)	Prec@1 80.469 (81.800)	Prec@5 99.023 (98.331)	Acc 0.818 (0.823)	
EVALUATING - Epoch: [42][19/20]	Time 0.009 (0.051)	Data 0.000 (0.035)	Loss 0.6409 (0.6736)	Prec@1 81.985 (81.750)	Prec@5 98.162 (98.460)	Acc 0.818 (0.820)	

Results - Epoch: 43
Training Loss 0.2075 	Training Prec@1 92.687 	Training Prec@5 99.873 	Validation Loss 0.6736 	Validation Prec@1 81.750 	Validation Prec@5 98.460 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 44

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [43][0/97]	Time 0.735 (0.735)	Data 0.661 (0.661)	Loss 0.1555 (0.1555)	Prec@1 93.359 (93.359)	Prec@5 100.000 (100.000)	Acc 0.934 (0.934)	
TRAINING - Epoch: [43][10/97]	Time 0.073 (0.142)	Data 0.000 (0.067)	Loss 0.2577 (0.1975)	Prec@1 91.602 (92.809)	Prec@5 99.414 (99.840)	Acc 0.928 (0.931)	
TRAINING - Epoch: [43][20/97]	Time 0.073 (0.109)	Data 0.000 (0.035)	Loss 0.2139 (0.1894)	Prec@1 91.992 (93.313)	Prec@5 100.000 (99.888)	Acc 0.933 (0.931)	
TRAINING - Epoch: [43][30/97]	Time 0.073 (0.097)	Data 0.000 (0.024)	Loss 0.1719 (0.1900)	Prec@1 94.922 (93.347)	Prec@5 100.000 (99.893)	Acc 0.933 (0.932)	
TRAINING - Epoch: [43][40/97]	Time 0.073 (0.091)	Data 0.000 (0.018)	Loss 0.2075 (0.1891)	Prec@1 92.578 (93.369)	Prec@5 100.000 (99.886)	Acc 0.934 (0.932)	
TRAINING - Epoch: [43][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.2535 (0.1901)	Prec@1 91.406 (93.306)	Prec@5 99.805 (99.889)	Acc 0.933 (0.932)	
TRAINING - Epoch: [43][60/97]	Time 0.073 (0.085)	Data 0.000 (0.012)	Loss 0.2139 (0.1924)	Prec@1 91.992 (93.199)	Prec@5 99.805 (99.891)	Acc 0.932 (0.932)	
TRAINING - Epoch: [43][70/97]	Time 0.073 (0.083)	Data 0.000 (0.011)	Loss 0.1847 (0.1954)	Prec@1 92.773 (93.126)	Prec@5 100.000 (99.901)	Acc 0.931 (0.932)	
TRAINING - Epoch: [43][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.1939 (0.1964)	Prec@1 93.359 (93.084)	Prec@5 100.000 (99.896)	Acc 0.931 (0.932)	
TRAINING - Epoch: [43][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.1831 (0.1984)	Prec@1 93.359 (93.007)	Prec@5 100.000 (99.901)	Acc 0.930 (0.932)	
TRAINING - Epoch: [43][96/97]	Time 0.073 (0.080)	Data 0.000 (0.008)	Loss 0.1904 (0.1990)	Prec@1 93.164 (92.993)	Prec@5 99.805 (99.891)	Acc 0.930 (0.932)	
EVALUATING - Epoch: [43][0/20]	Time 0.484 (0.484)	Data 0.462 (0.462)	Loss 0.4147 (0.4147)	Prec@1 88.086 (88.086)	Prec@5 99.805 (99.805)	Acc 0.881 (0.881)	
EVALUATING - Epoch: [43][10/20]	Time 0.016 (0.076)	Data 0.000 (0.057)	Loss 0.4088 (0.4368)	Prec@1 86.133 (86.754)	Prec@5 100.000 (99.308)	Acc 0.868 (0.871)	
EVALUATING - Epoch: [43][19/20]	Time 0.009 (0.051)	Data 0.000 (0.034)	Loss 0.4215 (0.4266)	Prec@1 86.029 (86.820)	Prec@5 100.000 (99.480)	Acc 0.868 (0.869)	

Results - Epoch: 44
Training Loss 0.1990 	Training Prec@1 92.993 	Training Prec@5 99.891 	Validation Loss 0.4266 	Validation Prec@1 86.820 	Validation Prec@5 99.480 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 45

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [44][0/97]	Time 0.857 (0.857)	Data 0.783 (0.783)	Loss 0.1935 (0.1935)	Prec@1 93.750 (93.750)	Prec@5 100.000 (100.000)	Acc 0.938 (0.938)	
TRAINING - Epoch: [44][10/97]	Time 0.073 (0.146)	Data 0.000 (0.071)	Loss 0.1622 (0.1888)	Prec@1 93.945 (93.235)	Prec@5 99.805 (99.822)	Acc 0.932 (0.933)	
TRAINING - Epoch: [44][20/97]	Time 0.073 (0.111)	Data 0.000 (0.038)	Loss 0.2217 (0.1917)	Prec@1 93.555 (93.341)	Prec@5 99.805 (99.805)	Acc 0.933 (0.933)	
TRAINING - Epoch: [44][30/97]	Time 0.073 (0.099)	Data 0.000 (0.025)	Loss 0.1807 (0.1912)	Prec@1 93.555 (93.277)	Prec@5 100.000 (99.824)	Acc 0.933 (0.933)	
TRAINING - Epoch: [44][40/97]	Time 0.073 (0.092)	Data 0.000 (0.019)	Loss 0.1973 (0.1907)	Prec@1 92.578 (93.240)	Prec@5 99.805 (99.848)	Acc 0.932 (0.932)	
TRAINING - Epoch: [44][50/97]	Time 0.073 (0.089)	Data 0.000 (0.016)	Loss 0.1834 (0.1896)	Prec@1 94.922 (93.252)	Prec@5 100.000 (99.862)	Acc 0.933 (0.932)	
TRAINING - Epoch: [44][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.2191 (0.1927)	Prec@1 92.188 (93.145)	Prec@5 100.000 (99.859)	Acc 0.931 (0.932)	
TRAINING - Epoch: [44][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.1863 (0.1947)	Prec@1 92.188 (93.095)	Prec@5 99.805 (99.871)	Acc 0.931 (0.932)	
TRAINING - Epoch: [44][80/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.2203 (0.1955)	Prec@1 92.578 (93.051)	Prec@5 99.805 (99.877)	Acc 0.931 (0.932)	
TRAINING - Epoch: [44][90/97]	Time 0.072 (0.082)	Data 0.000 (0.009)	Loss 0.1974 (0.1963)	Prec@1 92.773 (93.022)	Prec@5 99.805 (99.880)	Acc 0.930 (0.932)	
TRAINING - Epoch: [44][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.1819 (0.1964)	Prec@1 93.164 (93.021)	Prec@5 100.000 (99.883)	Acc 0.930 (0.932)	
EVALUATING - Epoch: [44][0/20]	Time 0.650 (0.650)	Data 0.631 (0.631)	Loss 0.5569 (0.5569)	Prec@1 84.766 (84.766)	Prec@5 99.219 (99.219)	Acc 0.848 (0.848)	
EVALUATING - Epoch: [44][10/20]	Time 0.016 (0.082)	Data 0.000 (0.059)	Loss 0.5084 (0.5708)	Prec@1 84.766 (84.411)	Prec@5 99.805 (99.041)	Acc 0.844 (0.845)	
EVALUATING - Epoch: [44][19/20]	Time 0.009 (0.052)	Data 0.000 (0.032)	Loss 0.5229 (0.5503)	Prec@1 86.029 (84.740)	Prec@5 99.632 (99.230)	Acc 0.847 (0.845)	

Results - Epoch: 45
Training Loss 0.1964 	Training Prec@1 93.021 	Training Prec@5 99.883 	Validation Loss 0.5503 	Validation Prec@1 84.740 	Validation Prec@5 99.230 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 46

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [45][0/97]	Time 0.724 (0.724)	Data 0.644 (0.644)	Loss 0.1716 (0.1716)	Prec@1 94.141 (94.141)	Prec@5 99.609 (99.609)	Acc 0.941 (0.941)	
TRAINING - Epoch: [45][10/97]	Time 0.073 (0.145)	Data 0.000 (0.068)	Loss 0.2073 (0.1711)	Prec@1 93.945 (94.141)	Prec@5 99.805 (99.822)	Acc 0.941 (0.944)	
TRAINING - Epoch: [45][20/97]	Time 0.073 (0.111)	Data 0.000 (0.036)	Loss 0.2087 (0.1827)	Prec@1 91.797 (93.694)	Prec@5 100.000 (99.888)	Acc 0.937 (0.942)	
TRAINING - Epoch: [45][30/97]	Time 0.073 (0.098)	Data 0.000 (0.024)	Loss 0.1909 (0.1875)	Prec@1 93.359 (93.385)	Prec@5 99.805 (99.880)	Acc 0.934 (0.940)	
TRAINING - Epoch: [45][40/97]	Time 0.073 (0.092)	Data 0.000 (0.019)	Loss 0.1697 (0.1895)	Prec@1 94.141 (93.340)	Prec@5 100.000 (99.881)	Acc 0.933 (0.938)	
TRAINING - Epoch: [45][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.1789 (0.1880)	Prec@1 93.945 (93.409)	Prec@5 99.805 (99.885)	Acc 0.934 (0.937)	
TRAINING - Epoch: [45][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.1560 (0.1873)	Prec@1 94.141 (93.388)	Prec@5 99.805 (99.894)	Acc 0.934 (0.937)	
TRAINING - Epoch: [45][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.2100 (0.1903)	Prec@1 91.992 (93.249)	Prec@5 99.805 (99.895)	Acc 0.932 (0.936)	
TRAINING - Epoch: [45][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.2120 (0.1918)	Prec@1 93.164 (93.234)	Prec@5 99.414 (99.882)	Acc 0.932 (0.936)	
TRAINING - Epoch: [45][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.2366 (0.1932)	Prec@1 92.188 (93.226)	Prec@5 99.805 (99.876)	Acc 0.932 (0.935)	
TRAINING - Epoch: [45][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.2563 (0.1942)	Prec@1 92.773 (93.200)	Prec@5 99.805 (99.881)	Acc 0.932 (0.935)	
EVALUATING - Epoch: [45][0/20]	Time 0.517 (0.517)	Data 0.500 (0.500)	Loss 0.4357 (0.4357)	Prec@1 86.133 (86.133)	Prec@5 100.000 (100.000)	Acc 0.861 (0.861)	
EVALUATING - Epoch: [45][10/20]	Time 0.026 (0.078)	Data 0.010 (0.062)	Loss 0.5392 (0.5590)	Prec@1 83.984 (84.677)	Prec@5 99.219 (99.094)	Acc 0.847 (0.848)	
EVALUATING - Epoch: [45][19/20]	Time 0.009 (0.050)	Data 0.000 (0.035)	Loss 0.5532 (0.5440)	Prec@1 86.029 (84.870)	Prec@5 100.000 (99.340)	Acc 0.849 (0.848)	

Results - Epoch: 46
Training Loss 0.1942 	Training Prec@1 93.200 	Training Prec@5 99.881 	Validation Loss 0.5440 	Validation Prec@1 84.870 	Validation Prec@5 99.340 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 47

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [46][0/97]	Time 0.841 (0.841)	Data 0.760 (0.760)	Loss 0.1912 (0.1912)	Prec@1 93.164 (93.164)	Prec@5 100.000 (100.000)	Acc 0.932 (0.932)	
TRAINING - Epoch: [46][10/97]	Time 0.073 (0.145)	Data 0.000 (0.069)	Loss 0.2125 (0.1857)	Prec@1 93.164 (93.821)	Prec@5 99.805 (99.929)	Acc 0.938 (0.937)	
TRAINING - Epoch: [46][20/97]	Time 0.073 (0.111)	Data 0.000 (0.036)	Loss 0.2326 (0.1932)	Prec@1 90.625 (93.359)	Prec@5 99.609 (99.870)	Acc 0.934 (0.936)	
TRAINING - Epoch: [46][30/97]	Time 0.073 (0.098)	Data 0.000 (0.025)	Loss 0.1908 (0.1885)	Prec@1 92.383 (93.492)	Prec@5 100.000 (99.887)	Acc 0.935 (0.936)	
TRAINING - Epoch: [46][40/97]	Time 0.072 (0.092)	Data 0.000 (0.019)	Loss 0.1831 (0.1866)	Prec@1 94.727 (93.536)	Prec@5 100.000 (99.890)	Acc 0.935 (0.936)	
TRAINING - Epoch: [46][50/97]	Time 0.073 (0.088)	Data 0.000 (0.015)	Loss 0.1877 (0.1891)	Prec@1 93.164 (93.501)	Prec@5 100.000 (99.897)	Acc 0.935 (0.936)	
TRAINING - Epoch: [46][60/97]	Time 0.073 (0.086)	Data 0.000 (0.013)	Loss 0.1778 (0.1897)	Prec@1 94.531 (93.475)	Prec@5 100.000 (99.891)	Acc 0.935 (0.936)	
TRAINING - Epoch: [46][70/97]	Time 0.073 (0.084)	Data 0.000 (0.011)	Loss 0.1967 (0.1928)	Prec@1 93.750 (93.348)	Prec@5 100.000 (99.884)	Acc 0.933 (0.935)	
TRAINING - Epoch: [46][80/97]	Time 0.073 (0.082)	Data 0.000 (0.010)	Loss 0.1858 (0.1937)	Prec@1 93.555 (93.241)	Prec@5 100.000 (99.884)	Acc 0.932 (0.935)	
TRAINING - Epoch: [46][90/97]	Time 0.072 (0.081)	Data 0.000 (0.009)	Loss 0.1838 (0.1945)	Prec@1 94.531 (93.231)	Prec@5 100.000 (99.893)	Acc 0.932 (0.935)	
TRAINING - Epoch: [46][96/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.1585 (0.1945)	Prec@1 95.508 (93.231)	Prec@5 99.805 (99.889)	Acc 0.932 (0.935)	
EVALUATING - Epoch: [46][0/20]	Time 0.532 (0.532)	Data 0.516 (0.516)	Loss 0.3837 (0.3837)	Prec@1 88.281 (88.281)	Prec@5 99.805 (99.805)	Acc 0.883 (0.883)	
EVALUATING - Epoch: [46][10/20]	Time 0.020 (0.079)	Data 0.005 (0.062)	Loss 0.5340 (0.4689)	Prec@1 85.547 (86.594)	Prec@5 99.023 (99.414)	Acc 0.866 (0.868)	
EVALUATING - Epoch: [46][19/20]	Time 0.009 (0.050)	Data 0.000 (0.034)	Loss 0.5111 (0.4548)	Prec@1 86.029 (86.850)	Prec@5 100.000 (99.540)	Acc 0.869 (0.868)	

Results - Epoch: 47
Training Loss 0.1945 	Training Prec@1 93.231 	Training Prec@5 99.889 	Validation Loss 0.4548 	Validation Prec@1 86.850 	Validation Prec@5 99.540 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 48

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [47][0/97]	Time 0.734 (0.734)	Data 0.654 (0.654)	Loss 0.1693 (0.1693)	Prec@1 94.141 (94.141)	Prec@5 100.000 (100.000)	Acc 0.941 (0.941)	
TRAINING - Epoch: [47][10/97]	Time 0.073 (0.139)	Data 0.000 (0.062)	Loss 0.2234 (0.1693)	Prec@1 92.578 (94.052)	Prec@5 99.805 (99.911)	Acc 0.941 (0.943)	
TRAINING - Epoch: [47][20/97]	Time 0.073 (0.107)	Data 0.000 (0.033)	Loss 0.1595 (0.1710)	Prec@1 93.359 (94.085)	Prec@5 100.000 (99.851)	Acc 0.941 (0.942)	
TRAINING - Epoch: [47][30/97]	Time 0.073 (0.096)	Data 0.000 (0.022)	Loss 0.1373 (0.1696)	Prec@1 94.727 (93.977)	Prec@5 100.000 (99.861)	Acc 0.940 (0.941)	
TRAINING - Epoch: [47][40/97]	Time 0.073 (0.090)	Data 0.000 (0.017)	Loss 0.1580 (0.1685)	Prec@1 94.141 (93.950)	Prec@5 100.000 (99.852)	Acc 0.940 (0.941)	
TRAINING - Epoch: [47][50/97]	Time 0.073 (0.087)	Data 0.000 (0.014)	Loss 0.2064 (0.1719)	Prec@1 92.578 (93.907)	Prec@5 100.000 (99.870)	Acc 0.939 (0.941)	
TRAINING - Epoch: [47][60/97]	Time 0.073 (0.085)	Data 0.000 (0.011)	Loss 0.1656 (0.1759)	Prec@1 93.750 (93.747)	Prec@5 100.000 (99.872)	Acc 0.937 (0.940)	
TRAINING - Epoch: [47][70/97]	Time 0.073 (0.083)	Data 0.000 (0.010)	Loss 0.1887 (0.1788)	Prec@1 92.969 (93.676)	Prec@5 99.805 (99.868)	Acc 0.937 (0.940)	
TRAINING - Epoch: [47][80/97]	Time 0.073 (0.082)	Data 0.000 (0.009)	Loss 0.1810 (0.1807)	Prec@1 94.141 (93.627)	Prec@5 100.000 (99.865)	Acc 0.936 (0.939)	
TRAINING - Epoch: [47][90/97]	Time 0.072 (0.081)	Data 0.000 (0.008)	Loss 0.1600 (0.1813)	Prec@1 93.945 (93.602)	Prec@5 100.000 (99.858)	Acc 0.936 (0.939)	
TRAINING - Epoch: [47][96/97]	Time 0.072 (0.080)	Data 0.000 (0.007)	Loss 0.1798 (0.1817)	Prec@1 93.359 (93.571)	Prec@5 99.805 (99.855)	Acc 0.936 (0.939)	
EVALUATING - Epoch: [47][0/20]	Time 0.678 (0.678)	Data 0.662 (0.662)	Loss 0.3941 (0.3941)	Prec@1 85.742 (85.742)	Prec@5 99.609 (99.609)	Acc 0.857 (0.857)	
EVALUATING - Epoch: [47][10/20]	Time 0.016 (0.083)	Data 0.000 (0.067)	Loss 0.4631 (0.4688)	Prec@1 85.742 (85.973)	Prec@5 99.609 (99.237)	Acc 0.860 (0.858)	
EVALUATING - Epoch: [47][19/20]	Time 0.009 (0.052)	Data 0.000 (0.037)	Loss 0.3916 (0.4587)	Prec@1 87.868 (85.900)	Prec@5 99.632 (99.440)	Acc 0.859 (0.859)	

Results - Epoch: 48
Training Loss 0.1817 	Training Prec@1 93.571 	Training Prec@5 99.855 	Validation Loss 0.4587 	Validation Prec@1 85.900 	Validation Prec@5 99.440 	

/scratch/tor213/DLS/question4/Hoffer/utils/log.py:163: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.
  self.results = self.results.append(df, ignore_index=True)

Starting Epoch: 49

/scratch/tor213/.env/lib64/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
TRAINING - Epoch: [48][0/97]	Time 0.776 (0.776)	Data 0.685 (0.685)	Loss 0.1903 (0.1903)	Prec@1 93.945 (93.945)	Prec@5 99.805 (99.805)	Acc 0.939 (0.939)	
TRAINING - Epoch: [48][10/97]	Time 0.073 (0.141)	Data 0.000 (0.063)	Loss 0.1858 (0.1703)	Prec@1 92.773 (94.070)	Prec@5 100.000 (99.893)	Acc 0.941 (0.943)	
TRAINING - Epoch: [48][20/97]	Time 0.073 (0.108)	Data 0.000 (0.033)	Loss 0.1295 (0.1641)	Prec@1 96.484 (94.308)	Prec@5 99.805 (99.916)	Acc 0.943 (0.942)	
slurmstepd: error: *** JOB 16880092 ON gv001 CANCELLED AT 2022-03-31T05:45:15 ***
