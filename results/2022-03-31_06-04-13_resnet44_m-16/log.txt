2022-03-31 06:04:13,431 - INFO - saving to results/2022-03-31_06-04-13_resnet44_m-16
2022-03-31 06:04:13,434 - DEBUG - run arguments: Namespace(adapt_grad_norm=None, autoaugment=False, batch_size=64, chunk_batch=1, config_file=None, cutmix=None, cutout=True, dataset='cifar10', datasets_dir='~/Datasets', device='cuda', device_ids=[0], dist_backend='nccl', dist_init='env://', distributed=False, drop_optim_state=False, dtype='float', duplicates=16, epochs=100, eval_batch_size=-1, evaluate=None, grad_clip=-1, input_size=None, label_smoothing=0, local_rank=-1, loss_scale=1, lr=0.1, mixup=None, model='resnet', model_config="{'depth': 44}", momentum=0.9, optimizer='SGD', print_freq=10, results_dir='results/', resume='', save='2022-03-31_06-04-13', save_all=False, seed=123, start_epoch=-1, sync_bn=False, tensorwatch=False, tensorwatch_port=0, weight_decay=0, workers=8, world_size=-1)
2022-03-31 06:04:13,434 - INFO - creating model resnet
2022-03-31 06:04:13,481 - INFO - created model with configuration: {'dataset': 'cifar10', 'depth': 44}
2022-03-31 06:04:13,482 - INFO - number of parameters: 661338
2022-03-31 06:04:18,732 - INFO - optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x147af9b94a60>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x147af9b94820>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]
2022-03-31 06:04:18,736 - INFO - data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 64, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 16, 'autoaugment': False, 'cutout': {'holes': 1, 'length': 16}}
 Regime:None
2022-03-31 06:04:18,736 - INFO - 
Starting Epoch: 1

2022-03-31 06:04:20,952 - DEBUG - OPTIMIZER - setting lr = 0.1
2022-03-31 06:04:20,952 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-03-31 06:04:21,900 - INFO - TRAINING - Epoch: [0][0/781]	Time 3.164 (3.164)	Data 2.215 (2.215)	Loss 2.3063 (2.3063)	Prec@1 8.203 (8.203)	Prec@5 41.309 (41.309)	Acc 0.082 (0.082)	
2022-03-31 06:04:23,682 - INFO - TRAINING - Epoch: [0][10/781]	Time 0.178 (0.450)	Data 0.000 (0.202)	Loss 2.3270 (2.3034)	Prec@1 10.938 (13.707)	Prec@5 53.906 (55.513)	Acc 0.137 (0.122)	
2022-03-31 06:04:25,463 - INFO - TRAINING - Epoch: [0][20/781]	Time 0.178 (0.320)	Data 0.000 (0.106)	Loss 2.2528 (2.2592)	Prec@1 10.742 (15.332)	Prec@5 64.844 (59.761)	Acc 0.153 (0.136)	
2022-03-31 06:04:27,245 - INFO - TRAINING - Epoch: [0][30/781]	Time 0.178 (0.274)	Data 0.000 (0.072)	Loss 2.1508 (2.2293)	Prec@1 26.172 (16.794)	Prec@5 67.090 (62.579)	Acc 0.168 (0.144)	
2022-03-31 06:04:29,024 - INFO - TRAINING - Epoch: [0][40/781]	Time 0.178 (0.251)	Data 0.000 (0.054)	Loss 2.1896 (2.1883)	Prec@1 20.312 (17.733)	Prec@5 75.293 (66.118)	Acc 0.177 (0.151)	
2022-03-31 06:04:30,806 - INFO - TRAINING - Epoch: [0][50/781]	Time 0.178 (0.237)	Data 0.000 (0.044)	Loss 1.9106 (2.1584)	Prec@1 28.223 (18.834)	Prec@5 80.176 (68.246)	Acc 0.188 (0.158)	
2022-03-31 06:04:32,588 - INFO - TRAINING - Epoch: [0][60/781]	Time 0.178 (0.227)	Data 0.000 (0.037)	Loss 1.9342 (2.1326)	Prec@1 22.461 (19.570)	Prec@5 83.496 (69.968)	Acc 0.196 (0.163)	
2022-03-31 06:04:34,367 - INFO - TRAINING - Epoch: [0][70/781]	Time 0.178 (0.220)	Data 0.000 (0.032)	Loss 2.0180 (2.1189)	Prec@1 26.367 (19.875)	Prec@5 80.762 (71.168)	Acc 0.199 (0.168)	
2022-03-31 06:04:36,147 - INFO - TRAINING - Epoch: [0][80/781]	Time 0.178 (0.215)	Data 0.000 (0.028)	Loss 2.0086 (2.1036)	Prec@1 25.293 (20.434)	Prec@5 74.023 (72.207)	Acc 0.204 (0.172)	
2022-03-31 06:04:37,929 - INFO - TRAINING - Epoch: [0][90/781]	Time 0.178 (0.211)	Data 0.000 (0.025)	Loss 2.0041 (2.0870)	Prec@1 23.438 (21.001)	Prec@5 76.855 (73.264)	Acc 0.210 (0.176)	
2022-03-31 06:04:39,712 - INFO - TRAINING - Epoch: [0][100/781]	Time 0.178 (0.208)	Data 0.000 (0.022)	Loss 1.9243 (2.0711)	Prec@1 29.199 (21.752)	Prec@5 78.125 (74.057)	Acc 0.218 (0.180)	
2022-03-31 06:04:41,491 - INFO - TRAINING - Epoch: [0][110/781]	Time 0.178 (0.205)	Data 0.000 (0.020)	Loss 1.8580 (2.0579)	Prec@1 30.176 (22.229)	Prec@5 80.859 (74.600)	Acc 0.222 (0.183)	
2022-03-31 06:04:43,272 - INFO - TRAINING - Epoch: [0][120/781]	Time 0.178 (0.203)	Data 0.000 (0.019)	Loss 1.8327 (2.0448)	Prec@1 27.441 (22.592)	Prec@5 84.473 (75.224)	Acc 0.226 (0.187)	
2022-03-31 06:04:45,052 - INFO - TRAINING - Epoch: [0][130/781]	Time 0.178 (0.201)	Data 0.000 (0.017)	Loss 1.8687 (2.0303)	Prec@1 30.762 (23.112)	Prec@5 84.082 (75.884)	Acc 0.231 (0.190)	
2022-03-31 06:04:46,831 - INFO - TRAINING - Epoch: [0][140/781]	Time 0.177 (0.199)	Data 0.000 (0.016)	Loss 1.8710 (2.0206)	Prec@1 29.102 (23.384)	Prec@5 84.863 (76.436)	Acc 0.234 (0.193)	
2022-03-31 06:04:48,613 - INFO - TRAINING - Epoch: [0][150/781]	Time 0.178 (0.198)	Data 0.000 (0.015)	Loss 1.8409 (2.0139)	Prec@1 26.367 (23.614)	Prec@5 86.426 (76.826)	Acc 0.236 (0.196)	
2022-03-31 06:04:50,396 - INFO - TRAINING - Epoch: [0][160/781]	Time 0.178 (0.197)	Data 0.000 (0.014)	Loss 2.0009 (2.0034)	Prec@1 25.781 (23.954)	Prec@5 80.371 (77.299)	Acc 0.240 (0.198)	
2022-03-31 06:04:52,177 - INFO - TRAINING - Epoch: [0][170/781]	Time 0.178 (0.196)	Data 0.000 (0.013)	Loss 1.9083 (1.9956)	Prec@1 22.949 (24.158)	Prec@5 79.102 (77.670)	Acc 0.242 (0.201)	
2022-03-31 06:04:53,960 - INFO - TRAINING - Epoch: [0][180/781]	Time 0.178 (0.195)	Data 0.000 (0.013)	Loss 1.7473 (1.9840)	Prec@1 26.367 (24.551)	Prec@5 85.645 (78.118)	Acc 0.246 (0.203)	
2022-03-31 06:04:55,742 - INFO - TRAINING - Epoch: [0][190/781]	Time 0.178 (0.194)	Data 0.000 (0.012)	Loss 1.7742 (1.9736)	Prec@1 37.207 (24.932)	Prec@5 84.961 (78.552)	Acc 0.249 (0.206)	
2022-03-31 06:04:57,524 - INFO - TRAINING - Epoch: [0][200/781]	Time 0.178 (0.193)	Data 0.000 (0.012)	Loss 1.7772 (1.9647)	Prec@1 31.738 (25.104)	Prec@5 85.840 (78.935)	Acc 0.251 (0.208)	
2022-03-31 06:04:59,305 - INFO - TRAINING - Epoch: [0][210/781]	Time 0.178 (0.192)	Data 0.000 (0.011)	Loss 1.7410 (1.9562)	Prec@1 34.863 (25.381)	Prec@5 90.430 (79.307)	Acc 0.254 (0.210)	
2022-03-31 06:05:01,086 - INFO - TRAINING - Epoch: [0][220/781]	Time 0.178 (0.192)	Data 0.000 (0.011)	Loss 1.8913 (1.9481)	Prec@1 31.348 (25.767)	Prec@5 82.617 (79.616)	Acc 0.258 (0.212)	
2022-03-31 06:05:02,868 - INFO - TRAINING - Epoch: [0][230/781]	Time 0.178 (0.191)	Data 0.000 (0.010)	Loss 1.7399 (1.9397)	Prec@1 32.910 (26.076)	Prec@5 87.988 (79.945)	Acc 0.261 (0.214)	
2022-03-31 06:05:04,649 - INFO - TRAINING - Epoch: [0][240/781]	Time 0.178 (0.191)	Data 0.000 (0.010)	Loss 1.5999 (1.9297)	Prec@1 39.258 (26.447)	Prec@5 91.797 (80.300)	Acc 0.264 (0.216)	
2022-03-31 06:05:06,430 - INFO - TRAINING - Epoch: [0][250/781]	Time 0.178 (0.190)	Data 0.000 (0.009)	Loss 1.6927 (1.9206)	Prec@1 36.523 (26.817)	Prec@5 87.598 (80.622)	Acc 0.268 (0.218)	
2022-03-31 06:05:08,211 - INFO - TRAINING - Epoch: [0][260/781]	Time 0.178 (0.190)	Data 0.000 (0.009)	Loss 1.9359 (1.9157)	Prec@1 30.566 (26.985)	Prec@5 82.617 (80.819)	Acc 0.270 (0.220)	
2022-03-31 06:05:09,992 - INFO - TRAINING - Epoch: [0][270/781]	Time 0.178 (0.189)	Data 0.000 (0.009)	Loss 1.7712 (1.9087)	Prec@1 34.766 (27.235)	Prec@5 83.887 (81.068)	Acc 0.272 (0.222)	
2022-03-31 06:05:11,774 - INFO - TRAINING - Epoch: [0][280/781]	Time 0.178 (0.189)	Data 0.000 (0.008)	Loss 1.5482 (1.8988)	Prec@1 45.117 (27.631)	Prec@5 90.137 (81.358)	Acc 0.276 (0.224)	
2022-03-31 06:05:13,553 - INFO - TRAINING - Epoch: [0][290/781]	Time 0.178 (0.188)	Data 0.000 (0.008)	Loss 1.8632 (1.8912)	Prec@1 24.805 (27.916)	Prec@5 85.352 (81.607)	Acc 0.279 (0.226)	
2022-03-31 06:05:15,334 - INFO - TRAINING - Epoch: [0][300/781]	Time 0.178 (0.188)	Data 0.000 (0.008)	Loss 1.4839 (1.8834)	Prec@1 46.094 (28.194)	Prec@5 91.797 (81.815)	Acc 0.282 (0.228)	
2022-03-31 06:05:17,120 - INFO - TRAINING - Epoch: [0][310/781]	Time 0.178 (0.188)	Data 0.000 (0.008)	Loss 1.6180 (1.8763)	Prec@1 34.570 (28.520)	Prec@5 90.332 (82.005)	Acc 0.285 (0.229)	
2022-03-31 06:05:18,906 - INFO - TRAINING - Epoch: [0][320/781]	Time 0.179 (0.187)	Data 0.000 (0.007)	Loss 1.7461 (1.8708)	Prec@1 29.980 (28.765)	Prec@5 86.426 (82.189)	Acc 0.288 (0.231)	
2022-03-31 06:05:20,693 - INFO - TRAINING - Epoch: [0][330/781]	Time 0.178 (0.187)	Data 0.000 (0.007)	Loss 1.5535 (1.8641)	Prec@1 45.215 (29.001)	Prec@5 87.695 (82.395)	Acc 0.290 (0.233)	
2022-03-31 06:05:22,481 - INFO - TRAINING - Epoch: [0][340/781]	Time 0.179 (0.187)	Data 0.000 (0.007)	Loss 1.7741 (1.8566)	Prec@1 32.129 (29.350)	Prec@5 89.062 (82.604)	Acc 0.294 (0.235)	
2022-03-31 06:05:24,269 - INFO - TRAINING - Epoch: [0][350/781]	Time 0.179 (0.187)	Data 0.000 (0.007)	Loss 1.7730 (1.8508)	Prec@1 31.641 (29.606)	Prec@5 86.035 (82.761)	Acc 0.296 (0.236)	
