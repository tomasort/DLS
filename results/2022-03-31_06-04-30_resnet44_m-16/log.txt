2022-03-31 06:04:30,224 - INFO - saving to results/2022-03-31_06-04-30_resnet44_m-16
2022-03-31 06:04:30,225 - DEBUG - run arguments: Namespace(adapt_grad_norm=None, autoaugment=False, batch_size=64, chunk_batch=1, config_file=None, cutmix=None, cutout=True, dataset='cifar10', datasets_dir='~/Datasets', device='cuda', device_ids=[0], dist_backend='nccl', dist_init='env://', distributed=False, drop_optim_state=False, dtype='float', duplicates=16, epochs=100, eval_batch_size=-1, evaluate=None, grad_clip=-1, input_size=None, label_smoothing=0, local_rank=-1, loss_scale=1, lr=0.1, mixup=None, model='resnet', model_config="{'depth': 44}", momentum=0.9, optimizer='SGD', print_freq=10, results_dir='results/', resume='', save='2022-03-31_06-04-30', save_all=False, seed=123, start_epoch=-1, sync_bn=False, tensorwatch=False, tensorwatch_port=0, weight_decay=0, workers=8, world_size=-1)
2022-03-31 06:04:30,225 - INFO - creating model resnet
2022-03-31 06:04:30,276 - INFO - created model with configuration: {'dataset': 'cifar10', 'depth': 44}
2022-03-31 06:04:30,277 - INFO - number of parameters: 661338
2022-03-31 06:04:35,587 - INFO - optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x14ee20de3a60>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x14ee20de3820>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]
2022-03-31 06:04:35,590 - INFO - data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 64, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 16, 'autoaugment': False, 'cutout': {'holes': 1, 'length': 16}}
 Regime:None
2022-03-31 06:04:35,590 - INFO - 
Starting Epoch: 1

2022-03-31 06:04:38,072 - DEBUG - OPTIMIZER - setting lr = 0.1
2022-03-31 06:04:38,073 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-03-31 06:04:38,833 - INFO - TRAINING - Epoch: [0][0/781]	Time 3.242 (3.242)	Data 2.481 (2.481)	Loss 2.3063 (2.3063)	Prec@1 8.203 (8.203)	Prec@5 41.309 (41.309)	Acc 0.082 (0.082)	
2022-03-31 06:04:40,619 - INFO - TRAINING - Epoch: [0][10/781]	Time 0.178 (0.457)	Data 0.000 (0.226)	Loss 2.3270 (2.3034)	Prec@1 10.938 (13.707)	Prec@5 53.906 (55.513)	Acc 0.137 (0.122)	
2022-03-31 06:04:42,401 - INFO - TRAINING - Epoch: [0][20/781]	Time 0.178 (0.324)	Data 0.000 (0.118)	Loss 2.2528 (2.2592)	Prec@1 10.742 (15.332)	Prec@5 64.844 (59.761)	Acc 0.153 (0.136)	
2022-03-31 06:04:44,185 - INFO - TRAINING - Epoch: [0][30/781]	Time 0.178 (0.277)	Data 0.000 (0.080)	Loss 2.1510 (2.2293)	Prec@1 26.172 (16.784)	Prec@5 67.090 (62.582)	Acc 0.168 (0.144)	
2022-03-31 06:04:45,971 - INFO - TRAINING - Epoch: [0][40/781]	Time 0.178 (0.253)	Data 0.000 (0.061)	Loss 2.1898 (2.1883)	Prec@1 20.312 (17.728)	Prec@5 75.293 (66.128)	Acc 0.177 (0.151)	
2022-03-31 06:04:47,755 - INFO - TRAINING - Epoch: [0][50/781]	Time 0.178 (0.239)	Data 0.000 (0.049)	Loss 1.9117 (2.1585)	Prec@1 28.027 (18.807)	Prec@5 80.273 (68.267)	Acc 0.188 (0.157)	
2022-03-31 06:04:49,536 - INFO - TRAINING - Epoch: [0][60/781]	Time 0.178 (0.229)	Data 0.000 (0.041)	Loss 1.9364 (2.1327)	Prec@1 21.094 (19.502)	Prec@5 83.496 (69.996)	Acc 0.195 (0.163)	
2022-03-31 06:04:51,315 - INFO - TRAINING - Epoch: [0][70/781]	Time 0.178 (0.221)	Data 0.000 (0.035)	Loss 2.0180 (2.1189)	Prec@1 25.488 (19.802)	Prec@5 80.664 (71.167)	Acc 0.198 (0.168)	
2022-03-31 06:04:53,095 - INFO - TRAINING - Epoch: [0][80/781]	Time 0.178 (0.216)	Data 0.000 (0.031)	Loss 2.0105 (2.1035)	Prec@1 25.488 (20.370)	Prec@5 73.926 (72.197)	Acc 0.204 (0.172)	
2022-03-31 06:04:54,876 - INFO - TRAINING - Epoch: [0][90/781]	Time 0.178 (0.212)	Data 0.000 (0.028)	Loss 2.0038 (2.0868)	Prec@1 22.852 (20.925)	Prec@5 76.953 (73.288)	Acc 0.209 (0.176)	
2022-03-31 06:04:56,659 - INFO - TRAINING - Epoch: [0][100/781]	Time 0.178 (0.209)	Data 0.000 (0.025)	Loss 1.9234 (2.0708)	Prec@1 29.297 (21.691)	Prec@5 77.734 (74.069)	Acc 0.217 (0.179)	
2022-03-31 06:04:58,439 - INFO - TRAINING - Epoch: [0][110/781]	Time 0.178 (0.206)	Data 0.000 (0.023)	Loss 1.8510 (2.0575)	Prec@1 30.371 (22.189)	Prec@5 81.738 (74.630)	Acc 0.222 (0.183)	
2022-03-31 06:05:00,218 - INFO - TRAINING - Epoch: [0][120/781]	Time 0.178 (0.204)	Data 0.000 (0.021)	Loss 1.8325 (2.0450)	Prec@1 27.246 (22.551)	Prec@5 84.668 (75.238)	Acc 0.226 (0.186)	
2022-03-31 06:05:01,996 - INFO - TRAINING - Epoch: [0][130/781]	Time 0.178 (0.202)	Data 0.000 (0.019)	Loss 1.8750 (2.0305)	Prec@1 31.055 (23.093)	Prec@5 84.473 (75.901)	Acc 0.231 (0.190)	
2022-03-31 06:05:03,778 - INFO - TRAINING - Epoch: [0][140/781]	Time 0.178 (0.200)	Data 0.000 (0.018)	Loss 1.8773 (2.0210)	Prec@1 28.516 (23.343)	Prec@5 84.668 (76.435)	Acc 0.233 (0.193)	
2022-03-31 06:05:05,559 - INFO - TRAINING - Epoch: [0][150/781]	Time 0.178 (0.198)	Data 0.000 (0.017)	Loss 1.8263 (2.0147)	Prec@1 29.297 (23.552)	Prec@5 86.621 (76.825)	Acc 0.236 (0.195)	
2022-03-31 06:05:07,340 - INFO - TRAINING - Epoch: [0][160/781]	Time 0.178 (0.197)	Data 0.000 (0.016)	Loss 2.0273 (2.0049)	Prec@1 25.098 (23.872)	Prec@5 80.957 (77.298)	Acc 0.239 (0.198)	
2022-03-31 06:05:09,121 - INFO - TRAINING - Epoch: [0][170/781]	Time 0.178 (0.196)	Data 0.000 (0.015)	Loss 1.8997 (1.9971)	Prec@1 25.586 (24.119)	Prec@5 78.320 (77.656)	Acc 0.241 (0.200)	
2022-03-31 06:05:10,901 - INFO - TRAINING - Epoch: [0][180/781]	Time 0.178 (0.195)	Data 0.000 (0.014)	Loss 1.7459 (1.9855)	Prec@1 25.781 (24.501)	Prec@5 86.035 (78.146)	Acc 0.245 (0.203)	
2022-03-31 06:05:12,681 - INFO - TRAINING - Epoch: [0][190/781]	Time 0.178 (0.194)	Data 0.000 (0.013)	Loss 1.7638 (1.9752)	Prec@1 36.426 (24.867)	Prec@5 82.812 (78.568)	Acc 0.249 (0.205)	
2022-03-31 06:05:14,463 - INFO - TRAINING - Epoch: [0][200/781]	Time 0.178 (0.193)	Data 0.000 (0.013)	Loss 1.7746 (1.9657)	Prec@1 32.031 (25.049)	Prec@5 86.230 (78.938)	Acc 0.250 (0.207)	
2022-03-31 06:05:16,243 - INFO - TRAINING - Epoch: [0][210/781]	Time 0.178 (0.193)	Data 0.000 (0.012)	Loss 1.7104 (1.9569)	Prec@1 35.059 (25.330)	Prec@5 89.648 (79.286)	Acc 0.253 (0.210)	
2022-03-31 06:05:18,023 - INFO - TRAINING - Epoch: [0][220/781]	Time 0.178 (0.192)	Data 0.000 (0.012)	Loss 1.8991 (1.9490)	Prec@1 31.934 (25.722)	Prec@5 83.496 (79.616)	Acc 0.257 (0.212)	
2022-03-31 06:05:19,803 - INFO - TRAINING - Epoch: [0][230/781]	Time 0.178 (0.191)	Data 0.000 (0.011)	Loss 1.8047 (1.9411)	Prec@1 29.883 (25.981)	Prec@5 87.305 (79.972)	Acc 0.260 (0.214)	
2022-03-31 06:05:21,584 - INFO - TRAINING - Epoch: [0][240/781]	Time 0.178 (0.191)	Data 0.000 (0.011)	Loss 1.6114 (1.9313)	Prec@1 39.648 (26.368)	Prec@5 90.430 (80.311)	Acc 0.264 (0.216)	
2022-03-31 06:05:23,367 - INFO - TRAINING - Epoch: [0][250/781]	Time 0.178 (0.190)	Data 0.000 (0.010)	Loss 1.6695 (1.9222)	Prec@1 36.133 (26.729)	Prec@5 88.281 (80.633)	Acc 0.267 (0.218)	
2022-03-31 06:05:25,148 - INFO - TRAINING - Epoch: [0][260/781]	Time 0.178 (0.190)	Data 0.000 (0.010)	Loss 1.9459 (1.9169)	Prec@1 28.418 (26.898)	Prec@5 80.078 (80.829)	Acc 0.269 (0.220)	
2022-03-31 06:05:26,931 - INFO - TRAINING - Epoch: [0][270/781]	Time 0.178 (0.189)	Data 0.000 (0.010)	Loss 1.7908 (1.9103)	Prec@1 32.227 (27.134)	Prec@5 83.984 (81.088)	Acc 0.271 (0.221)	
2022-03-31 06:05:28,713 - INFO - TRAINING - Epoch: [0][280/781]	Time 0.178 (0.189)	Data 0.000 (0.009)	Loss 1.5678 (1.9009)	Prec@1 45.410 (27.492)	Prec@5 90.137 (81.356)	Acc 0.275 (0.223)	
2022-03-31 06:05:30,494 - INFO - TRAINING - Epoch: [0][290/781]	Time 0.178 (0.189)	Data 0.000 (0.009)	Loss 1.8666 (1.8934)	Prec@1 23.926 (27.768)	Prec@5 84.668 (81.609)	Acc 0.278 (0.225)	
2022-03-31 06:05:32,275 - INFO - TRAINING - Epoch: [0][300/781]	Time 0.178 (0.188)	Data 0.000 (0.009)	Loss 1.4863 (1.8856)	Prec@1 46.973 (28.065)	Prec@5 91.309 (81.817)	Acc 0.281 (0.227)	
2022-03-31 06:05:34,057 - INFO - TRAINING - Epoch: [0][310/781]	Time 0.178 (0.188)	Data 0.000 (0.008)	Loss 1.6062 (1.8782)	Prec@1 35.547 (28.386)	Prec@5 91.406 (82.026)	Acc 0.284 (0.229)	
2022-03-31 06:05:35,839 - INFO - TRAINING - Epoch: [0][320/781]	Time 0.178 (0.188)	Data 0.000 (0.008)	Loss 1.7662 (1.8724)	Prec@1 30.859 (28.670)	Prec@5 86.230 (82.217)	Acc 0.287 (0.230)	
2022-03-31 06:05:37,620 - INFO - TRAINING - Epoch: [0][330/781]	Time 0.178 (0.187)	Data 0.000 (0.008)	Loss 1.6012 (1.8656)	Prec@1 45.410 (28.941)	Prec@5 89.258 (82.427)	Acc 0.289 (0.232)	
2022-03-31 06:05:39,401 - INFO - TRAINING - Epoch: [0][340/781]	Time 0.178 (0.187)	Data 0.000 (0.008)	Loss 1.8273 (1.8581)	Prec@1 30.859 (29.298)	Prec@5 87.109 (82.617)	Acc 0.293 (0.234)	
2022-03-31 06:05:41,184 - INFO - TRAINING - Epoch: [0][350/781]	Time 0.178 (0.187)	Data 0.000 (0.007)	Loss 1.7744 (1.8523)	Prec@1 30.371 (29.543)	Prec@5 87.988 (82.782)	Acc 0.295 (0.236)	
2022-03-31 06:05:42,965 - INFO - TRAINING - Epoch: [0][360/781]	Time 0.178 (0.187)	Data 0.000 (0.007)	Loss 1.4718 (1.8455)	Prec@1 41.992 (29.821)	Prec@5 93.555 (82.989)	Acc 0.298 (0.237)	
