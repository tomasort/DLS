2022-03-31 16:05:21,715 - INFO - saving to results/2022-03-31_16-05-21_resnet44_m-8
2022-03-31 16:05:21,715 - DEBUG - run arguments: Namespace(adapt_grad_norm=None, autoaugment=False, batch_size=64, chunk_batch=1, config_file=None, cutmix=None, cutout=True, dataset='cifar10', datasets_dir='~/Datasets', device='cuda', device_ids=[0], dist_backend='nccl', dist_init='env://', distributed=False, drop_optim_state=False, dtype='float', duplicates=8, epochs=100, eval_batch_size=-1, evaluate=None, grad_clip=-1, input_size=None, label_smoothing=0, local_rank=-1, loss_scale=1, lr=0.1, mixup=None, model='resnet', model_config="{'depth': 44}", momentum=0.9, optimizer='SGD', print_freq=10, results_dir='results/', resume='', save='2022-03-31_16-05-21', save_all=False, seed=123, start_epoch=-1, sync_bn=False, tensorwatch=False, tensorwatch_port=0, weight_decay=0, workers=8, world_size=-1)
2022-03-31 16:05:21,715 - INFO - creating model resnet
2022-03-31 16:05:21,780 - INFO - created model with configuration: {'dataset': 'cifar10', 'depth': 44}
2022-03-31 16:05:21,781 - INFO - number of parameters: 661338
2022-03-31 16:05:27,001 - INFO - optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x14f75407aa60>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x14f75407a820>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]
2022-03-31 16:05:27,002 - INFO - data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 64, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 8, 'autoaugment': False, 'cutout': {'holes': 1, 'length': 16}}
 Regime:None
2022-03-31 16:05:27,002 - INFO - 
Starting Epoch: 1

2022-03-31 16:05:30,560 - DEBUG - OPTIMIZER - setting lr = 0.1
2022-03-31 16:05:30,560 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-03-31 16:05:31,342 - INFO - TRAINING - Epoch: [0][0/781]	Time 4.340 (4.340)	Data 3.557 (3.557)	Loss 2.3068 (2.3068)	Prec@1 7.031 (7.031)	Prec@5 42.383 (42.383)	Acc 0.070 (0.070)	
2022-03-31 16:05:32,435 - INFO - TRAINING - Epoch: [0][10/781]	Time 0.110 (0.494)	Data 0.000 (0.324)	Loss 2.3304 (2.3035)	Prec@1 11.328 (13.903)	Prec@5 53.516 (55.273)	Acc 0.139 (0.121)	
2022-03-31 16:05:33,459 - INFO - TRAINING - Epoch: [0][20/781]	Time 0.092 (0.307)	Data 0.000 (0.170)	Loss 2.2553 (2.2595)	Prec@1 9.961 (15.597)	Prec@5 63.867 (59.552)	Acc 0.156 (0.137)	
2022-03-31 16:05:34,449 - INFO - TRAINING - Epoch: [0][30/781]	Time 0.096 (0.240)	Data 0.000 (0.115)	Loss 2.1631 (2.2303)	Prec@1 25.781 (17.043)	Prec@5 67.578 (62.374)	Acc 0.170 (0.145)	
2022-03-31 16:05:35,525 - INFO - TRAINING - Epoch: [0][40/781]	Time 0.113 (0.208)	Data 0.000 (0.087)	Loss 2.1929 (2.1896)	Prec@1 22.656 (18.021)	Prec@5 74.609 (65.930)	Acc 0.180 (0.153)	
2022-03-31 16:05:36,599 - INFO - TRAINING - Epoch: [0][50/781]	Time 0.092 (0.188)	Data 0.000 (0.070)	Loss 1.9209 (2.1597)	Prec@1 24.023 (18.903)	Prec@5 80.078 (67.992)	Acc 0.189 (0.159)	
2022-03-31 16:05:37,709 - INFO - TRAINING - Epoch: [0][60/781]	Time 0.141 (0.176)	Data 0.000 (0.059)	Loss 1.9270 (2.1321)	Prec@1 22.266 (19.714)	Prec@5 82.617 (69.813)	Acc 0.197 (0.165)	
2022-03-31 16:05:38,747 - INFO - TRAINING - Epoch: [0][70/781]	Time 0.092 (0.165)	Data 0.000 (0.051)	Loss 2.0462 (2.1184)	Prec@1 24.023 (19.971)	Prec@5 82.812 (71.113)	Acc 0.200 (0.170)	
2022-03-31 16:05:39,791 - INFO - TRAINING - Epoch: [0][80/781]	Time 0.117 (0.158)	Data 0.000 (0.045)	Loss 1.9959 (2.1031)	Prec@1 27.148 (20.614)	Prec@5 71.875 (72.073)	Acc 0.206 (0.174)	
2022-03-31 16:05:40,804 - INFO - TRAINING - Epoch: [0][90/781]	Time 0.101 (0.152)	Data 0.000 (0.040)	Loss 2.0229 (2.0866)	Prec@1 23.438 (21.162)	Prec@5 74.609 (73.000)	Acc 0.212 (0.178)	
2022-03-31 16:05:41,862 - INFO - TRAINING - Epoch: [0][100/781]	Time 0.092 (0.147)	Data 0.000 (0.036)	Loss 1.9108 (2.0700)	Prec@1 28.516 (21.950)	Prec@5 77.344 (73.791)	Acc 0.220 (0.181)	
2022-03-31 16:05:42,926 - INFO - TRAINING - Epoch: [0][110/781]	Time 0.092 (0.143)	Data 0.000 (0.033)	Loss 1.8962 (2.0583)	Prec@1 28.125 (22.456)	Prec@5 80.078 (74.319)	Acc 0.225 (0.185)	
2022-03-31 16:05:43,979 - INFO - TRAINING - Epoch: [0][120/781]	Time 0.124 (0.140)	Data 0.014 (0.031)	Loss 1.8561 (2.0443)	Prec@1 25.586 (22.819)	Prec@5 84.375 (74.976)	Acc 0.228 (0.189)	
2022-03-31 16:05:45,039 - INFO - TRAINING - Epoch: [0][130/781]	Time 0.119 (0.138)	Data 0.000 (0.029)	Loss 1.9445 (2.0310)	Prec@1 29.492 (23.244)	Prec@5 83.008 (75.669)	Acc 0.232 (0.192)	
2022-03-31 16:05:46,096 - INFO - TRAINING - Epoch: [0][140/781]	Time 0.124 (0.135)	Data 0.000 (0.027)	Loss 1.8439 (2.0192)	Prec@1 28.711 (23.644)	Prec@5 85.938 (76.298)	Acc 0.236 (0.195)	
2022-03-31 16:05:47,094 - INFO - TRAINING - Epoch: [0][150/781]	Time 0.092 (0.133)	Data 0.000 (0.025)	Loss 1.8179 (2.0111)	Prec@1 32.617 (23.912)	Prec@5 84.375 (76.791)	Acc 0.239 (0.198)	
2022-03-31 16:05:48,161 - INFO - TRAINING - Epoch: [0][160/781]	Time 0.112 (0.131)	Data 0.000 (0.023)	Loss 1.9667 (2.0006)	Prec@1 29.492 (24.278)	Prec@5 81.250 (77.282)	Acc 0.243 (0.200)	
2022-03-31 16:05:49,171 - INFO - TRAINING - Epoch: [0][170/781]	Time 0.113 (0.130)	Data 0.000 (0.022)	Loss 1.8709 (1.9928)	Prec@1 25.000 (24.583)	Prec@5 80.859 (77.691)	Acc 0.246 (0.203)	
2022-03-31 16:05:50,242 - INFO - TRAINING - Epoch: [0][180/781]	Time 0.129 (0.128)	Data 0.000 (0.021)	Loss 1.7283 (1.9819)	Prec@1 29.492 (24.975)	Prec@5 87.891 (78.102)	Acc 0.250 (0.205)	
2022-03-31 16:05:51,360 - INFO - TRAINING - Epoch: [0][190/781]	Time 0.114 (0.128)	Data 0.000 (0.020)	Loss 1.7966 (1.9725)	Prec@1 34.180 (25.199)	Prec@5 83.594 (78.491)	Acc 0.252 (0.208)	
2022-03-31 16:05:52,388 - INFO - TRAINING - Epoch: [0][200/781]	Time 0.092 (0.126)	Data 0.000 (0.019)	Loss 1.7863 (1.9636)	Prec@1 35.156 (25.395)	Prec@5 83.789 (78.875)	Acc 0.254 (0.210)	
2022-03-31 16:05:53,425 - INFO - TRAINING - Epoch: [0][210/781]	Time 0.092 (0.125)	Data 0.000 (0.018)	Loss 1.6792 (1.9548)	Prec@1 34.766 (25.672)	Prec@5 91.211 (79.226)	Acc 0.257 (0.212)	
2022-03-31 16:05:54,573 - INFO - TRAINING - Epoch: [0][220/781]	Time 0.093 (0.125)	Data 0.000 (0.017)	Loss 1.9112 (1.9479)	Prec@1 33.203 (25.961)	Prec@5 82.422 (79.514)	Acc 0.260 (0.214)	
2022-03-31 16:05:55,635 - INFO - TRAINING - Epoch: [0][230/781]	Time 0.102 (0.124)	Data 0.000 (0.016)	Loss 1.7924 (1.9416)	Prec@1 33.398 (26.209)	Prec@5 88.477 (79.830)	Acc 0.262 (0.216)	
2022-03-31 16:05:56,632 - INFO - TRAINING - Epoch: [0][240/781]	Time 0.092 (0.123)	Data 0.000 (0.016)	Loss 1.5980 (1.9319)	Prec@1 43.359 (26.592)	Prec@5 91.992 (80.173)	Acc 0.266 (0.218)	
