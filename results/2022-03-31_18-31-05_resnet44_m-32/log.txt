2022-03-31 18:31:05,112 - INFO - saving to results/2022-03-31_18-31-05_resnet44_m-32
2022-03-31 18:31:05,112 - DEBUG - run arguments: Namespace(adapt_grad_norm=None, autoaugment=False, batch_size=64, chunk_batch=1, config_file=None, cutmix=None, cutout=True, dataset='cifar10', datasets_dir='~/Datasets', device='cuda', device_ids=[0], dist_backend='nccl', dist_init='env://', distributed=False, drop_optim_state=False, dtype='float', duplicates=32, epochs=100, eval_batch_size=-1, evaluate=None, grad_clip=-1, input_size=None, label_smoothing=0, local_rank=-1, loss_scale=1, lr=0.1, mixup=None, model='resnet', model_config="{'depth': 44}", momentum=0.9, optimizer='SGD', print_freq=10, results_dir='results/', resume='', save='2022-03-31_18-31-05', save_all=False, seed=123, start_epoch=-1, sync_bn=False, tensorwatch=False, tensorwatch_port=0, weight_decay=0, workers=8, world_size=-1)
2022-03-31 18:31:05,112 - INFO - creating model resnet
2022-03-31 18:31:05,203 - INFO - created model with configuration: {'dataset': 'cifar10', 'depth': 44}
2022-03-31 18:31:05,204 - INFO - number of parameters: 661338
2022-03-31 18:31:10,731 - INFO - optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x149bd8e7ba60>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x149bd8e7b820>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]
2022-03-31 18:31:10,732 - INFO - data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 64, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 32, 'autoaugment': False, 'cutout': {'holes': 1, 'length': 16}}
 Regime:None
2022-03-31 18:31:10,732 - INFO - 
Starting Epoch: 1

2022-03-31 18:31:13,217 - DEBUG - OPTIMIZER - setting lr = 0.1
2022-03-31 18:31:13,217 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-03-31 18:31:14,806 - INFO - TRAINING - Epoch: [0][0/781]	Time 4.074 (4.074)	Data 2.484 (2.484)	Loss 2.3066 (2.3066)	Prec@1 6.738 (6.738)	Prec@5 41.748 (41.748)	Acc 0.067 (0.067)	
2022-03-31 18:31:17,364 - INFO - TRAINING - Epoch: [0][10/781]	Time 0.255 (0.603)	Data 0.000 (0.226)	Loss 2.3284 (2.3035)	Prec@1 10.449 (13.450)	Prec@5 54.395 (55.562)	Acc 0.134 (0.117)	
2022-03-31 18:31:19,914 - INFO - TRAINING - Epoch: [0][20/781]	Time 0.255 (0.437)	Data 0.000 (0.118)	Loss 2.2577 (2.2598)	Prec@1 11.133 (14.983)	Prec@5 63.232 (59.761)	Acc 0.150 (0.131)	
2022-03-31 18:31:22,460 - INFO - TRAINING - Epoch: [0][30/781]	Time 0.255 (0.378)	Data 0.000 (0.080)	Loss 2.1469 (2.2293)	Prec@1 25.586 (16.562)	Prec@5 67.676 (62.595)	Acc 0.166 (0.140)	
2022-03-31 18:31:25,009 - INFO - TRAINING - Epoch: [0][40/781]	Time 0.255 (0.348)	Data 0.000 (0.061)	Loss 2.1915 (2.1881)	Prec@1 20.557 (17.683)	Prec@5 75.684 (66.032)	Acc 0.177 (0.148)	
2022-03-31 18:31:27,556 - INFO - TRAINING - Epoch: [0][50/781]	Time 0.255 (0.330)	Data 0.000 (0.049)	Loss 1.9223 (2.1593)	Prec@1 27.393 (18.758)	Prec@5 81.006 (68.135)	Acc 0.188 (0.155)	
2022-03-31 18:31:30,116 - INFO - TRAINING - Epoch: [0][60/781]	Time 0.255 (0.318)	Data 0.000 (0.041)	Loss 1.9402 (2.1335)	Prec@1 20.117 (19.375)	Prec@5 82.910 (69.943)	Acc 0.194 (0.161)	
2022-03-31 18:31:32,664 - INFO - TRAINING - Epoch: [0][70/781]	Time 0.254 (0.309)	Data 0.000 (0.035)	Loss 2.0330 (2.1192)	Prec@1 25.391 (19.689)	Prec@5 79.883 (71.121)	Acc 0.197 (0.166)	
2022-03-31 18:31:35,211 - INFO - TRAINING - Epoch: [0][80/781]	Time 0.255 (0.302)	Data 0.000 (0.031)	Loss 1.9874 (2.1038)	Prec@1 25.488 (20.228)	Prec@5 76.367 (72.193)	Acc 0.202 (0.170)	
