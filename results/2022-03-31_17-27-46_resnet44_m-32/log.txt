2022-03-31 17:27:46,646 - INFO - saving to results/2022-03-31_17-27-46_resnet44_m-32
2022-03-31 17:27:46,647 - DEBUG - run arguments: Namespace(adapt_grad_norm=None, autoaugment=False, batch_size=64, chunk_batch=1, config_file=None, cutmix=None, cutout=True, dataset='cifar10', datasets_dir='~/Datasets', device='cuda', device_ids=[0], dist_backend='nccl', dist_init='env://', distributed=False, drop_optim_state=False, dtype='float', duplicates=32, epochs=100, eval_batch_size=-1, evaluate=None, grad_clip=-1, input_size=None, label_smoothing=0, local_rank=-1, loss_scale=1, lr=0.1, mixup=None, model='resnet', model_config="{'depth': 44}", momentum=0.9, optimizer='SGD', print_freq=10, results_dir='results/', resume='', save='2022-03-31_17-27-46', save_all=False, seed=123, start_epoch=-1, sync_bn=False, tensorwatch=False, tensorwatch_port=0, weight_decay=0, workers=8, world_size=-1)
2022-03-31 17:27:46,647 - INFO - creating model resnet
2022-03-31 17:27:46,724 - INFO - created model with configuration: {'dataset': 'cifar10', 'depth': 44}
2022-03-31 17:27:46,724 - INFO - number of parameters: 661338
2022-03-31 17:27:58,480 - INFO - optimization regime: [{'epoch': 0, 'optimizer': 'SGD', 'lr': 0.1, 'momentum': 0.9, 'regularizer': {'name': 'WeightDecay', 'value': 0.0001, 'log': False, 'filter': {'parameter_name': <function weight_decay_config.<locals>.<lambda> at 0x1545c97b8a60>, 'module': <function weight_decay_config.<locals>.<lambda> at 0x1545c97b8820>}}}, {'epoch': 81, 'lr': 0.01}, {'epoch': 122, 'lr': 0.001}, {'epoch': 164, 'lr': 0.0001}]
2022-03-31 17:27:58,480 - INFO - data regime: Current: {'datasets_path': '~/Datasets', 'name': 'cifar10', 'split': 'train', 'augment': True, 'input_size': None, 'batch_size': 64, 'shuffle': True, 'num_workers': 8, 'pin_memory': True, 'drop_last': True, 'distributed': False, 'duplicates': 32, 'autoaugment': False, 'cutout': {'holes': 1, 'length': 16}}
 Regime:None
2022-03-31 17:27:58,480 - INFO - 
Starting Epoch: 1

2022-03-31 17:28:01,497 - DEBUG - OPTIMIZER - setting lr = 0.1
2022-03-31 17:28:01,497 - DEBUG - OPTIMIZER - setting momentum = 0.9
2022-03-31 17:28:02,800 - INFO - TRAINING - Epoch: [0][0/781]	Time 4.319 (4.319)	Data 3.015 (3.015)	Loss 2.3066 (2.3066)	Prec@1 6.738 (6.738)	Prec@5 41.748 (41.748)	Acc 0.067 (0.067)	
2022-03-31 17:28:05,489 - INFO - TRAINING - Epoch: [0][10/781]	Time 0.268 (0.637)	Data 0.000 (0.274)	Loss 2.3284 (2.3035)	Prec@1 10.449 (13.450)	Prec@5 54.395 (55.562)	Acc 0.134 (0.117)	
2022-03-31 17:28:08,163 - INFO - TRAINING - Epoch: [0][20/781]	Time 0.267 (0.461)	Data 0.000 (0.144)	Loss 2.2577 (2.2598)	Prec@1 11.133 (14.983)	Prec@5 63.281 (59.763)	Acc 0.150 (0.131)	
2022-03-31 17:28:10,840 - INFO - TRAINING - Epoch: [0][30/781]	Time 0.268 (0.399)	Data 0.000 (0.097)	Loss 2.1469 (2.2293)	Prec@1 25.488 (16.564)	Prec@5 67.676 (62.591)	Acc 0.166 (0.140)	
2022-03-31 17:28:13,515 - INFO - TRAINING - Epoch: [0][40/781]	Time 0.268 (0.367)	Data 0.000 (0.074)	Loss 2.1915 (2.1881)	Prec@1 20.605 (17.683)	Prec@5 75.684 (66.026)	Acc 0.177 (0.148)	
2022-03-31 17:28:16,190 - INFO - TRAINING - Epoch: [0][50/781]	Time 0.267 (0.347)	Data 0.000 (0.059)	Loss 1.9221 (2.1593)	Prec@1 27.295 (18.752)	Prec@5 81.104 (68.132)	Acc 0.188 (0.155)	
2022-03-31 17:28:18,865 - INFO - TRAINING - Epoch: [0][60/781]	Time 0.267 (0.334)	Data 0.000 (0.050)	Loss 1.9410 (2.1335)	Prec@1 20.117 (19.370)	Prec@5 82.812 (69.934)	Acc 0.194 (0.161)	
2022-03-31 17:28:21,546 - INFO - TRAINING - Epoch: [0][70/781]	Time 0.273 (0.325)	Data 0.000 (0.043)	Loss 2.0330 (2.1192)	Prec@1 25.293 (19.681)	Prec@5 79.980 (71.114)	Acc 0.197 (0.166)	
2022-03-31 17:28:24,222 - INFO - TRAINING - Epoch: [0][80/781]	Time 0.268 (0.318)	Data 0.000 (0.037)	Loss 1.9867 (2.1039)	Prec@1 25.537 (20.223)	Prec@5 76.367 (72.183)	Acc 0.202 (0.170)	
2022-03-31 17:28:26,897 - INFO - TRAINING - Epoch: [0][90/781]	Time 0.267 (0.312)	Data 0.000 (0.033)	Loss 2.0068 (2.0867)	Prec@1 21.729 (20.778)	Prec@5 77.246 (73.274)	Acc 0.208 (0.174)	
2022-03-31 17:28:29,578 - INFO - TRAINING - Epoch: [0][100/781]	Time 0.268 (0.308)	Data 0.000 (0.030)	Loss 1.8959 (2.0700)	Prec@1 28.369 (21.608)	Prec@5 78.760 (74.083)	Acc 0.216 (0.177)	
2022-03-31 17:28:32,254 - INFO - TRAINING - Epoch: [0][110/781]	Time 0.268 (0.304)	Data 0.000 (0.027)	Loss 1.8870 (2.0582)	Prec@1 30.518 (22.169)	Prec@5 80.811 (74.621)	Acc 0.222 (0.181)	
2022-03-31 17:28:34,933 - INFO - TRAINING - Epoch: [0][120/781]	Time 0.268 (0.301)	Data 0.000 (0.025)	Loss 1.8376 (2.0451)	Prec@1 27.490 (22.566)	Prec@5 84.619 (75.264)	Acc 0.226 (0.185)	
2022-03-31 17:28:37,613 - INFO - TRAINING - Epoch: [0][130/781]	Time 0.268 (0.299)	Data 0.000 (0.023)	Loss 1.9219 (2.0314)	Prec@1 28.516 (23.093)	Prec@5 82.520 (75.897)	Acc 0.231 (0.188)	
2022-03-31 17:28:40,292 - INFO - TRAINING - Epoch: [0][140/781]	Time 0.268 (0.297)	Data 0.000 (0.022)	Loss 1.8452 (2.0196)	Prec@1 30.371 (23.500)	Prec@5 85.010 (76.474)	Acc 0.235 (0.191)	
2022-03-31 17:28:42,971 - INFO - TRAINING - Epoch: [0][150/781]	Time 0.268 (0.295)	Data 0.000 (0.020)	Loss 1.8294 (2.0120)	Prec@1 27.979 (23.801)	Prec@5 87.061 (76.881)	Acc 0.238 (0.194)	
2022-03-31 17:28:45,653 - INFO - TRAINING - Epoch: [0][160/781]	Time 0.268 (0.293)	Data 0.000 (0.019)	Loss 1.9401 (2.0017)	Prec@1 27.637 (24.127)	Prec@5 82.373 (77.332)	Acc 0.241 (0.197)	
2022-03-31 17:28:48,331 - INFO - TRAINING - Epoch: [0][170/781]	Time 0.268 (0.292)	Data 0.000 (0.018)	Loss 1.8412 (1.9936)	Prec@1 24.951 (24.382)	Prec@5 82.471 (77.750)	Acc 0.244 (0.200)	
2022-03-31 17:28:51,010 - INFO - TRAINING - Epoch: [0][180/781]	Time 0.268 (0.290)	Data 0.000 (0.017)	Loss 1.7542 (1.9819)	Prec@1 24.365 (24.777)	Prec@5 86.182 (78.172)	Acc 0.248 (0.202)	
2022-03-31 17:28:53,690 - INFO - TRAINING - Epoch: [0][190/781]	Time 0.268 (0.289)	Data 0.000 (0.016)	Loss 1.7611 (1.9719)	Prec@1 37.451 (25.106)	Prec@5 85.156 (78.630)	Acc 0.251 (0.205)	
2022-03-31 17:28:56,369 - INFO - TRAINING - Epoch: [0][200/781]	Time 0.268 (0.288)	Data 0.000 (0.015)	Loss 1.8393 (1.9629)	Prec@1 31.055 (25.297)	Prec@5 85.059 (79.020)	Acc 0.253 (0.207)	
2022-03-31 17:28:59,048 - INFO - TRAINING - Epoch: [0][210/781]	Time 0.268 (0.287)	Data 0.000 (0.014)	Loss 1.6913 (1.9541)	Prec@1 33.936 (25.544)	Prec@5 92.090 (79.382)	Acc 0.255 (0.209)	
2022-03-31 17:29:01,728 - INFO - TRAINING - Epoch: [0][220/781]	Time 0.268 (0.286)	Data 0.000 (0.014)	Loss 1.8972 (1.9474)	Prec@1 31.689 (25.876)	Prec@5 83.691 (79.678)	Acc 0.259 (0.212)	
2022-03-31 17:29:04,407 - INFO - TRAINING - Epoch: [0][230/781]	Time 0.268 (0.285)	Data 0.000 (0.013)	Loss 1.7732 (1.9396)	Prec@1 32.178 (26.174)	Prec@5 86.670 (80.002)	Acc 0.262 (0.214)	
2022-03-31 17:29:07,087 - INFO - TRAINING - Epoch: [0][240/781]	Time 0.268 (0.285)	Data 0.000 (0.013)	Loss 1.6041 (1.9294)	Prec@1 39.941 (26.566)	Prec@5 90.186 (80.370)	Acc 0.266 (0.216)	
2022-03-31 17:29:09,767 - INFO - TRAINING - Epoch: [0][250/781]	Time 0.268 (0.284)	Data 0.000 (0.012)	Loss 1.6838 (1.9201)	Prec@1 38.086 (26.959)	Prec@5 87.744 (80.698)	Acc 0.270 (0.218)	
2022-03-31 17:29:12,449 - INFO - TRAINING - Epoch: [0][260/781]	Time 0.268 (0.283)	Data 0.000 (0.012)	Loss 1.8929 (1.9144)	Prec@1 30.957 (27.116)	Prec@5 81.152 (80.899)	Acc 0.271 (0.220)	
2022-03-31 17:29:15,129 - INFO - TRAINING - Epoch: [0][270/781]	Time 0.268 (0.283)	Data 0.000 (0.011)	Loss 1.8257 (1.9084)	Prec@1 29.150 (27.330)	Prec@5 81.689 (81.137)	Acc 0.273 (0.222)	
2022-03-31 17:29:17,809 - INFO - TRAINING - Epoch: [0][280/781]	Time 0.268 (0.282)	Data 0.000 (0.011)	Loss 1.5939 (1.8994)	Prec@1 45.605 (27.682)	Prec@5 89.307 (81.385)	Acc 0.277 (0.224)	
2022-03-31 17:29:20,488 - INFO - TRAINING - Epoch: [0][290/781]	Time 0.268 (0.282)	Data 0.000 (0.011)	Loss 1.8280 (1.8922)	Prec@1 27.686 (27.969)	Prec@5 86.914 (81.644)	Acc 0.280 (0.226)	
2022-03-31 17:29:23,169 - INFO - TRAINING - Epoch: [0][300/781]	Time 0.268 (0.281)	Data 0.000 (0.010)	Loss 1.4729 (1.8838)	Prec@1 46.729 (28.279)	Prec@5 92.188 (81.887)	Acc 0.283 (0.227)	
2022-03-31 17:29:25,850 - INFO - TRAINING - Epoch: [0][310/781]	Time 0.268 (0.281)	Data 0.000 (0.010)	Loss 1.6222 (1.8769)	Prec@1 38.379 (28.583)	Prec@5 93.018 (82.069)	Acc 0.286 (0.229)	
2022-03-31 17:29:28,539 - INFO - TRAINING - Epoch: [0][320/781]	Time 0.277 (0.281)	Data 0.000 (0.010)	Loss 1.8007 (1.8720)	Prec@1 28.662 (28.789)	Prec@5 83.496 (82.224)	Acc 0.288 (0.231)	
2022-03-31 17:29:31,218 - INFO - TRAINING - Epoch: [0][330/781]	Time 0.268 (0.280)	Data 0.000 (0.009)	Loss 1.5673 (1.8652)	Prec@1 45.312 (29.038)	Prec@5 88.037 (82.431)	Acc 0.290 (0.233)	
2022-03-31 17:29:33,910 - INFO - TRAINING - Epoch: [0][340/781]	Time 0.268 (0.280)	Data 0.000 (0.009)	Loss 1.7379 (1.8577)	Prec@1 36.670 (29.375)	Prec@5 88.818 (82.635)	Acc 0.294 (0.235)	
2022-03-31 17:29:36,600 - INFO - TRAINING - Epoch: [0][350/781]	Time 0.278 (0.280)	Data 0.000 (0.009)	Loss 1.7488 (1.8510)	Prec@1 30.713 (29.642)	Prec@5 86.426 (82.800)	Acc 0.296 (0.236)	
2022-03-31 17:29:39,279 - INFO - TRAINING - Epoch: [0][360/781]	Time 0.268 (0.279)	Data 0.000 (0.009)	Loss 1.4690 (1.8440)	Prec@1 43.066 (29.961)	Prec@5 92.969 (83.024)	Acc 0.300 (0.238)	
2022-03-31 17:29:41,959 - INFO - TRAINING - Epoch: [0][370/781]	Time 0.268 (0.279)	Data 0.000 (0.008)	Loss 1.5659 (1.8376)	Prec@1 45.068 (30.225)	Prec@5 89.014 (83.190)	Acc 0.302 (0.240)	
2022-03-31 17:29:44,638 - INFO - TRAINING - Epoch: [0][380/781]	Time 0.268 (0.279)	Data 0.000 (0.008)	Loss 1.4563 (1.8309)	Prec@1 46.191 (30.504)	Prec@5 96.094 (83.375)	Acc 0.305 (0.241)	
2022-03-31 17:29:47,318 - INFO - TRAINING - Epoch: [0][390/781]	Time 0.268 (0.278)	Data 0.000 (0.008)	Loss 1.6055 (1.8246)	Prec@1 38.867 (30.742)	Prec@5 91.162 (83.560)	Acc 0.307 (0.243)	
2022-03-31 17:29:49,997 - INFO - TRAINING - Epoch: [0][400/781]	Time 0.268 (0.278)	Data 0.000 (0.008)	Loss 1.6160 (1.8187)	Prec@1 37.842 (31.008)	Prec@5 93.262 (83.712)	Acc 0.310 (0.245)	
2022-03-31 17:29:52,677 - INFO - TRAINING - Epoch: [0][410/781]	Time 0.268 (0.278)	Data 0.000 (0.008)	Loss 1.5838 (1.8136)	Prec@1 40.039 (31.232)	Prec@5 92.139 (83.850)	Acc 0.312 (0.246)	
2022-03-31 17:29:55,356 - INFO - TRAINING - Epoch: [0][420/781]	Time 0.268 (0.278)	Data 0.000 (0.007)	Loss 1.5822 (1.8090)	Prec@1 37.988 (31.441)	Prec@5 92.676 (83.962)	Acc 0.314 (0.248)	
2022-03-31 17:29:58,037 - INFO - TRAINING - Epoch: [0][430/781]	Time 0.269 (0.277)	Data 0.000 (0.007)	Loss 1.5382 (1.8028)	Prec@1 42.188 (31.697)	Prec@5 94.092 (84.114)	Acc 0.317 (0.250)	
2022-03-31 17:30:00,717 - INFO - TRAINING - Epoch: [0][440/781]	Time 0.268 (0.277)	Data 0.000 (0.007)	Loss 1.6920 (1.7962)	Prec@1 41.260 (31.981)	Prec@5 90.283 (84.284)	Acc 0.320 (0.251)	
2022-03-31 17:30:03,397 - INFO - TRAINING - Epoch: [0][450/781]	Time 0.268 (0.277)	Data 0.000 (0.007)	Loss 1.5614 (1.7910)	Prec@1 41.113 (32.181)	Prec@5 88.330 (84.417)	Acc 0.322 (0.253)	
2022-03-31 17:30:06,077 - INFO - TRAINING - Epoch: [0][460/781]	Time 0.268 (0.277)	Data 0.000 (0.007)	Loss 1.6345 (1.7859)	Prec@1 39.307 (32.418)	Prec@5 90.137 (84.537)	Acc 0.324 (0.254)	
